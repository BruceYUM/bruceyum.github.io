[{"categories":["RocketMQ"],"content":"前 言 大家好，我是三此君，一个在自我救赎之路上的非典型程序员。 “一张图”系列旨在通过“一张图”系统性的解析一个板块的知识点： 三此君向来不喜欢零零散散的知识点，通过一张图将零散的知识点连接起来，能够让我们对一个板块有更深入、更系统的理解。 同时本系列尽可能的精炼，希望能够让大家花 20%的时间，快速理解这个板块下 80% 的内容。 本文是“一张图”系列的第一个板块：一张图解析 RocketMQ。 为了叙述的方便，绘图的时候将整个系列分为许多小的模块，讲解的时候也是按照模块循序渐进的。一张图解析 RocketMQ 原图 一张图解析 RocketMQ 是会深入到源码层面，但是文中不会粘贴源码。三此君在看源码的时候写了很多备注，可以降低大家看源码的难度，需要的同学自行到三此君的仓库中 Fork：rocketmq release-4.3.0 本文是《一张图解析 RocketMQ》系列的第 1 篇，今天的内容主要分为三个部分： 整体架构：会从大家熟悉的“生产者-消费者模式”逐步推出 RocketMQ 完整架构，只需要记住一张完整的架构图即可。 元数据管理：我把 RocketMQ 集群的元数据整理成一张图，方便大家直观的了解都有哪些元数据，各有什么用。 消息收发示例：通过 Docker 部署 RocketMQ，并用简单的示例串起 RocketMQ 消息收发流程。 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:1:0","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"整体架构 什么是消息队列？顾名思义，首先得有一个队列，这个队列用来存储消息。那有了消息队列就得有人往里面放，有人往里面取。有没有似曾相识燕归来的感 jio，这莫非就是连小学生都知道的，经典的“生产者-消费者模式”？接下来我们就来看看它里面穿了什么？ 别急，先来回顾一下 “生产者-消费者模式” 这个老朋友。简单来说，这个模型是由两类线程和一个队列构成： 生产者线程：生产产品，并把产品放到队列里。 消费者线程：从队列里面获取产品，并消费。 有了这个队列，生产者就只需要关注生产，而不用管消费者的消费行为，更不用等待消费者线程执行完；消费者也只管消费，不用管生产者是怎么生产的，更不用等着生产者生产。 这意味着什么呢，生产者和消费者之间实现解藕和异步。这就厉害了，因为我们生活中很多都是异步的。比如最近新冠疫情卷土重来，我点的外卖只能送到小区门口的外卖队列里面，而我只能去外卖队列里面取外卖，然后一顿狼吞虎咽。 具体 “生产者-消费者模式” 怎么实现，想必各位小学都学过了，我们来看看这个模式还有什么问题吧。最大的问题就是我们小学学的 “生产者-消费者模式” 是个单机版的，只能自嗨。这就相当于，我就是外卖骑手，我点了个外卖放到外卖队列，然后我再从外卖队列里面去取，一顿操作猛如虎呀！于是就有了进化版，我们把消费者，队列，生产者放到不同的服务器上，这就是传说中的分布式消息队列了。 生产者生产的消息通过网络传递给队列存储，消费者通过网络从队列获取消息。但是还有问题，消息可能有很多种，全都放在一起岂不是乱套了？我点的外卖和快递全都放在一起，太难找了吧。于是我们就需要区分不同类型消息，相同类型的消息称为一个 Topic。同时，骑手不可能只有一个，点外卖的也不会只有我一个人，于是就有了生产者组和消费者组。 但还是有问题呀，小区那么大，一个队列放不下。我住在小区南门，点个外卖还要跑去北门拿，那真的是 eggs hurt。于是物业在东南西北门各设了一个外卖快递放置点。也就是我们有多个队列，组成 队列集群。 可是，问题又双叒叕来了（还有完没完），一个小区那么多个外卖快递队列，骑手怎么知道送到哪里去，我又怎么知道去哪里取？很简单，导航呀。我们把导航的信息称为路由信息，这些信息需要有一个管理的地方，它告诉生产者，某这个 Topic 的消息可以发给哪些队列，同时告诉消费者你需要的消息可以从哪些队列里面取。RocketMQ 为这些路由信息的设置了管理员 NameServer，当然 NameServer 也可以有很多个，组成 NameServer 集群。 到这里，你就应该知道 RocketMQ 里面都穿了什么啦。包括了生产者（Producer），消费者（Consumer），NameServer 以及队列本身（Broker）。Broker 是代理的意思，负责队列的存取等操作，我们可以把 Broker 理解为队列本身。 NameServer：我们可以同时部署很多台 NameServer 服务器，并且这些服务器是无状态的，节点之间无任何信息同步。 NameServer 起来后监听 端口，等待 Broker、Producer、Consumer 连上来，NameServer 是集群元数据管理中心。 Broker：Broker 启动，跟所有的 NameServer 保持长连接，每 30s 发送一次发送心跳包（像心跳一样持续稳定的发送请求）。心跳包中包含当前 Broker 信息 ( IP+ 端口等）以及存储所有 Topic 信息。注册成功后，NameServer 集群中就有 Topic 跟 Broker 的映射关系。 我们可以同时部署多个 Master 和多个 Slave，一个 Master 可以对应多个 Slave，但是一个 Slave 只能对应一个 Master。Master 与 Slave 的需要有相同的 BrokerName，不同的 BrokerId 。BrokerId 为 0 表示 Master，非 0 表示 Slave，但只有 BrokerId=1 的从服务器才会参与消息的读负载。（可以暂时忽略 Broker 的主从角色） Topic：收发消息前，先创建 Topic，创建 Topic 时需要指定该 Topic 要存储在哪些 Broker 上，也可以在发送消息时自动创建 Topic。 Producer：Producer 发送消息，启动时先跟 NameServer 集群中的其中一台建立长连接，并从 NameServer 中获取当前发送的 Topic 存在哪些 Broker 上，采用轮询策略从选择一个队列，然后与队列所在的 Broker 建立长连接，并向 Broker 发消息。 Consumer：Consumer 跟 Producer 类似，跟其中一台 NameServer 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始消费消息。 我们刚刚提到骑手不止一个，取外卖快递的也不止我一个，所以会有生产者组合消费者组的概念。这里需要补充说明一下，消息分为集群消息和广播消息： 集群消息：一个 Topic 的一条消息，一个消费者组只能有一个消费者实例消费。例如，同样是外卖 Topic，一份外卖，我们整个小区也只有一个人消费，就是集群消费。 广播消息：一个 Topic 的一条消息，一个消费者组所有消费者实例都会消费。例如，如果是因为疫情，政府发放食品，那我们小区每个人都会消费，就是广播消费。 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:2:0","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"元数据管理 因为 Producer、Consumer 和 Broker 都需要和 NameServer 交互，负责的三此君不得不先和大家唠唠 NameServer 是何方神圣。上面有说道 NameServer 是集群的元数据管理中心，那它到底管理了哪些元数据？我们来看看 NameServer 里面又穿了什么，看完了记得关注、转发、点赞、收藏哦。 简单来说，NameServer 是我们的整个 RocketMQ 集群的元数据管理中心，负责集群元数据的增删改查。先不管这个增删改查是怎么实现的，我们甚至可以理解就是数据库的增删改查，但是我们一定要知道这些元数据都长什么样子。才能知道 Producer、Consumer 及 Broker 是如何根据这些数据进行消息收发的。 如图所示，二主二从的 Broker 集群相关的元数据信息，包括 topicQueueTable、BrokerAddrTable、ClusterAddrTable、brokerLiveInfo、FilterServer (暂时不用关注，图中未画出)。 HashMap\u003cString topic, List\u003cQueueData\u003e\u003e topicQueueTable：Key 是 Topic 的名称，它存储了所有 Topic 的属性信息。Value 是个 QueueData 列表，长度等于这个 Topic 数据存储的 Master Broker 的个数，QueueData 里存储着 Broker 的名称、读写 queue 的数量、同步标识等。 HashMap\u003cString BrokerName, BrokerData\u003e brokerAddrTable：这个结构存储着一个 BrokerName 对应的属性信息，包括所属的 Cluster 名称，一个 Master Broker 和多个 Slave Broker 的地址信息 HashMap\u003cString ClusterName, Set\u003cString BrokerName\u003e\u003e clusterAddrTable：存储的是集群中 Cluster 的信息，就是一个 Cluster 名称对应一个由 BrokerName 组成的集合。 HashMap\u003cString BrokerAddr, BrokerLiveInfo\u003e brokerLiveTable：Key 是 BrokerAddr 对应着一台机器，BrokerLiveTable 存储的内容是这台 Broker 机器的实时状态，包括上次更新状态的时间戳，NameServer 会定期检查这个时间戳，超时没有更新就认为这个 Broker 无效了，将其从 Broker 列表里清除。 HashMap\u003cString BrokerAddr, List\u003cString\u003e FilterServer\u003e filterServerTable：Key 是 Broker 的地址，Value 是和这个 Broker 关联的多个 FilterServer 的地址。Filter Server 是过滤服务器，是 RocketMQ 的一种服务端过滤方式，一个 Broker 可以有一个或多个 Filter Server。 其他角色会主动向 NameServer 上报状态，根据上报消息里的请求码做相应的处理，更新存储的对应信息。 Broker 接到创建 Topic 的请求后向 NameServer 发送注册信息，NameServer 收到注册信息后首先更新 Broker 信息，然后对每个 Master 角色的 Broker，创建一个 QueueData 对象。如果是新建 Topic，就是添加 QueueData 对象；如果是修改 Topic，就是把旧的 QueueData 删除，加入新的 QueueData。 Broker 向 NameServer 发送的心跳会更新时间戳，NameServer 每 10 秒检查一次检查时间戳，检查到时间戳超过 2 分钟则认为 Broker 已失效，便会触发清理逻辑。 连接断开的事件也会触发状态更新，当 NameServer 和 Broker 的长连接断掉以后，onChannelDestroy 函数会被调用，把这个 Broker 的信息清理出去。 Producer/Consumer 启动之后会和 NameServer 建立长连接，定时从 NameServer 获取路由信息保存到本地。消息的发送与拉取都会用到上面的数据。 那么多数据，相信大家看的有点晕，三此君简单总结下：NameServer 通过 brokerLiveInfo 来维护存活的 Broker。Producer 会获取上面的路由信息，发送消息的时候指定发送到哪个 Topic，根据 Topic 可以从 topicQueueTable 选择一个 Broker，根据 BrokerName 可以从 BrokerAddrTable 获取到Broker IP 地址。有了地址 Producer 就可以将消息通过网络传递给 Broker。 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:3:0","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"消息收发示例 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:4:0","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"RocketMQ 部署 刚刚我们了解 RocketMQ 整体架构，那怎么样通过 RocketMQ 收发消息呢？需要先通过 Docker 部署一套 RocketMQ： 如果你没有安装 Docker，可以根据菜鸟教程 MacOS Docker 安装/Windows Docker 安装 进行安装。然后，通过 docker-compose 部署 RocketMQ： 克隆 docker-middleware 仓库，打开 RocketMQ 目录； 修改broker.conf中的brokerIP1 参数为本机 IP； 进入docker-compose.yml文件所在路径，执行docker-compose up命令即可； 注意：如果你现在不了解 Docker 不重要，只需要按照步骤部署好 RocketMQ 即可，并不会阻碍我们理解 RocketMQ 相关内容。 部署完成后我们就可以在 Docker Dashboard 中看到 RocketMQ 相关容器，包括 Broker、NameServer 及 Console（RocketMQ 控制台），到这里我们就可以使用部署的 RocketMQ 收发消息了。 RocketMQ 已经部署好了，接下来先来看一个简单的消息收发示例，可以说是 RocketMQ 的 “Hello World”。 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:4:1","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"消息发送 public class SyncProducer { public static void main(String[] args) throws Exception { // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"Topic1\",\"Tag\", \"Key\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf(\"%s%n\", sendResult); // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); } } 首先，实例化一个生产者 producer，并告诉它 NameServer 的地址，这样生产者才能从 NameServer 获取路由信息。 然后 producer 得做一些初始化（这是很关键的步骤），它要和 NameServer 通信，要先建立通信连接等。 producer 已经准备好了，那得准备好要发的内容，把 “Hello World” 发送到 Topic1。 内容准备好，那 producer 就可以把消息发送出去了。producer 怎么知道 Broker 地址呢？他就会去 NameServer 获取路由信息，得到 Broker 的地址是 localhost:10909，然后通过网络通信将消息发送给 Broker。 生产者发送的消息通过网络传输给 Broker，Broker 需要对消息按照一定的结构进行存储。存储完成之后，把存储结果告知生产者。 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:4:2","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"消息接收 public class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息 erbconsumerijun.subscribe(\"sancijun\", \"*\"); // 注册回调实现类来处理从broker拉取回来的消息 consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage( List\u003cMessageExt\u003e msgs,ConsumeConcurrentlyContext context) { System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); // 标记该消息已经被成功消费 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); // 启动消费者实例 consumer.start(); } } 首先，实例化一个消费者 consumer，告诉它 NameServer 的地址，这样消费者才能从 NameServer 获取路由信息。 然后这个消费者需要知道自己可以消费哪些 Topic 的消息，也就是每个消费者需要订阅一个或多个 Topic。 消费者也需要做一些初始化，业务本身并没有理会怎么从 Broker 拉取消息，这些都是消费者默默无闻的奉献。所以，我们需要启动消费者，消费者会从 NameServer 拉取路由信息，并不断从 Broker 拉取消息。拉取回来的消息提供给业务定义的 MessageListener。 消息拉取回来后，消费这需要怎么处理呢？每个消费者都不一样（业务本身决定），由我们业务定义的 MessageListener 处理。处理完之后，消费者也需要确认收货，就是告诉 Broker 消费成功了。 以上就是本文的全部内容，本文没有堆砌太多无意义的概念，没有讲什么削峰解耦，异步通信。这些内容网上也很多，看了和没看没什么两样。最后的最后，看懂的点赞，没看懂的收藏，顺便在分享给你的小伙伴。还没有关注的朋友记得关注，入股不亏。 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:4:3","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"参考文献 RocketMQ 官方文档 RocketMQ 源码 丁威, 周继锋. RocketMQ技术内幕：RocketMQ架构设计与实现原理. 机械工业出版社, 2019-01. 李伟. RocketMQ分布式消息中间件：核心原理与最佳实践. 电子工业出版社, 2020-08. 杨开元. RocketMQ实战与原理解析. 机械工业出版社, 2018-06. 转载请注明出处 ","date":"2022-05-03","objectID":"/1.rocketmq-%E6%A6%82%E8%BF%B0/:5:0","tags":["RocketMQ 架构","RocketMQ","MQ","消息队列","消息中间件","kafka","元数据\"","NameServer","生产者","消费者","Broker"],"title":"RocketMQ 概述","uri":"/1.rocketmq-%E6%A6%82%E8%BF%B0/"},{"categories":["RocketMQ"],"content":"前 言 大家好，我是三此君，一个在自我救赎之路上的非典型程序员。 “一张图”系列旨在通过“一张图”系统性的解析一个板块的知识点： 三此君向来不喜欢零零散散的知识点，通过一张图将零散的知识点连接起来，能够让我们对一个板块有更深入、更系统的理解。 同时本系列尽可能的精炼，希望能够让大家花 20%的时间，快速理解这个板块下 80% 的内容。 本文是“一张图”系列的第一个板块：一张图解析 RocketMQ。 为了叙述的方便，绘图的时候将整个系列分为许多小的模块，讲解的时候也是按照模块循序渐进的。一张图解析 RocketMQ 原图 一张图解析 RocketMQ 是会深入到源码层面，但是文中不会粘贴源码。三此君在看源码的时候写了很多备注，可以降低大家看源码的难度，需要的同学自行到三此君的仓库中 Fork：rocketmq release-4.3.0 本文是“一张图解析 RocketMQ”第2 篇，对 RocketMQ 不了解的同学可以先看看三此君的 RocketMQ 概述。在了解了 RocketMQ 的整体架构之后，我们来深入的分析下生产者消息发送的设计与实现。本文从一个生产者示例开始，以两行代码为切入点，逐步剖析生产者启动流程、同步消息发送流程、RocketMQ 的通信机制，最后简单过一下异步消息发送流程。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:1:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"生产者示例 消息分为同步消息、异步消息和单向消息，简单来说： 同步消息：消息发送之后会等待 Broker 响应，并把响应结果传递给业务线程，整个过程业务线程在等待。 异步消息：调用异步发送 API，Producer 把消息发送请求放进线程池就返回。逻辑处理，网络请求都在线程池中进行，等结果处理好之后回调业务定义好的回调函数。 单向消息：只负责发送消息，不管发送结果。 我们先来回顾下同步消息发送的例子： public class SyncProducer { public static void main(String[] args) throws Exception { // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"Topic1\",\"Tag\", \"Key\", \"Hello world\".getBytes(\"UTF-8\")); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf(\"%s%n\", sendResult); // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); } } 首先，实例化一个生产者 producer，并告诉它 NameServer 的地址，这样生产者才能从 NameServer 获取路由信息。 然后 producer 得做一些初始化（这是很关键的步骤），它要和 NameServer 通信，要先初始化通信模块等。 producer 已经准备好了，那得准备好要发的内容，把 “Hello World” 发送到 Topic1。 内容准备好，那 producer 就可以把消息发送出去了。producer 怎么知道 Broker 地址呢？他会去 NameServer 获取路由信息，得到 Broker 的地址是 localhost:10909，然后通过网络通信将消息发送给 Broker。 生产者发送的消息通过网络传输给 Broker，Broker 需要对消息按照一定的结构进行存储。存储完成之后，把存储结果告知生产者。 其中有两个关键的地方：producer.start() 及 producer.send()，也就是生产者初始化及消息发送。我们以这两行代码为切入点，看看 RocketMQ Producer 的设计与实现。 Tips：因为本文是RocketMQ 设计与实现分析，虽然不会粘贴任何源码，但是图文中会有大量的类名和方法名，看的时候不必执着于这些陌生的类名和方法名，三此君会解释这些类和方法的用途。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:2:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"生产者启动 我们实例化一个生产者 DefaultMQProducer，并调用 DefaultMQProducer.start() 方法进行初始化： 启动流程比较长，其实最重要的就是初始化了通信模块，并启动了多个定时任务，这些在后面的消息发送过程中都会用到： 检查配置是否合法：生产者组名是否为空、是否满足命名规则、长度是否满足等。 启动通信模块服务 Netty RemotingClient：RemotingClient 是一个接口，底层使用的通讯框架是Netty，提供了实现类 NettyRemotingClient，RemotingClient 在初始化的时候实例化 Bootstrap，方便后续用来创建 SocketChannel；后文会介绍 RocketMQ 的通信机制，大家稍安勿躁。 启动 5 个后台定时任务：定时更新 NameServerAddr 信息，定时更新 topic 的路由信息，定时向 Broker 发送心跳及清理下线的 Broker，定时持久化 Consumer 的 Offset 信息，定时调整线程池； 生产者每 30s 会从某台 NameServer 获取 Topic 和 Broker 的映射关系（路由信息）存在本地内存中，如果发现新的 Broker 就会和其建立长连接，每 30s 会发送心跳至 Broker 维护连接。 Tips：生产者为什么要启动消息拉取服务？重平衡服务是什么？简单来说，这两个服务都是用于消费者的，这里我们暂且不理会。消息拉取服务 pullMessageService 是从 Broker 拉取消息的服务 ，重平衡服务 rebalanceService 用于消费者的负载均衡，负责分配消费者可消费的消息队列。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:3:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"同步发送 总体上讲，消息发送可以划分为三个层级： 业务层：准备需要发送的消息。 消息处理层：获取业务发送的 Message，经过一系列的参数检查、消息发送准备、参数包装等操作。 通信层：基于 Netty 封装的一个网络通信服务，将消息发送给 Broker。 我们通过前面的示例来看整个同步消息发送的处理流程，整个过程我们的主要目标就是把消息发送到 Broker： 第一步：业务层构建待发送消息 Message msg = new Message(\"Topic1\",\"Tag\", \"Key\", \"Hello world\".getBytes(\"UTF-8\")); 第二步：然后我们调用 producer.send(msg) 发送消息，可是 producer 怎么知道发给谁呢？消息本身又需要经过哪些处理呢？我们进入调用链直到 sendDefaultImpl 检查消息是否为空，消息的 Topic 的名字是否为空或者是否符合规范，消息体大小是否符合要求，最大值为4MB，可以通过 maxMessageSize 进行设置。 执行 tryToFindTopicPublishInfo() 方法：获取 Topic 路由信息，如果不存在则抛出异常。如果本地缓存没有路由信息，就通过Namesrv 获取路由信息，更新到本地。消息构建的时候我们指定了消息所属 Topic，根据 Topic 路由信息我们可以找到对应的 Broker。 Tips：从 NameServer 获取的路由信息 TopicRouteData 会包含指定 Topic 的 topicQueueTable、brokerAddrTable，如果获取不到路由信息会使用默认的 topic 名称 “TBW102” 去获取路由信息。 TBW102 就是接受自动创建主题的， Broker 启动会把这个默认主题登记到 NameServer，这样当 Producer 发送新 Topic 的消息时候就得知哪个 Broker 可以自动创建主题，然后发往那个 Broker。 Broker 接受到这个消息的时候发现没找到对应的主题，但是它接受创建新主题，这样就会创建对应的 Topic 路由信息。 计算消息发送的重试次数，同步重试和异步重试的执行方式是不同的。在同步发送情况下如果发送失败会默认重投两次（默认retryTimesWhenSendFailed = 2），并且不会选择上次失败的 Broker，会向其他 Broker 投递。 执行队列选择方法 selectOneMessageQueue()。根据 lastBrokerName（上次发送消息失败的 Broker 的名字）和 Topic 路由选一个 MessageQueue。 首次发送 lastBrokerName 为 null，采用轮询策略选择一个 MessageQueue。如果上次发送失败，也是采用轮询策略选择一个 MessageQueue，但是会跳过属于上次发送失败 Broker 的 MessageQueue，也就是换一个 Broker 发送。 Tips：选择一个 MessageQueue，什么是 MessageQueue 呢？这和 Broker 的存储结构相关，我们会在存储部分详细介绍，这里先说结论，每个 Topic 默认会有 4 个 MessageQueue，每个 MessageQueue 有不同的 queueId(0-3)。 我们也可以通过sendLatencyFaultEnable 来设置是否总是发送到延迟级别较低的Broker，默认值为False，我么这里就不展开讨论了。 执行 sendKernelImpl() 方法。 第三步：sendDefaultImpl 做了一系列逻辑处理，我们已经得到了待发送的 BrokerName，而我们的目标是把消息发送到 Broker。sendKernelImpl 方法是发送消息的核心方法，主要用于准备通信层的入参（比如Broker地址、请求体等），将请求传递给通信层。 根据 MessageQueue.brokerName 获取 Broker IP 地址，给message添加全局唯一 ID。 Tips：sendKernelImpl 也有很多的逻辑处理，我们暂时先略过这里的压缩、事务消息、钩子函数、重试消息： 对大于4k的普通消息进行压缩，并设置消息的系统标记为MessageSysFlag.COMPRESSED_FLAG。 如果是事务Prepared消息，则设置消息的系统标记为MessageSysFlag.TRANSACTION_PREPARED_TYPE 如果注册了消息发送钩子函数，则执行消息发送之前的增强逻辑，通过DefaultMQProducerImpl#registerSendMessageHook注册钩子处理类，并且可以注册多个。 构建发送消息请求头：生产者组、主题名称、默认创建主题Key、该主题在单个Broker默认队列数、队列ID（队列序号）、消息系统标记（MessageSysFlag）、消息发送时间、消息标记、消息扩展属性、消息重试次数、是否是批量消息等 处理重试消息。 调用 MQClientAPIImpl.sendMessage()，首先构建一个远程请求 RemotingCommand，根据发送类型（同步或异步）调用不同的通信层实现方法。我们这里是同步消息，则调用 RemotingClient.invokeSync()。 处理返回结果，将通信层返回的结果封装成 SendResult 对象返回给业务层。 第四步：RemotingClient 是基于 Netty 实现的，熟悉 Netty 的同学已经大概知道后面的流程，不熟系的同学也没有关系，这里先混个眼熟，下面我们会对 Netty 做简单的介绍。 RemotingClient.invokeSync() 先是通过 Broker Addr 获取或者创建 Netty Channel。先从 channelTables Map 本地缓存中，以Broker Addr 为 key 获取 Channel，没有获取到则通过 Netty Bootstrap.connect( Broker Addr) 创建 Channel，并放入缓存。 然后生成\u003copaque, ResponseFuture\u003e的键值对放入 responseTable 缓存中，结果返回的时候根据 opaque 从缓存中获取结果。 调用 channel.writeAndFlush() 将消息通过网络传输给指定 Broker。这里是 Netty 框架的 API，已经不在 RocketMQ 范畴。 调用 ResponseFuture.waitResponse() 方法，直到 Netty 接收 Broker的返回结果。其实就是执行 countDownLatch.await()。 第五步：结果处理及返回。 Broker 处理结果返回，Netty 产生可读事件，由 Channelhandler 处理可读事件，这里是 NettyClientHandler.channelRead0()接收写入数据，处理可读事件。 然后处理返回结果，从 responseTable 取出 ResponseFuture，并执行 responseFuture.putResponse()。实际上就只执行 countDownLatch.countDown() 唤醒第四步中等待的调用线程，返回 Broker 的处理结果 RemotingCommand。 结果层层返回，直到 MQClientAPIImpl.sendMessageSync() 出手了，这里调用 MQClientAPIImpl.processSendResponse() 处理返回结果，封装成 SendResult 对象返回给业务层。 到这里，生产者已经将消息发送到指定的 Broker 了，其中包括了消息的层层校验及封装；还有很重要的是如何选择一个 MessageQueue 进行发送（重试），重试是保证消息发送可靠的关键步骤；最后通过 Netty 将请求发送给 Broker。我们先不管 Broker 收到请求如何处理，但是要明白消息如何送到 Broker 进行存储，需要对 Netty 有简单的理解。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:4:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"通信机制 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:5:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"Netty 介绍 Netty 有很多概念，等介绍完概念大家都困了，我们就不过多介绍了，直接来看看 Netty 的基础流程，能够帮助我们更好的理解 RocketMQ 即可。 Netty 服务端启动初始化两个线程组 BossGroup \u0026 WorkerGroup，分别用于处理客户端连接及网络读写。 Netty 客户端启动初始化一个线程组， 用于处理请求及返回结果。 客户端 connect 到 Netty 服务端，创建用于 传输数据的 Channel。 Netty 服务端的 BossGroup 处理客户端的连接请求，然后把剩下的工作交给 WorkerGroup。 连接建立好了，客户端就可以利用这个连接发送数据给 Netty 服务端。 Netty WorkerGroup 中的线程使用 Pipeline(包含多个处理器 Handler) 对数据进行处理。 Netty 服务端的处理完请求后，返回结果也经过 Pipeline 处理。 Netty 服务端通过 Channel 将数据返回给客户端。 客户端通过 Channel 接收到数据，也经过 Pipeline 进行处理。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:5:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"Netty 示例 我们先用 Netty 实现一个简单的 服务端/客户端 通信示例，我们是这样使用的，那 RocketMQ 基于 Netty 的通信也应该是这样使用的，不过是在这个基础上封装了一层。主要关注以下几个点：服务端什么时候初始化的，服务端实现的 Handler 做了什么事？客户端什么时候初始化的，客户端实现的 Handler 做了什么事？ Netty 服务端初始化：初始化的代码很关键，我们要从源码上理解 RocketMQ 的通信机制，那肯定会看到类似的代码。根据上面的流程来看，首先是实例化 bossGroup 和 workerGroup，然后初始化 Channel，从代码可以看出我们是在 Pipeline 中添加了自己实现的 Handler，这个 Handler 就是业务自己的逻辑了，那 RocketMQ 要处理数据应该也需要实现相应的 Handler。 public class MyServer { public static void main(String[] args) throws Exception { //创建两个线程组 boosGroup、workerGroup EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //创建服务端的启动对象，设置参数 ServerBootstrap bootstrap = new ServerBootstrap(); //设置两个线程组boosGroup和workerGroup bootstrap.group(bossGroup, workerGroup) //设置服务端通道实现类型 .channel(NioServerSocketChannel.class) //使用匿名内部类的形式初始化Channel对象 .childHandler(new ChannelInitializer\u003cSocketChannel\u003e() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { //给pipeline管道添加处理器 socketChannel.pipeline().addLast(new MyServerHandler()); } });//给workerGroup的EventLoop对应的管道设置处理器 //绑定端口号，启动服务端 ChannelFuture channelFuture = bootstrap.bind(6666).sync(); //对关闭通道进行监听 channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 实现自定义的服务端处理器 Handler：自定义的 Handler 需要实现 Netty 定义的 HandlerAdapter，当有可读事件时就会调用这里的 channelRead() 方法。等下我们看 RocketMQ 通信机制的时候留意RocketMQ 自定义了哪些 Handler，这些 Handler 有做了什么事。 /** * 自定义的Handler需要继承Netty规定好的 HandlerAdapter 才能被Netty框架所关联，有点类似SpringMVC的适配器模式 **/ public class MyServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //获取客户端发送过来的消息 ByteBuf byteBuf = (ByteBuf) msg; System.out.println(\"收到\" + ctx.channel().remoteAddress() + \"发送的消息：\" + byteBuf.toString(CharsetUtil.UTF_8)); //发送消息给客户端 ctx.writeAndFlush(Unpooled.copiedBuffer(\"服务端已收到消息，记得关注三此君，记得三连\", CharsetUtil.UTF_8)); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { //发生异常，关闭通道 ctx.close(); } } Netty 客户端初始化：Netty 客户端，在 RocketMQ 中对应了 Producer/Consumer。在 Producer 启动中有一步是启动通信模块服务，其实就是初始化 Netty 客户端。客户端也需要先实例化一个 NioEventLoopGroup，然后将自定义的 handler 添加到 Pipeline，还有很重要的一步是我们需要 connect 连接到 Netty 服务端。 public class MyClient { public static void main(String[] args) throws Exception { NioEventLoopGroup eventExecutors = new NioEventLoopGroup(); try { //创建bootstrap启动引导对象，配置参数 Bootstrap bootstrap = new Bootstrap(); //设置线程组 bootstrap.group(eventExecutors) //设置客户端的Channel实现类型 .channel(NioSocketChannel.class) //使用匿名内部类初始化 Pipeline .handler(new ChannelInitializer\u003cSocketChannel\u003e() { @Override protected void initChannel(SocketChannel ch) throws Exception { //添加客户端Channel的处理器 ch.pipeline().addLast(new MyClientHandler()); } }) //connect连接服务端 ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 6666).sync(); //对Channel关闭进行监听 channelFuture.channel().closeFuture().sync(); } finally { //关闭线程组 eventExecutors.shutdownGracefully(); } } } 实现自定义的客户端处理器 Handler：客户端处理器也继承自 Netty 定义的 HandlerAdapter，当 Channel 变得可读的时候（服务端数据返回）会调用我们自己实现的 channelRead()。 public class MyClientHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //发送消息到服务端 ctx.writeAndFlush(Unpooled.copiedBuffer(\"三此君，我正在看 RocketMQ 生产者发送消息~\", CharsetUtil.UTF_8)); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //接收服务端发送过来的消息 ByteBuf byteBuf = (ByteBuf) msg; System.out.println(\"收到三此君的消息，我一定会三连的\" + ctx.channel().remoteAddress() + byteBuf.toString(CharsetUtil.UTF_8)); } } ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:5:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"RocketMQ 通信流程 RocketMQ 通信模块基于 Netty 实现，总体代码量不多。主要是 NettyRemotingServer和NettyRemotingClient，分别对应通信的服务端和客户端。根据前面的 Netty 示例，我们要理解 RocketMQ 如何基于 Netty 通信，只需要知道 4 个地方：NettyRemotingServer 如何初始化，NettyRemotingClient 初始化，如何基于 NettyRemotingClient 发送消息，无论是客户端还是服务端收到数据后都需要 Handler 来处理。 Broker/NameServer 需要启动 Netty 服务端。Broker 我们后面会进一步分析，只需要知道 Broker 启动的时候会调用 NettyRemotingServer.start() 方法初始化 Netty 服务器。 主要做了 4 件事：配置 BossGroup/WorkerGroup NioEventLoopGroup 线程组，配置 Channel，添加 NettyServerHandler，调用 serverBootstrap.bind() 监听端口等待客户端连接。 Producer/Consumer 需要启动 Netty 客户端，在生产者启动流程中 MQClientInstantce 启动通信服务模块，其实就是调用NettyRemotingClient.start() 初始化 Netty 客户端。 主要做了 3 件事：配置客户端 NioEventLoopGroup 线程组，配置 Channel，添加 NettyClientHandler。 客户端配置了 Channel，但是 Channel 还没有创建，因为 Channel 肯定要和具体的 Server IP Addr 关联。在同步消息发送流程中，调用 NettyRemoteClient.invokeSync()，从 channelTables 缓存中获取或者创建一个新的 Channel，其实就是调用 bootstrap.connect() 连接到 NettyServer，创建用于通信的 Channel。 有了 Channel 后，Producer 调用 Channel.writeAndFlush() 将数据发送给服务器。NettyRemotingServer WorkerGroup 处理可读事件，调用 NettyServerHandler 处理数据。 NettyServerHandler 调用 processMessageReceived方法。processMessageReceived 方法做了什么呢？通过传入的请求码 RequestCode 区别不同的请求，不同的请求定义了不同的 Processor。例如，是生产者存入消息使用 SendMessageProcessor，查询消息使用 QueryMessageProcessor，拉取消息使用 PullMessageProcessor。这些 Processor 在服务端初始化的时候，以 RequestCode 为 Key 添加到 Processor 缓存中。processMessageReceived 就是根据 RequeseCode 获取不同的 Processor，处理完后把结果返回给 NettyRemotingClient。 NettyRemotingClient 收到可读事件，调用 NettyClientHandler 处理返回结果。NettyClientHandler也调用processMessageReceived 处理返回结果。processMessageReceived 从以 opaque 为 key ResponseTables 缓存冲取出 ResponseFuture，将返回结果设置到 ResponseFuture。同步消息则执行 responseFuture.putResponse()，异步调用执行回调。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:5:3","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"异步发送 除了同步消息发送，RocketMQ 还支持异步发送。我们只需要在前面是示例中稍作修改就会得到一个异步发送示例，最大的不同在于发送的时候传入 SendCallback 接收异步返回结果回调。 public class AsyncProducer { public static void main(String[] args) throws Exception { // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"Topic1\",\"Tag\", \"Key\", \"Hello world\".getBytes(\"UTF-8\")); // SendCallback 接收异步返回结果的回调 producer.send(msg, new SendCallback() { @Override public void onSuccess(SendResult sendResult) { System.out.printf(\"关注呀！！！%-10d OK %s %n\", index,sendResult.getMsgId()); } @Override public void onException(Throwable e) { System.out.printf(\"三连呀！！！%-10d Exception %s %n\", index, e); e.printStackTrace(); } }); // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); } } 同步发送个异步发送主要的过程都是一样的，不同点在于同步消息调用 Netty Channel.writeAndFlush 之后是 waitResponse 等待 Broker 返回，而异步消息是调用预先定义好的回调函数。 异步消息和同步消息整体差不多，可以说在基于 Netty 实现异步消息比同步消息还要简单一下，我们这里主要来看一些不同点： 调用 DefaultMQProducer 异步发送接口需要我们定义 SendCallback 回调函数，在执行成功或者执行失败后回调。 DefaultMQProducerImp 中的 send 方法会将异步发送请求封装成 Runable 提交到线程池，然后业务线程就直接返回了。 sendDefaultImpl 计算重试同步和异步消息有区别，异步消息在这里不会重试，而是在后面结果返回的时候通过递归重试。 跟着调用链到 sendMessageAsync 方法，需要注意的是这里构建了 InvokeCallback 实例，ResponseFuture 会持有该实例，Netty 结果返回后调用该实例的方法。 下面就是正常的 Netty 数据发送流程，直到 Broker 处理完请求，返回结果。NettyRemotingClient 处理可读事件，NettyClientHandler 处理返回结果，调用 ResponseFuture.executeInokeCallback，进而调用 InvokeCallback.operationComplete. 如果 Broker 返回结果是成功的，则封装返回结果 SendResult，并回调业务实现的 SendCallback.onSucess 方法，更新容错项。 如果 Broker 返回失败，或出现任何异常则执行重试，重试超过 retryTimesWhenSendFailed 次则回调业务定义的 SendCallback.onException方法。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:6:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"总结 以上就是 RocketMQ 消息发送的主要内容，我们简单的总结下： 生产者启动：主要是调用 NettyRemotingClient.start() 初始化 Netty 客户端，并启动 5 个后台线程； 消息发送：业务层封装发送的消息，逻辑层进行层层校验及封装，轮询策略选择一个 MessageQueue 发送(重试)，通信层基于 Netty 将消息发送给 Broker。 通信机制：基于 Netty 实现，只需要留意 NettyRemotingServer/NettyRemotingClient 的初始化，并且在通道变得可读/可写时，会调用 NettyServerhandler/NettyClienthandler 进行处理。 同步异步：同步和异步消息大同小异，只是同步消息通过 Netty 发送请求后会执行 ResponseFuture.waitResponse() 阻塞等待，而异步消息发送请求后不会等待，请求返回后调用 SendCallback 回调。 ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:7:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"参考文献 RocketMQ 官方文档 RocketMQ 源码 丁威, 周继锋. RocketMQ技术内幕：RocketMQ架构设计与实现原理. 机械工业出版社, 2019-01. 李伟. RocketMQ分布式消息中间件：核心原理与最佳实践. 电子工业出版社, 2020-08. 杨开元. RocketMQ实战与原理解析. 机械工业出版社, 2018-06. ","date":"2022-05-03","objectID":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/:8:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","生产者","Producer","同步消息","异步消息","通信机制"],"title":"RocketMQ 生产者","uri":"/2.rocketmq-%E7%94%9F%E4%BA%A7%E8%80%85/"},{"categories":["RocketMQ"],"content":"前 言 大家好，我是三此君，一个在自我救赎之路上的非典型程序员。 “一张图”系列旨在通过“一张图”系统性的解析一个板块的知识点： 三此君向来不喜欢零零散散的知识点，通过一张图将零散的知识点连接起来，能够让我们对一个板块有更深入、更系统的理解。 同时本系列尽可能的精炼，希望能够让大家花 20%的时间，快速理解这个板块下 80% 的内容。 本文是“一张图”系列的第一个板块：一张图解析 RocketMQ。 为了叙述的方便，绘图的时候将整个系列分为许多小的模块，讲解的时候也是按照模块循序渐进的。一张图解析 RocketMQ 原图 一张图解析 RocketMQ 是会深入到源码层面，但是文中不会粘贴源码。三此君在看源码的时候写了很多备注，可以降低大家看源码的难度，需要的同学自行到三此君的仓库中 Fork：rocketmq release-4.3.0 本文是《一张图解析 RocketMQ》系列的第 3 篇，之前我们已经了解的 RocketMQ 概述、RocketMQ 生产者，生产者通过网络传输消息，现在接力棒已经交给了 Broker，那 Broker 是如何存储消息的呢？为什么 RocketMQ 可以有百万的吞吐量呢？要知道 Broker 如何存储消息，我们需要先了解 RocketMQ 的存储结构，也就是消息是如何组织的。了解了存储结构，我们才能更好的理解存储流程，不然我们不知道为什么流程是这样的。最后我们需要了解有哪些机制支撑 RocketMQ 百万吞吐量。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:1:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"存储架构 消息在 Broker 上的存储结构如上图，所有的所有相关文件放在 ROCKETMQ_HOME 下，有哪些文件呢？存放消息本身的 CommitLog，以及消息的索引文件 ConsumeQueue 和 IndexFile： CommitLog 从物理结构上来看，所有的消息都存储在 CommitLog 里面，其实就是所有的消息按照“消息在 CommitLog 各字段示意图”所示，挨个按顺序存储到文件中。 单个 CommitLog 文件大小默认 1G ，文件名长度为 20 位，左边补零，剩余为起始偏移量。比如 00000000000000000000 代表了第一个文件，起始偏移量为 0，文件大小为 1G=1073741824；当第一个文件写满了，第二个文件为 00000000001073741824，起始偏移量为 1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件。CommitLog 顺序写，可以大大提高写入效率。 但是问题来了，消息发送的时候我们指定了 Topic，现在所有 Topic 都顺序个写入到 CommitLog，存入的时候是安逸了（顺序写），但是获取消息可就麻烦了。如果我要获取某个 Topic 的消息，需要遍历 commitlog 文件，根据 topic 过滤消息。这个渣男，只管自己爽。有什么办法可以提高消息查询效率呢？ ConsumeQueue 我们再回忆一下，消息存入的时候是指定了 Topic，同时我们也说了每个 Topic 默认创建 4 个 ConsumeQueue（ queueId 标识）。关键就在 ConsumeQueue 上，ConsumeQueue 是指定 Topic 消息的索引文件，怎么理解呢？从“消息在 ConsumeQueue 各字段示意图”可知，每个条目共 20 个字节，分别为 8 字节的 commitlog 物理偏移量、4 字节的消息长度、8 字节 tag hashcode，单个文件由 30W 个条目组成，可以像数组一样随机访问每一个条目，每个 ConsumeQueue 文件大小约 5.72M。ConsumeQueue 文件可以看成是基于 topic 的 commitlog 索引文件。Consumer 即可根据 ConsumeQueue 来查找待消费的消息。 因为 ConsumeQueue 里只存偏移量信息，所以尺寸是有限的，在实际情况中，大部分的 ConsumeQueue 能够被全部读入内存，所以这个中间结构的操作速度很快，可以认为是内存读取的速度。此外为了保证 CommitLog 和 ConsumeQueue 的一致性，CommitLog 里存储了 ConsumeQueues、Message Key、Tag 等所有信息，即使 ConsumeQueue 丢失，也可以通过 CommitLog 完全恢复出来。 ConsumeQueue 文件夹的组织方式如下：topic/queue/file 三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。 IndexFile IndexFile 是另一种可选索引文件，提供了一种可以通过 key 或时间区间来查询消息的方法。 IndexFile 索引文件其底层实现为 hash 索引，类似于 Java 1.7 HashMap，计算 Key 的 hashcode，hashcode 取余得到 hash 槽，拉链法解决哈希冲突。 Index 文件的存储位置是：$HOME \\store\\index${fileName}，文件名 fileName 是以创建时的时间戳命名的，固定的单个 IndexFile 文件大小约为 400M，一个 IndexFile 可以保存 2000W 个索引。 所以，RocketMQ 消息存储架构主要有 CommitLog，ConsumeQueue，IndexFile 构成。我们发送一条消息，会先格式化成“消息在 CommitLog 各字段示意图”中的样子，顺序写入 CommitLog 中，然后 Broker 会按照 ”消息在 ConsumeQueue 各字段示意图“所示构建一条索引记录，存入该消息所属 Topic 的 ConsumeQueue 索引文件中。如果有 IndexFile，还会构建 IndexFile。 现在我们已经知道了 RocketMQ 消息的存储结构，接下来我们的就要了解 RocketMQ 是如何构建 CommitLog、ConsumeQueue 和 IndexFile，以及 RocketMQ 如何保证性能支撑百万吞吐量的？这是本文的主要目标，一定要抓住主要目标，不要走丢咯。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:2:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"启动流程 了解了 RocketMQ 消息在磁盘中是怎么存储的，我们就可以来看看具体的存储流程了。首先，还是先来看看 Broker 的启动流程。初始化过程都是这个鸟样，只看初始化过程完全不知所云，但是不看初始化过程，直接看具体执行流程也是摸不着头脑，一堆组件不知道从哪里来的，所以我们还是先耐着性子大致看看。但这并不是我们关注的重点，注意几个关键点即可。 初始化启动环境。部署好 RocketMQ 后，执行/bin/mqbroker 脚本，主要用于设置 RocketMQ 目录环境变量，例如 ROCKETMQ_HOME 。然后调用 ./bin/runbroker.sh 进入 RocketMQ 的启动入口，主要设置了 JVM 启动参数，比如 JAVA_HOME、Xms、Xmx。执行 main 函数。 初始化 BrokerController。该初始化主要包含 RocketMQ 启动命令行参数解析、NettyRemotingServer 初始化、Broker 各个模块配置参数解析、Broker 各个模块初始化、进程关机 Hook 初始化等过程。 启动 RocketMQ 的各个组件。但是这些组件并不是每一个都是核心组件，部分组件会在后面的流程中使用，这里混个眼熟，如果后面流程没有提及的大家可以暂且跳过，我们的目标是把握 RocketMQ 的核心内容，而不是每个细节。 MessageStore：存储层服务，比如 CommitLog、ConsumeQueue 存储管理，消息刷盘，索引构建等。 RemotingServer：普通通道请求处理服务。一般的请求都是在这里被处理的。 FastRemotingServer：VIP 通道请求处理服务。如果普通通道比较忙，那么可以使用 VIP 通道，一般作为客户端降级使用。 BrokerOuterAPI：Broker 访问对外接口的封装对象。 PullRequestHoldService：Pull 长轮询服务。 ClientHousekeepingService：清理心跳超时的生产者、消费者、过滤服务器。 FilterServerManager：过滤服务器管理。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:3:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"存储流程 在前面 RocketMQ 存储结构中我们了解了 RocketMQ 将所有消息顺序写入 CommitLog，然后构建 ConsumeQueue/IndexFile 索引文件，所以这个小结我们主要的目标就是看看这些文件是如何构建的。 Broker 启动流程中很关键的一点是启动了 NettyRemotingServer，在 [RocketMQ 生产者]( 中我们介绍过 RocketMQ 的通信机制 NettyRemotingServer 初始化会监听端口等待客户端连接，当客户端发送请求的时，NettyRemotingServer WorkerGroup 处理可读事件，调用 NettyServerHandler.channelRead0() 处理数据。 接着调用链到 processRequestCommand 方法，这个方法主要是根据请求中的 RequestCode，从本地缓存 processorTable 中获取相应的 Processor 来执行后续逻辑。处理器是什么？处理器的缓存从哪里来？ Processor 就是用来处理特定请求的执行者，例如，生产者存入消息使用 SendMessageProcessor，查询消息使用 QueryMessageProcessor，拉取消息使用 PullMessageProcessor。在 Broker 启动流程中有一步是注册 Processor，以 RequestCode 为 Key ，Processor 为值，添加到 processorTable 缓存中。 接着 [RocketMQ 生产者]( 消息发送流程来看，当生产者的请求达到 Broker，Broker 获取的 Processor 应为 SendMessageProcessor。封装一个 Runable 对象，run 方法内调用 SendMessageProcessor.processRequest ，提交到线程池，继续后面的处理。 SendMessageProcessor.processRequest 调用 sendMessage 方法，主要包含消息的校验及重试逻辑处理，然后调用存储模块 DefaultMessageStore 存储消息。 消息校验：校验 Broker 是否配置可写，校验 Topic 名字是否为默认值，获取或创建 topicConfig，判断 queueId 是否超过限制。 重试消息处理：消费者消费失败后会将消息发回给 Broker，这里我们暂且认为就是生产者发送的请求，先看下面的流程。 DefaultMessageStore.putMessage 只是做了很多的校验，简单看看即可。包括：如果当前 Broker 停止工作则拒绝消息写入、Broker 为 SLAVE 角色则拒绝消息写入、当前 RocketMQ 不支持写入则拒绝消息写入、主题长度超过 256 个字符则拒绝消息写入、消息属性长度超过 65536 个字符则拒绝消息写入、PageCache 忙则报错。然后调用 CommitLog.putMessage 存入消息。 看到这里应该稍微熟悉一些了，终于到我们期待已久的 CommitLog 出场了。主要是延迟消息处理，然后获取可以写入的 CommitLog 进行写入。 延迟消息处理：如果消息的延迟级别大于 0，将消息的原主题名称与原消息队列 ID 存入消息属性中，用延迟消息主题 SCHEDULE_TOPIC、消息队列 ID 更新原先消息的主题与队列，这是并发消息消费重试关键的一步。但不是这个本节的主要目标，后文会进一步分析。 关键点在如何获取可以写入的 CommitLog。存储结构小节里面有提到每个 CommitLog 默认大小 1G，写完一个文件，以偏移量命名创建下一个文件。每个 1G 大小 CommitLog 的在代码层面对应的是 MappedFile，而多个 MappedFiled 组成 MappedFileQueue。逻辑上的 CommitLog 通过持有 MappedFileQueue 管理多个 MappedFile。所以，获取可以写入的 CommitLog 也就是获取 MappedFileQueue 最后一个 MappedFile，为什么是最后一个，因为前面的已经写完了呀。来看看 RocketMQ 逻辑与物理存储的对应关系应该能够更直观的理解。 获取到最后一个 MappedFile 后，调用 MappedFiled.appendMessage 将消息追加到该文件中。可是尽管是顺序写入，但是连小学生都知道写磁盘还是很慢，难道想这样支撑 RocketMQ 百万吞吐量？too young too simple！ 从逻辑存储结构和物理存储结构的映射关系来看，MappedFile 持有物理 CommitLog 的 fileChannel (Java NIO 文件读写的通道)，通过 fileChannel 可以访问物理 CommitLog 文件，但是 RocketMQ 并没有直接使用 fileChannel，而是映射到一个 MappedByteBuffer，我们的目的就是把消息写入这个 ByteBuffer 中，进而写入 MappedFile 对应的 CommitLog 文件。为什么需要这样做，还有哪些细节，会在”文件内存映射“小结中为大家解答。 继续看流程，得到 MappedFile 对应的 ByteBuffer，我们需要将消息序列化，写入 ByteBuffer 中。 构建消息 id, createMessageId 获取该消息在消息队列的偏移量，CommitLog 中保存了当前所有消息队列的当前待写入偏移量。 判断是否是事务消息：这里主要处理 Prepared 类型和 Rollback 类型的消息，设置消息 queueOffset 为 0 计算消息总大小，calMsgLength。 判断文件的剩余空间，是否足够写入当条消息，如果不可以，则将文件末尾写入剩余空间大小+固定魔数；然后返回一个 END_OF_FILE 的结果 如果空间足够，这将这条消息写入之前得到的 MappedFile 的 ByteBuffer 中。 将各字段按照”消息在 CommitLog 各字段示意图“存入 Bytebuffer，然后返回 PUT_OK 结果 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:4:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"文件内存映射 我们已经知道 MappedFile 持有 CommitLog 文件的 fileChannel，可以通过 fileChannel 访问 CommitLog，但是 RocketMQ 却没有使用 fileChannel 访问 CommitLog，而是映射到一个 MappedByteBuffer ？这里就有疑问了，映射是什么意思？什么是 MappedByteBuffer，有什么用，为什么要这样做？ 这里的映射其实是使用 Java NIO 的内存映射 Buffer，将文件映射到内存中，得到 MappedByteBuffer。就是传说中的文件内存映射，映射文件同时具有内存的写入速度和与磁盘一样可靠的持久化方式。我们都知道磁盘 I/O 速度非常慢，文件内存映射就是 RockerMQ 支撑百万吞吐量的关键之一，可为什么文件内存映射会有那么大的威力？我们需要先来简单回顾一下传统的磁盘 I/O，看看它有什么大病。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:5:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"传统 I/O Linux 操作系统分为“用户态”和“内核态”，文件操作、网络操作需要涉及这两种形态的切换。一台服务器把本机磁盘文件的内容发送到客户端，一般分为两个步骤： read(file, tmp_buf, len)：把数据从存储器 （磁盘、网卡等） 读取到用户缓冲区 write(socket, tmp_buf, len)：把数据从用户缓冲区写出到存储器 可以清楚看到这里一共触发了 4 次用户态和内核态的上下文切换，分别是 read()/write() 调用和返回时的切换，2 次 DMA 拷贝，2 次 CPU 拷贝，加起来一共 4 次拷贝操作。通过引入 DMA，我们已经把 Linux 的 I/O 过程中的 CPU 拷贝次数从 4 次减少到了 2 次，但是 CPU 拷贝依然是代价很大的操作，对系统性能的影响还是很大，特别是那些频繁 I/O 的场景，更是会因为 CPU 拷贝而损失掉很多性能，我们需要进一步优化，减少甚至是完全避免 CPU 拷贝。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:5:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"mmap 零拷贝技术是指计算机执行操作时，[CPU](https://zh.wikipedia.org/wiki/中央处理器）不需要先将数据从某处 [内存](https://zh.wikipedia.org/wiki/随机存取存储器）复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省 CPU 周期和 内存带宽。 零拷贝可以减少甚至完全避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作，并且减少用户态 – 内核态上下文切换带来的系统开销，这些是为什么零拷贝提升 I/O 性能的原因。零拷贝技术有文多种，RocketMQ 主要使用 mmap 技术，而 kafka 主要使用 sendFile，所以我们也主要了解 mmap 技术。 利用 mmap() 替换 read()，配合 write() 调用的整个流程如下： 用户进程调用 mmap()，从用户态陷入内核态，将内核缓冲区映射到用户缓存区； DMA 控制器将数据从硬盘拷贝到内核缓冲区； mmap() 返回，上下文从内核态切换回用户态； 用户进程调用 write()，尝试把文件数据写到内核里的套接字缓冲区，再次陷入内核态； CPU 将内核缓冲区中的数据拷贝到的套接字缓冲区； DMA 控制器将数据从套接字缓冲区拷贝到网卡完成数据传输； write() 返回，上下文从内核态切换回用户态。 通过使用 mmap 的方式，可以省去向用户态的内存复制，提高速度。这种机制在 Java 中是通过 MappedByteBuffer 实现的，RocketMQ 通过 mmap 方式优化文件读写性能。 RocketMQ 主要通过 MappedByteBuffer 对文件进行读写操作。其中，利用了 NIO 中的 FileChannel 将磁盘上的物理文件直接映射到用户态的内存地址中（这种 mmap 的方式减少了传统 I/O 将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率（正因为需要使用内存映射机制，故 RocketMQ 的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存）。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:5:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"PageCache 在存储流程小节的 Broker 逻辑/物理存储结构图中，我们可以发现 MappedFile 持有 fileChannel、mappedByteBuffer、writeBuffer。fileChannel 指向对应的物理文件，并通过 fileChannel 创建 mappedByteBuffer，mappedByteBuffer 就对应上面提到的 mmap 文件内存映射。通过 mmap 方式写入文件时，消息并没有直接落到磁盘上，而是先写入操作系统的 PageCache。 顺序读写 PageCache 异步刷盘：页缓存（PageCache) 是 OS 对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于 OS 使用 PageCache 机制对读写访问操作进行了性能优化，将一部分的内存用作 PageCache。对于数据的写入，OS 会先写入至 PageCache 内，随后通过异步的方式由内核线程将 pageCache 内的数据刷盘至物理磁盘上。 预读取：对于数据的读取，如果一次读取文件时出现未命中 PageCache 的情况，OS 从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。 在 RocketMQ 中，ConsumeQueue 逻辑消费队列存储的数据较少，并且是顺序读取，在 PageCache 机制的预读取作用下，ConsumeQueue 文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。而对于 CommitLog 消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统 I/O 调度算法，比如设置调度算法为“Deadline”（此时块存储采用 SSD 的话），随机读的性能也会有所提升。 上面只提到了 mappedByteBuffer，那writeBuffer又是什么呢？writeBuffer 在 transientStorePoolEnable 为 true 启用，是通过 ByteBuffer 分配直接内存，并锁定在内存中（不换到虚拟内存） Tips：文件内存映射、零拷贝、PageCache 都和操作系统密切相关，三此君在这里只是简单的介绍，保证大家能够更好的理解 RocketMQ，感兴趣的同学可以进行深入的了解。也可以留言给三此君，三此君会尽快安排相关内容的分享。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:6:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"消息刷盘 从上面的流程可以看到，目前还只是写入内存中，这部分的速度都是很快的。那 RocketMQ 什么时候将消息写入磁盘呢？这就涉及到我们消息的刷盘机制，也就是流程中大家看到的 handleDiskFlush。消息刷盘在实现上分为同步刷盘、异步刷盘和异步转存： 同步刷盘服务（GroupCommitService）：在 Broker 存储消息到 PageCache 后，同步将 PageCache 刷到磁盘，再返回客户端消息并写入结果。同步刷盘对 MQ 消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用该模式较多。 异步刷盘服务（FlushRealTimeService）：在 Broker 存储消息到 PageCache 后，立即返回客户端写入结果，然后异步刷盘服务将 PageCache 异步刷到磁盘。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了 MQ 的性能和吞吐量。 异步转存服务（CommitRealTimeService）：Broker 通过配置读写分离将消息写入直接内存（Direct Memory，简称 DM），然后通过异步转存服务，将 DM 中的数据再次存储到 PageCache 中，以供异步刷盘服务将 PageCache 刷到磁盘中。 先是判断同步刷盘还是异步刷盘，同步刷盘则构建并提交同步刷盘请求。否则判断 isTransientStorePoolEnable 是否为 true，false 则直接调用异步刷盘服务，true 则调用异步转存服务。 同步刷盘：同步刷盘首先构建刷盘请求提交到同步刷盘请求列表中，然后等待同步刷盘任务完成，如果超时则返回刷盘错误，刷盘成功后正常返回给调用方。 同步刷盘服务 GroupCommitService 是一个循环线程，run 方法每 10s 执行一次 doCommit，当然如果有同步请求提交会立即执行刷盘。 doCommit 判断当前消息是否已经刷盘，如果没有刷盘则调用 CommitLog.mappedFileQueue.flush 方法，实际上调用的是 mappedByteBuffer.force 方法进行强制刷盘。刷盘之后唤醒调用线程。 异步刷盘：异步刷盘服务 FlushRealTimeService 也是一个循环线程，如果超过 10s 或者大于 4 页数据没有刷盘则执行刷盘，也是调用 CommitLog.mappedFileQueue.flush 方法进行刷盘。 异步转存：异步转存服务是在 transientStorePoolEnable 为 true 时，消息并没有写入 PageCache，而是写入直接内存中，异步转存只是将直接内存中的消息提交到 PageCache，然后唤醒异步刷盘服务进行刷盘。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:7:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"索引构建 大家到这里，消息都刷盘了，应该都万事大吉了吧？忘记了我们的主要目标除了 CommitLog 刷盘，还有 ComsumQueue/IndexFile 的构建呢？可是整个流程执行下来没有看到哪里构建了索引文件呀？得往回倒一倒，Broker 启动的时候，我们启动了一个叫 ReputMessageService 服务，这个服务本身是循环线程，专门用来构建索引文件，来看看肿么肥四吧。 ConsumeQueue 和 IndexFile 两个索引都是由 ReputMessageService 线程构建，ReputMessageService 继承 ServiceThread，ReputMessageService 线程每执行一次任务推送休息 1 毫秒就继续尝试调用 doReput() 推送消息到消息消费队列和索引文件。 从 CommitLog 中查找未创建索引的消息，将消息组装成 DispatchRequest 对象，该逻辑主要在 CommitLog.checkMessageAndReturnSize() 方法中实现。 调用 doDispatch() 方法，调用 CommitLogDispatcherBuildConsumeQueue 和 CommitLogDispatcherBuildIndex 两个索引处理器的 dispatch() 方法来处理 DispatchRequest。CommitLogDispatcherBuildConsumeQueue 索引处理器用于构建 ConsumeQueue，CommitLogDispatcherBuildIndex 用于构建 Index file。ConsumeQueue 是必须创建的，IndexFile 是否需要创建则是通过设置 messageIndexEnable 为 True 或 False 来实现的，默认为 True。 ConsumeQueue 索引文件的构建，首先要查找或者创建一个 ConsumeQueue，从上面 ”Broker 逻辑上“图所示，ConsumeQueue 的组织方式其实和 CommitLog 是一样的，也是持有 MappedFileQueue，然后获取可写入的 LastMappedFile。依次将消息偏移量、消息长度、tag hashcode 写入到 ByteBuffer 中，并根据 consumeQueueOffset 计算 ConumeQueue 中的物理地址。ConsumeQueue 的刷盘方式也是采用的 CommitLog 一步刷盘方式。 IndexFile 索引文件组织方式和前面两者不一样，并且是可选的。IndexFile 持有物理文件引用的文件映射内存 MappedByteBuffer，我们只需要按照 ”消息在 IndexFile 各字段示意图“所以写入各个字段即可。IdnexFile 持久化方式也不同，是在 getAndCreateLastIndexFile 会创建线程去刷盘。 ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:8:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"总 结 以上就是 RocketMQ 消息存储的主要内容，我们简单总结一下： 要理解消息的存储流程需要先知道消息的存储结构：在物理上消息挨个顺序写入 CommitLog，为了提升消息查询效率需要构建消息的索引文件 ConsumeQueue/IndeFile； Broker 启动时进行参数解析，并初始化了 NettyRemotingServer，启动存储服务用于消息存储及索引构建等； Broker 收到消息存储请求，经过层层校验，获取 CommitLog 对应的 MappedFile，将消息写入MappedFile 对应的内存映射ByteBuffer；(如果开启了isTransientStorePoolEnable，先写入 DM，再转存内存映射 ByteBuffer) 写入 ByteBuffer 还不行，消息要落在磁盘上才不会丢失。消息刷盘分为同步刷盘、异步刷盘和异步转存，异步转存是定时任务将 DM 的消息提交到 MappedByteBuffer 中，再有异步刷盘线程进行刷盘。同步刷盘和异步刷盘最终都是调用CommitLog.mappedFileQueue.flush 方法进行刷盘 刷盘之后还需要构建消息对应的索引，索引构建由专门的后台线程，每隔一秒执行一次。 最后，最最最重要的就是记得关注，记得点赞，记得转发，记得收藏呀！！！ ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:9:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"参考文献 RocketMQ 官方文档 RocketMQ 源码 Linux I/O 原理和 Zero-copy 技术全面揭秘 丁威, 周继锋. RocketMQ技术内幕：RocketMQ架构设计与实现原理. 机械工业出版社, 2019-01. 李伟. RocketMQ分布式消息中间件：核心原理与最佳实践. 电子工业出版社, 2020-08. 杨开元. RocketMQ实战与原理解析. 机械工业出版社, 2018-06. ","date":"2022-05-04","objectID":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/:10:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消息存储","Broker","零拷贝","mmap","文件内存映射","消息存储结构\"","PageCache","ConsumeQueue","IndexFile","刷盘"],"title":"RocketMQ 消息存储","uri":"/3.rocketmq-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/"},{"categories":["RocketMQ"],"content":"前 言 大家好，我是三此君，一个在自我救赎之路上的非典型程序员。 “一张图”系列旨在通过“一张图”系统性的解析一个板块的知识点： 三此君向来不喜欢零零散散的知识点，通过一张图将零散的知识点连接起来，能够让我们对一个板块有更深入、更系统的理解。 同时本系列尽可能的精炼，希望能够让大家花 20%的时间，快速理解这个板块下 80% 的内容。 本文是“一张图”系列的第一个板块：一张图解析 RocketMQ。 为了叙述的方便，绘图的时候将整个系列分为许多小的模块，讲解的时候也是按照模块循序渐进的。一张图解析 RocketMQ 原图 一张图解析 RocketMQ 是会深入到源码层面，但是文中不会粘贴源码。三此君在看源码的时候写了很多备注，可以降低大家看源码的难度，需要的同学自行到三此君的仓库中 Fork：rocketmq release-4.3.0 本文是《一张图解析 RocketMQ》系列的第 4 篇，之前我们已经了解的 RocketMQ 概述、RocketMQ 生产者、RocketMQ 消息存储，从生产者发送消息，到 Broker 存储消息，现在消费者终于可以拉取消息并消费了。我们还是通过一个示例，并从其中的关键代码为切入点，深入分析 RocketMQ 消费者的设计与实现。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:1:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"消费者示例 public class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息 consumer.subscribe(\"sancijun\", \"*\"); // 注册回调实现类来处理从broker拉取回来的消息 consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage( List\u003cMessageExt\u003e msgs,ConsumeConcurrentlyContext context) { System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); // 标记该消息已经被成功消费 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); // 启动消费者实例 consumer.start(); } } 首先，实例化一个 DefaultMQPushConsumer 消费者 consumer，告诉它 NameServer 的地址，这样消费者才能从 NameServer 获取路由信息。 除了 DefaultMQPushConsumer，还有 DefaultMQPullConsumer。DefaultMQPullConsumer 需要业务调用 API 去拉取消息，而 DefaultMQPushConsumer 其实是基于 Pull 拉的方式来实现 Push 推的效果。DefaultMQPushConsumer 会自动把消息拉取回来，然后回调业务实现的 MessageListener，把消息交回给业务方。DefaultMQPullConsumer 消费行为主要由业务方自己控制，而 DefaultMQPushConsumer 主要由 RocketMQ 控制消费行为，在实践过程中也更常用，所以我们主要分析 DefaultMQPushConsumer 的原理。 然后这个消费者需要知道自己可以消费哪些 Topic 的消息，也就是每个消费者需要订阅一个或多个 Topic，并且指定了 tag。其实在消费发送和存储的时候我们都有看到 tag，主要用于定义消息的业务属性。消费者可以只订阅 Topic 下某些 tag 的消息，也就是根据 tag 过滤消息。 消费者也需要做一些初始化，业务本身并没有理会怎么从 Broker 拉取消息，这些都是 DefaultMQPushConsumer 默默无闻的奉献。所以，我们需要启动消费者，消费者会从 NameServer 拉取路由信息，并不断从 Broker 拉取消息。 消息拉取回来后，消息这需要怎么处理呢？每个消费者都不一样（业务本身决定），由我们业务定义的 MessageListener 处理。最后，消费者也需要确认收货，就是告诉 Broker 消费成功与否。 从上面的例子可以看到，我们只是启动了消费者，并没有调用拉取消息相关的 API，消息是怎么顺着网线爬过来的呢？既然只是启动了消费者，那我们就来看看消费者启动是怎么肥四。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:2:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"消费者启动 检查消费者的配置，比如消费者组名、消费类型、Queue分配策略等参数是否符合规范；将订阅关系数据发给Rebalance服务对象。校验消费者实例名，如果是默认的名字，则更改为当前的程序进程id。 消费类型就是在 RocketMQ 概述中提到的 集群消费或广播消费，而 Queue 分配策略和 Rebalance 我们会在本文后面分析。 获取或创建 MQClientInstance，MQClientInstance 和 RocketMQ 生产者 中Producer 启动的 MQClientInstance 是一样的，用于管理本实例中全部生产者与消费者的生产和消费行为。同一个 clientId 是共用一个 MQClientInstance 的， clientId 是通过本机 IP 和 instanceName（默认值 default）拼起来的。 设置Rebalance对象消费者组、消费类型、Queue 分配策略、MQClientInstance 等参数，后面用到了再聊。 初始化 Broker API 的封装类 pullAPIWrapper，看名字就知道消息拉取流程中会派上用场，同时注册消息过滤器。 初始化位点管理器，并加载位点信息，位点管理也就是消费进度管理啦。位点管理器分为本地管理和远程管理两种，集群消费时消费位点保存在 Broker 中，由远程管理器管理；广播消费时位点存储在本地，由本地管理器管理。 本地注册消费者实例，如果注册成功，则表示消费者启动成功。 启动MQClientInstance实例，启动过程和生产者启动一致。主要是启动了 NettyRemotingClient 和一些定时任务等。 初始化消费服务并启动。之所以用户“感觉”消息是 Broker 主动推送给自己的，是因为DefaultMQPushConsumer通过PullMessageService 将消息拉取到本地，再通过Callback的 形 式，将本地消息Push给用户的消费代码。DefaultMQPushConsumer 与DefaultMQPullConsumer 获取消息的方式一样，本质上都是拉取。 更新本地订阅关系和路由信息；通过 Broker 检查是否支持消费者的过滤类型；向集群中的所有Broker发送消费者组的心跳信息。 立即执行一次 Rebalance，Rebalance 过程我们在后文中详细讲解。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:3:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"消息消费流程 DefaultMQPushConsumer 启动初始化过程中会启动消息拉取服务 PullMessageService，该服务是一个循环线程服务， run() 方法不断执行从 PullRequestQueue 中获取一个消息拉取任务 PullRequest，然后根据该任务中的消费者组获取相应的 DefaultMQPushConsumer 实例，执行消息拉取任务。 PullRequest 是消息拉取任务，封装了哪个消费者组，待拉取的 MessageQueue，拉取之后消息存放在本地的 ProcessQueue，以及拉取偏移量等。PullRequestQueue很明显就是存放PullRequest的队列，它是由 RebalanceService 维护，我们会本文后面详细分析 Rebalance 过程，这里先不展开了。 DefaultMQPushConsumer.pullMessage() 检查当前处理的队列是否被删除，服务器是否在运行中状态等。然后进行本地流控判断，如果本地缓存消息数量大于配置的最大拉取条数（默认为1000，可以调整），或本地缓存消息字节数大于配置的最大缓存字节数，则延迟 50ms 再拉取。检查订阅关系是否为空，为空则延迟 50ms 再拉取。 封装拉取回调函数 PullCallback，网络请求成功则回调 PullCallback.onSuccess，异常则会调用 PullCallback.onException。 根据 brokerName 和 brokerId 查找brokerAddr, 没找到则先从NameServer拉取路由信息，再重新获取brokerAddr。构建拉取消息请求头 PullMessageRequestHeader(Topic、queueId、offset) 等，然后调用 pullMessageAsync() 将信息发送到服务器。 pullMessageAsync 将请求封装成 RemotintCommand，然后构建回调函数 InvokeCallback，远程请求返回会回调 InvokeCallback.operationComplete。 然后就是我们已经很熟悉的基于 Netty 的网络请求过程，整个网络请求响应过程和生产者消息发送是一样的。Netty 的初始化同样是在 Consumer 启动流程中，在这里主要是获取或者创建一个 NettyChannel。先从 channelTables Map 本地缓存中，以 Broker Addr 为 key 获取 Channel，没有获取到则通过 Netty Bootstrap.connect( Broker Addr) 创建 Channel，并放入缓存。然后生成\u003copaque, ResponseFuture\u003e的键值对放入 responseTable 缓存中。调用 channel.writeAndFlush() 将请求通过网络传输给指定 Broker。 当客户端发送请求的时，NettyRemotingServer WorkerGroup 处理可读事件，调用 NettyServerHandler.channelRead0() 处理数据。接着调用链到 processRequestCommand 方法，这个方法主要是根据请求中的 RequestCode，从本地缓存 processorTable 中获取相应的 Processor 来执行后续逻辑。当前是拉取消息，故获取到的是 PullMessageProcessor。PullMessageProcessor 的具体处理过程我们稍后在分析，现在只需要知道它会调用 MessageStore.getMessage() 获取消息并返回给 Consumer。 消息查询：结合 RocketMQ 消息存储 中介绍的存储结构，我们都知道了消息实际存储在 CommitLog 中，为了加速消息查询，维护了 ConsumeQueue 这个索引文件接下来我们就看看如何从这两个文件中找到想要的消息。Broker 会根据请求中的 Topic、queueId、offset 等信息找到待返回消息在 ConsumeQueue 中的记录，然后读取这些记录的物理偏移量，再根据物理偏移量从 CommitLog 总获取实际的消息，经过序列化等处理后返回给 Consumer。查询消息的过程可以分为以下几个步骤。 1.拉取前校验，校验 DefaultMessageStore 服务是否已经关闭（正常关闭进程时会被关闭），校验 DefaultMessageStore 服务是否可读。 2.findConsumeQueue 方法根据 Topic、queueId 查找 ConsumeQueue 索引映射文件。判断根据查找到的 ConsumeQueue 索引文件校验传入的待查询的位点值是否合理，只有待查询的消息 offset 大于当前 ConsumeQueue文件 minOffset，且小于 maxOffset 才合理，否则重新计算下一次可以拉取的位点值。 3.循环读取满足 maxMsgNums=32 条数的消息。循环从 ConsumeQueue 中依次读取消息物理位点、消息大小和 taghashCode。先做 Hash 过滤，再使用过滤后的消息物理偏移量和 消息大小 到 CommitLog 中查找消息体，并放入结果列表中。 4.监控指标统计，返回拉取的消息结果。 请求回调：回调流程也和生产者异步消息回调一样。NettyRemotingClient 处理可读事件，NettyClientHandler 处理返回结果，调用 ResponseFuture.executeInokeCallback，进而调用 InvokeCallback.operationComplete。返回成功则 pullCallback.onSuccess() ，异常则调用 pullCallback.onException()，我们假设返回成功。 1.网络请求返回的是二进制数据，需要解码成消息列表填充 msgFoundList，并对消息进行消息过滤（TAG）模式。前面提过，消费者可以只订阅 Topic 下某些 Tag，所以在这里进行过滤。 2.如果拉取到的消息列表为空，则将 pullRequest 重新放回 pullRequestQueue 队列中，那么 pullMessageService 就可以从队列中继续获取该 pullRequest 执行下一次拉取任务。 3.将拉取到的消息存入 ProcessQueue。ProcessQueue 可以理解为 MessageQueue 在消费者端的本地缓存，拉取的消息会先缓存到 ProcessQueue。 4.拉取到的消息提交到 ConsumeMessageService 中供业务方消费，并由 ConsumeMessageService 提交给业务线程进行业务消费逻辑处理。 5.pullCallback.onSuccess提交给ConsumeMessageService，并把 pullRequest 重新放回 pullRequestQueue，就可以反返回了，pullMessageService 会从队列中继续获取该 pullRequest 执行下一次拉取任务。 接力棒交给了 ConsumeMessageService，ConsumeMessageService 又是如何将消息提交给业务方消费的呢？ConsumeMessageService.submitConsumeRequest 先将拉取回来的消息封装到一个可执行对象 ConsumeRequest 中，然后将这个可执行对象提交到线程池。 ConsumeMessageService有两种：并行消费服务 ConsumeMessageConcurrentlyService 和 顺序消费服务 ConsumeMessageOrderlyService。ConsumeMessageConcurrentlyService 或者ConsumeMessageOrderlyService 区别在于 ConsumeMessageOrderlyService 会将本地缓存的消息按照MessageId排序后返回给消费者线程。 然后 ConsumeRequest 被线程池调度并执行其中的 run 方法，最关键的是在 run 方法中调用了业务注册的 MessageListener.consumeMessage 方法，这就是业务自己实现的消费逻辑。 业务消费完之后需要进行消费结果处理。包含消费指标统计、消费重试处理和消费位点处理。我们先大致了解下，后面会详细分析具体的结果处理流程。 1.统计消费成功和失败的TPS 2.消费重试处理：消费失败的发回 Broker。发回失败的将消费重试次数加1，并重新提交给消费者； 3.消费位点处理：根据消费结果更新消费位点记录。 上面我们已经了解了整个消息消费的主要流程，其实包含三个关键步骤： pullMessageService 这个循环线程不断从 pullRequestQueue 获取消息拉取任务，构建拉取请求，通过 Netty 将消息拉取请求发送给 Broker。 然后是远程请求返回，回调消费者 PullCallback，将消息缓存到本地 ProcessQueue，并提交给消费者服务。 消费者服务将消息封装成可执行对象提交到线程池，线程池调度执行ConsumeRequest.run 方法，并调用业务实现的 MessageListener.cunsumeMessage 方法，处理业务消费逻辑。最后，进行消费结果处理","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:4:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"负载均衡 在消息消费流程中，PullMessageService 需要从 pullRequestQueue 队列中获取消息拉取任务 pullRequest，而这个 pullRequest 是由负载均衡服务 RebalanceService 创建的，因此贴心的三此君不得不跟大家一起看看 RebalanceService 是何方神圣。 RebalanceService 也是一个循环线程，每 20s 执行一次。查找当前 clientId 对应的全部的消费者组，全部执行一次 Rebalance。每个消费者执行 Rebalance 先获取订阅的所有 Topic，在 Topic 维度进行 Rebalance，即调用 rebalanceByTopic。 rebalanceByTopic 是消费者重平衡实现的核心方法，如上图： 首先从 rebalanceImpl 实例的本地缓存变量 topicSubscribeInfoTable 中获取该 Topic 主题下的消息消费队列集合 mqSet； 根据 topic 和 consumerGroup 为参数调用 mQClientFactory.findConsumerIdList 方法获取该消费组下所有消费者 Id 列表 cidAll。 先对 Topic 下的消息消费队列、消费者 Id 排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列。 然后，调用 updateProcessQueueTableInRebalance() 方法，具体的做法是， 将分配到的消息队列集合 mqSet 与 当前消费者正在处理的消息队列 processQueueTable 比对。例如，消费者 cid1 正在处理的是队列是 [q1,q5,q6]，重新分配后 cid1处理[q1,q2,q3]，则cid 需要新处理两个队列。 如果有 MessageQueue 不再分配给当前的消费者消费，则设置 ProcessQueue.setDropped(true)，表示放弃当前 MessageQueue 的 Pull 消息， 如果有新增的mq分配给该消费者则创建对应的ProcessQueue，创建对应的 pullRequest 加入到pullRequestQueue中。 消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:5:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"延迟重试 消费结果处理中我们提到，如果消费失败需要进行重试。消费者将消费失败的消息发送回 Broker，延迟一段时间进行重新消费。具体来说，RocketMQ 会创建重试主题：%RETRY%+消费组名称，并将原有的 Topic 修改为重试 Topic。这样还不行，因为我们需要延迟一段时间重试，刚刚失败就立即重试没有意义。所以在发回重试消息的时候会设置一个延迟级别 delayLevel，Broker 就会把该重试消息放到延迟队列中。如果重试次数超过 15 次，消息进入死信队列，需要人工干预。 所以，消息重试机制其实涉及 4 种队列，消息原 Topic 的队列、消息重试队列以、延迟队列及 死信队列DLQ。他们之间的关系是怎么样的呢？工作机制又是怎样的呢？ 我们还是回到具体的流程中： 消费者重试逻辑入口是在 ConsumeMessageConcurrentlyService#processConsumeResult 消费结果处理中，如果消费结果是RECONSUME_LATER，会从上下文中获取并设置延迟级别delayLevel，然后将消息发送回 Broker。 通信层就是调用 RemoteClientNetty.invokeSync 方法 (RequestCode=CONSUMER_SEND_MSG_BACK) 将请求发送给 Broker，Broker 根据 RequestCode 找到 SendMessageProcessor，并调用 consumerSendMsgBack 方法进行后续处理。 消息重试的关键点之一就在 consumerSendMsgBack 中： 创建重试主题：%RETRY%+原消费组名称，消费者默认会订阅原主题及对应的重试主题，故消费者会消费对应的重试消息。 根据物理偏移量从 commitlog 文件中获取消息，并将消息的原主题存入属性中，消费者就可以从消息属性中恢复原主题。 重试次数超过 maxReconsumeTimes (default=15)，再次改变主题为 DLQ（死信队列）。死信队列没什么可说的，就是一个特殊的队列，这个队列的消息不会被消费，需要人工干预。 将重试消息存入到 CommitLog 及索引文件 直到这里还只能实现重试，但是无法实现延迟重试，延迟需要借助延迟队列。延迟队列并不仅在消费重试的时候使用，我们也可以通过 Producer API 发送延迟消息。我们这里就通过消费重试的场景来了解延迟队列。接着刚刚的流程，重试消息构建好之后需要将消息存入 CommitLog。还记得我们在发回重试消息的时候设置了一个 delayLevel，这里就排上用场了。 在存入 CommitLog的时候会检查 delayLevel，如果 delayLevel\u003e0 会再次改变消息主题为延迟主题 SCHEDULE_TOPIC_XXXX。 只是改一个主题就能延迟了？当然还需要 Broker 提供一些机制为延迟队列保驾护航。 默认创建 15 个定时任务，分别处理 15 个延迟队列，对应 15 个延迟级别，延迟队列的 queueId = delayLevel -1。默认延迟 “1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”。所以，知道了 delayLevel，我们就知道了这条消息在延迟主题中所属的队列，以及延迟的时间。 根据 queueId 与延迟主题 SCHEDULE_TOPIC 查找 ConsumeQueue，获取每条消息的偏移量，大小及TaghashCode 根据消息物理偏移量与消息大小从commitlog文件中查找消息。清除消息的delayLevel，并恢复消息原先的Topic及queueId 将消息再次存入到Commitlog及索引文件 回到消息延迟重试逻辑中，消息主题从 Topic1-\u003e %RETRY%+${group} -\u003e SCHEDULE_TOPIC_XXXX，现在延迟队列恢复原主题，也就是从 SCHEDULE_TOPIC_XXXX 恢复到 %RETRY%+${group}。前面我们也说了，消费者会默认订阅对应的重试主题。 那么接下来，消费者就会消费对应的重试主题。回到消息正常的消费拉取流程，在预处理重试消息队列步骤中：如果拉取的消息来自重试队列，则将Topic名重置为原来的Topic名。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:6:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"位移管理 消费结果处理中还需要重点关注 RocketMQ 消费进度的管理。我们每次之拉取一批消息，如果不知道消费进度，那我们怎么知道下一次从什么地方开始消费？如果消费者宕机了，重新启动应该从哪里开始消费？这些问题都依赖 RocketMQ 消费进度管理。 RocketMQ 的消费进度管理分为本地位移管理 LocalOffsetStore 和 远程位移管理 RemoteOffsetStore 两种方式。LocalOffsetStore 用于广播消费，RemoteOffsetStore 用于集群消费位移管理。这里我们主要分析 RemoteOffsetStore。 先看上图中左下角 RemoteBrokerOffsetStore.updateOffset，是消费流程结果处理的时候调用 OffsetStore 来更新本地消费进度缓存，从图中可以看出，本地消费进度缓存 offsetTable 中存储的是\u003cMessageQueue, minOffset\u003e。为什么是最小的 offset？你想想 TCP 确认的时候是不是也是确认最小的 offset？ 消费结果处理更新完本地消费进度缓存后就返回了，接下来由消费者启动时创建的定时任务，每 10s 执行一次，将所有队列的消费进度同步给 Broker。Broker 收到请求之后，通过 RequestCode.UPDATE_CONSUMER_OFFSET 找到 ConsumerOffsetManager。执行 ConsumerOffsetManager.commitOffset 更新 Broker 消费位移。Broker 存储的消费进度表 offsetTable 是\u003ctopic@group, \u003cqueueId, minOffset»，也就是每个消费者组每个队列的最小位移。 以上就是远程位移管理的两要点，还需要补充的是除了定时任务同步所有消费队列位移，在消费者 shutdown 及Broker 返回拉取位移非法时都会进行位移同步。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:7:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"顺序消息 从消费者启动、消息拉取、消息消费、到结果处理中的消息重试和消费位移管理，我们已经了解了整个并发消息消费的整体流程及原理。但是三此君不得不跟大家加个餐呀，我们一直都在说并发消息，但是面试官要是问题顺序消息的原理，三此君要是没跟大家讲的话，没发跟大家交代呀。看在三此君那么负责的份上，是不是应该关注？是不是应该点赞？是不是应该转发？是不是应该收藏？ 是不是听到这里心都凉了一半，怎么还有……大家不慌，顺序消息和并发消息大同小异，我们主要了解下怎么保证消息的顺序消费的。顺序消息，其实只能够保证一个消费队列的消息顺序，如果要保证全局有序，那么需要保证只有一个消费队列。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:8:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"总结 消费方式分为 Push 和 Pull，Pull 需要业务方自己调用 API 进行拉取，Push 是基于 Pull，由 RocketMQ 线程将消息拉会本地，再调用业务方实现的 MessageListener，将消息传递非业务方进行消费。 消费者启动完成各种参数校验，和生产者一样的是都会实例化 MQClientInstance，并且启动消息拉取服务，消息重平衡服务。 消息重平衡服务每 20s 执行一次，获取对应 Topic 所有的 MessageQueue 和 clientId进行排序，然后按照分配策略（默认平均分配）进行重新分配，如果有新的分配的队列就生成 PullRequest 放入 pullRequestQueue 中。 消息消费的入口就在消费者初始化是启动了消息拉取服务 PullMessageService，该服务会从 pullRequestQueue 获取消息拉取任务 pullRequest，从 Broker 拉取消息，并提交给 ConsumeMessageService。 ConsumeMessageService 将回调业务方实现的 MessageListener进行消费，消费完成后执行消费结果处理。 消费结果处理的重点在消息重试和位点管理。 消息重试是在消费失败时，消息发送会 Broker，并设置延迟级别（随着重试次数层架，延迟级别也会增加），并将消息放入重试队列。因为设置了延迟级别，存入 CommitLog 的时候会替换原 Topic 替换为延迟主题 SCHEDULE_TOPIC。Broker 的有定时任务处理延迟队列，将到时间的延迟消息恢复主题，并放入原队列中。消费者订阅了重试队列，消费到时间被重投的队列。 广播消费使用的本地位移管理，集群消费使用远程位移管理。ConsumeMessageService 消费完成后会用当前最小的偏移量更新本地消费位移缓存，offsetTable。消费者初始化的时候启动了定时任务，每 10s 将本地消费位移缓存同步给 Broker。 ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:9:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"参考文献 RocketMQ 官方文档 RocketMQ 源码 丁威, 周继锋. RocketMQ技术内幕：RocketMQ架构设计与实现原理. 机械工业出版社, 2019-01. 李伟. RocketMQ分布式消息中间件：核心原理与最佳实践. 电子工业出版社, 2020-08. 杨开元. RocketMQ实战与原理解析. 机械工业出版社, 2018-06. ","date":"2022-05-04","objectID":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/:10:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","消费者","负载均衡","延迟队列","重试","顺序消息","位移"],"title":"RocketMQ 消费者","uri":"/4.rocketmq-%E6%B6%88%E8%B4%B9%E8%80%85/"},{"categories":["RocketMQ"],"content":"前 言 大家好，我是三此君，一个在自我救赎之路上的非典型程序员。 “一张图”系列旨在通过“一张图”系统性的解析一个板块的知识点： 三此君向来不喜欢零零散散的知识点，通过一张图将零散的知识点连接起来，能够让我们对一个板块有更深入、更系统的理解。 同时本系列尽可能的精炼，希望能够让大家花 20% 的时间，快速理解这个板块下 80% 的内容。 本文是“一张图”系列的第一个板块：一张图解析 RocketMQ。 为了叙述的方便，绘图的时候将整个系列分为许多小的模块，讲解的时候也是按照模块循序渐进的。一张图解析 RocketMQ 原图 一张图解析 RocketMQ 是会深入到源码层面，但是文中不会粘贴源码。三此君在看源码的时候写了很多备注，可以降低大家看源码的难度，需要的同学自行到三此君的仓库中 Fork：rocketmq release-4.3.0 本文是《一张图解析 RocketMQ》系列的第 5 篇，之前我们已经了解的 RocketMQ 概述、RocketMQ 生产者、RocketMQ 消息存储、RocketMQ 消费者。RocketMQ 大部分内容已经讲完了，可是还有一些很重要的特性得和大家唠唠，今天要分享的就是其中很重要的 RocketMQ 事务消息。 所谓事务消息，其实就是基于 MQ 的分布式事务解决方案。如果直接上来就看事务消息的实现，大家可能觉得云里雾里的。所以，我们还是需要先了解下什么事分布式事务问题。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:1:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"分布式事务问题 事务，我们是上小学就学过了，事务是满足 ACID 性质的一些列操作集合。当然，为了保证事务的 ACID 性质，其实有一套非常复杂的机制。可是残酷的世界从来不会让我们失望，我们连对事务的认知都还停留在 ACID 层面，现在又来一个分布式事务。小小年纪承受了那么多本不应该承受的，也只能硬着头皮上了。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:2:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"什么是分布式事务 我们先来看一个电商下单付款案例：用户完成一次下单并付款，服务器接收请求，首先创建新订单，然后扣减商品库存，最后从用户账户余额扣除金额。这几个操作要么一起成功，要么一起失败。如果我们所有服务都部署在同一台服务器上，并且只有一个数据库，这个问题就是我们小学学过的数据库事务问题。可是实力不允许啊，直接做个淘宝，上微服务、中台、DDD，全都一起上……拍脑袋谁不会，步子太大，恐怕扯着胯。现在分成了订单服务，库存服务和用户服务，完成上面的操作需要访问三个不同的微服务和三个不同的数据库。 这下问题可就大了，我们没办法使用数据库的事务能力了，要是下单成功，没减库存，没扣钱，那岂不是亏大了？当我们把三件事情看做一个事情事，要保证“业务”的一致性，要么所有操作全部成功，要么全部失败，不允许出现部分成功部分失败的现象，这就是分布式系统下的事务了。 **分布式事务是指是指事务各个参与者分别位于分布式系统的不同节点之上，通过网络通信来达到分布式一致性。**网络通信不可避免出现失败、超时的情况，因此分布式事务的实现比本地事务面临更多的困难。概括起来，分布式事务有三种场景：跨数据库分布式事务、跨服务分布式事务、混合式分布式事务。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:2:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"常见解决方案 解决方案 描述 基于 XA/2PC 实现的分布式事务 XA (eXtended Architecture ) 是 X/Open 组织提出的一套名为X/Open XA 的处理事务规范，定义了全局的事务管理器（Transaction Manager，用于协调全局事务）和局部的资源管理器（Resource Manager，用于驱动本地事务）之间的通信接口。 基于 TCC 实现的分布式事务 TCC (Try、Commit、Cancel) 是一种补偿型事务，该模型要求应用的每个服务提供 try、confirm、cancel 三个接口，它的核心思想是通过对资源的预留（提供中间态），尽早释放对资源的加锁，如果事务可以提交，则完成对预留资源的确认，如果事务要回滚，则释放预留的资源。TCC 也是一种两阶段提交协议，可以看作 2PC/XA 的一种变种，本质是一个应用层面上的 2PC，但是不会长时间持有资源锁。 基于 Saga 实现的分布式事务 Saga 并不是一个新概念，其相关论文在 1987 年就发布了，和 XA 两阶段提交规范出现的时间差不多。Saga 和 TCC 一样，也是一种补偿事务，但是它没有 try 阶段，而是把分布式事务看作一组本地事务构成的事务链。 事务链中的每一个正向事务操作，都对应一个可逆的事务操作。Saga 事务协调器负责按照顺序执行事务链中的分支事务，分支事务执行完毕，即释放资源。如果某个分支事务失败了，则按照反方向执行事务补偿操作。 基于事务消息实现的分布式事务 基于 MQ 的分布式事务解决方案，适用于对最终一致性敏感度较低的业务场景，例如跨企业的系统间的调用，适用的场景有限。 基于 XA 协议的二阶段提交协议方法和三阶段提交协议方法，采用了强一致性，遵从 ACID，基于消息的最终一致性方法，采用了最终一致性，遵从 BASE 理论。之所以有这么多解决方案，是因为任何事情都没有银弹，只有最合适当前场景的解决方案。 各种各样的分布式事务解决方案已经超出了本文的范围，如果大家希望进一步了解分布式事务解决方案，可以吧“安排”打在公屏上，三此君就会尽快为大家安排。本文的目的还是分享 RocketMQ 的事务消息，而事务消息本身是基于 2PC 思想的，故本文只会带大家了解必要的 2PC 相关内容。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:2:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"XA/2PC XA（XA 是 eXtended Architecture 的缩写） 规范中定义了分布式事务处理模型，这个模型中包含三个核心角色： RM (Resource Managers)：资源管理器，提供数据资源的操作、管理接口，保证数据的一致性和完整性。最有代表性的就是数据库管理系统，当然有的文件系统、MQ 系统也可以看作 RM。 TM (Transaction Managers)：事务管理器，是一个协调者的角色，协调跨库事务关联的所有 RM 的行为。 AP (Application Program)：应用程序，按照业务规则调用 RM 接口来完成对业务模型数据的变更，当数据的变更涉及多个 RM 且要保证事务时，AP 就会通过 TM 来定义事务的边界，TM 负责协调参与事务的各个 RM 一同完成一个全局事务。 XA 规范中分布式事务是构建在 RM 本地事务（此时本地事务被看作分支事务）的基础上的，TM 负责协调这些分支事务要么都成功提交、要么都回滚。 XA 规范把分布式事务处理过程划分为两个阶段，所以又叫两阶段提交协议（two phrase commit）： 1. 预备阶段 TM 记录事务开始日志，并询问各个 RM 是否可以执行提交准备操作。 RM 收到指令后，评估自己的状态，尝试执行本地事务的预备操作：预留资源，为资源加锁、执行操作等，但是并不提交事务，并等待 TM 的后续指令。如果尝试失败则告知 TM 本阶段执行失败并且回滚自己的操作，然后不再参与本次事务（以 MySQL 为例，这个阶段会完成资源的加锁，redo log 和 undo log 的写入）。 TM 收集 RM 的响应，记录事务准备完成日志。 2. 提交/回滚阶段 这个阶段根据上个阶段的协调结果发起事务的提交或者回滚操作。 如果所有 RM 在上一个步骤都返回执行成功，那么： TM 记录事务 commit 日志，并向所有 RM 发起事务提交指令。 RM 收到指令后，提交事务，释放资源，并向 TM 响应“提交完成”。 如果 TM 收到所有 RM 的响应，则记录事务结束日志。 如果有 RM 在上一个步骤中返回执行失败或者超时没有应答，则 TM 按照执行失败处理，那么： 记录事务 abort 日志，向所有 RM 发送事务回滚指令。 RM 收到指令后，回滚事务，释放资源，并向 TM 响应回滚完成。 如果 TM 收到所有 RM 的响应，则记录事务结束日志。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:2:3","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"RocketMQ 事务消息 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"事务消息流程概述 Apache RocketMQ 在 4.3.0 版中已经支持分布式事务消息，这里 RocketMQ 采用了 2PC 的思想来实现了提交事务消息，所以我们肯定可以在 RocketMQ 事务消息流程中看到预备阶段及提交/回滚两个阶段。同时RocketMQ增加一个补偿逻辑来处理二阶段超时或者失败的消息，如下图所示。 预备阶段 发送 Half 消息（也可以叫 prepare 消息）。 服务端响应消息写入结果。 根据发送结果执行本地事务（如果写入失败，此时 Half 消息对业务不可见，本地逻辑不执行）。 提交/回滚阶段 根据本地事务状态执行 Commit 或者 Rollback（Commit 操作生成消息索引，消息对消费者可见） 补偿机制 对没有 Commit/Rollback 的事务消息（pending 状态的消息），从服务端发起一次“回查” Producer 收到回查消息，检查回查消息对应的本地事务的状态 根据本地事务状态，重新 Commit 或者 Rollback ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"事务消息示例 public class TransactionProducer { public static void main(String[] args) throws MQClientException, InterruptedException { // 实例化事务监听器，主要用于执行本地事务，保存本地事务状态 TransactionListener transactionListener = new TransactionListenerImpl(); // 实例化事务消息生产者 TransactionMQProducer producer = new TransactionMQProducer(\"please_rename_unique_group_name\"); // 事务消息执行线程池 ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue\u003cRunnable\u003e(2000), new ThreadFactory() { @Override public Thread newThread(Runnable r) { Thread thread = new Thread(r); thread.setName(\"client-transaction-msg-check-thread\"); return thread; } }); producer.setExecutorService(executorService); producer.setTransactionListener(transactionListener); producer.start(); // 发送消息 String[] tags = new String[] {\"关注\", \"点赞\", \"收藏\", \"转发\", \"三连呀！\"}; for (int i = 0; i \u003c 10; i++) { try { Message msg = new Message(\"TopicTest1234\", tags[i % tags.length], \"KEY\" + i, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(\"%s%n\", sendResult); Thread.sleep(10); } catch (MQClientException | UnsupportedEncodingException e) { e.printStackTrace(); } } for (int i = 0; i \u003c 100000; i++) { Thread.sleep(1000); } producer.shutdown(); } } // 实现 TransactionListener，即实现TransactionListener定义的两个方法：executeLocalTransaction和checkLocalTransaction public class TransactionListenerImpl implements TransactionListener { private AtomicInteger transactionIndex = new AtomicInteger(0); private ConcurrentHashMap\u003cString, Integer\u003e localTrans = new ConcurrentHashMap\u003c\u003e(); // 执行本地事务 @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { int value = transactionIndex.getAndIncrement(); int status = value % 3; localTrans.put(msg.getTransactionId(), status); return LocalTransactionState.UNKNOW; } // 查询本地事务状态 @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) { Integer status = localTrans.get(msg.getTransactionId()); if (null != status) { switch (status) { case 0: return LocalTransactionState.UNKNOW; case 1: return LocalTransactionState.COMMIT_MESSAGE; case 2: return LocalTransactionState.ROLLBACK_MESSAGE; } } return LocalTransactionState.COMMIT_MESSAGE; } } 从 RocketMQ 的事务消息示例中，我们可以知道事务消息的入口在 producer.sendMessageInTransaction，然后实现了TransactionListener.executeLocalTransaction 用于执行本地事务，TransactionListener.checkLocalTransaction 用于查询本地事务状态。这些方法在什么时候被调用？和我们上面提到的流程有什么关系？又是如何保证分布式事务的正确的？ ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"事务消息实现 下图已经总结了我们本文要讲的 RocketMQ 事务消息预提交、提交/回滚及回查的流程及原理，3 个 ⭐ 标注的地方就是三个阶段的入口，我们分别来看看这三个流程： ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:3","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"预备阶段 预备阶段主要的目标就是发送 Half 消息并执行本地事务： 首先调用了 TransactionMQProducer.sendMessageInTransaction 方法发送事务消息，其实消息的发送存储流程都大同小异。一阶段的消息对用户是不可见的，RocketMQ 将一阶段的 Half 消息存入用户不可见的 RMQ_SYS_TRANS_HALF_TOPIC 主题，这是 RocketMQ 的惯用伎俩之一（延迟消息就是这样）。 那么RocketMQ 怎么知道要存入 RMQ_SYS_TRANS_HALF_TOPIC (下文简称 HALF_TOPIC) 还是消息原来的 Topic ？所以我们在发送事务消息的时候要标识这是事务消息。DefaultMQProducerImpl.sendMessageInTransaction 方法中设置 TRAN_MSG = true 和PGROUP，分别表示消息为prepare消息、消息所属消息生产者组。 DefaultMQProducerImpl.sendKernelImpl 根据 TRAN_MSG 判断是否是事务消息，是则设置 sysFlag 系统标记为MessageSysFlag.TRANSACTION_PREPARED_TYPE，Broker 上判断事务消息会用到 sysFlag。 设置好系统标记之后，生产者就像发送普通消息一样调用 NettyRemotingClient 将消息发送给 Broker，Broker 收到请求，根据RequestCode.SEND_MESSAGE 调用 SendMessageProcessor.sendMessage 处理请求。 Broker 获取消息属性中 TRAN_MSG 属性，Flase 就走普通消息存储流程。如果为 True 则调用 TransactionalMessageService.prepareMessage 存入 Half 消息。 将原消息Topic 及 queueId 存入消息属性。Topic 替换为 RMQ_SYS_TRANS_HALF_TOPIC，queueId = 0 然后调用 DefaultMessageStore.putMessage 按普通消息的步骤存入prepare消息 RocketMQ 会开启一个定时任务从 Topic 为 HALF_TOPIC 中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。 Half 消息存入之后，Broker 将存储结果返回给 Producer，Producer 收到发送成功的结果就调用业务实现的TransactionListener.executeLocalTransaction 方法执行本地事务，并保存本地事务执行结果。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:4","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"提交/回滚 本地事务执行完成之后调用 DefaultMQProducerImpl.endTransaction 处理事务执行结果，其实就是 2PC 中的提交/回滚阶段。根据本地事务执行结果，向 Broker 发送 RequestCode.END_TRANSACTION 请求，告诉 Broker 是提交还是回滚。 Broker 收到请求，根据RequestCode.END_TRANSACTION找到 EndTransactionProcessor 处理事务结果。根据事务的不同状态做不同的处理。 如果事务状态为TRANSACTION_NOT_TYPE (UNKOWN) 直接返回 null，不做处理。 本地事务执行需要一定时间，Producer 在收到 half 消息存储结果时，本地事务状态通常都是 UNKOWN 的，也就是生产者此时发送的 RequestCode.END_TRANSACTION 请求不会做任何处理。那真正的提交在什么时候呢？ 事务状态为 TRANSACTION_COMMIT_TYPE 则进行事务提交，简单来说事务提交就是恢复消息原本的主题，并存入 CommitLog 及 ConsumerQueue，这样 Consumer 就可以正常消费。同时还需要将消息添加到 RMQ_SYS_TRANS_OP_HALF_TOPIC (下文简称 OP_TOPIC ) 中，标记当前的事务消息已经提交。 这里我们涉及了 3 个 Topic：在预提交阶段，我们将 Half 消息存入 HALF_TOPIC。在提交阶段我们有恢复了消息的原 Topic，并且在 OP_TOPIC 添加了一条消息，用于标记当前的事务消息已经提交。也就是如果消息在 OP_TOPIC 中存在就表名已经提交或回滚。 commitMessage：根据 offset 查询 Half 消息 从消息属性中恢复消息主题、消费队列，构建新的消息对象 sendFinalMessage：将第二步构建的消息存储入commitlog中，因为恢复了消息主题等参数，所以可以被消费者消费。 deletePrepareMessage：将 Half 消息存储到 RMQ_SYS_TRANS_OP_HALF_TOPIC 主题中，表示该事务消息已经处理过（提交或回滚） 事务状态为 TRANSACTION_ROLLBACK_TYPE 则进行回滚，回滚与提交类似，只是回滚无须恢复消息原主题，直接将消息存储在 OP_TOPIC 主题中，表示已处理过该消息。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:5","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"回查 本地事务执行完了需要将执行结果状态发送给 Broker，但是由于网络 NPC 问题，我们无法保证请求定会被正常接收。如果发生了网络错误，导致没有正常提交或者回滚要怎么处理呢？很多时候我们并不是怕发生问题，而且事实上问题总会发生，关键在于问题发生后我们采取什么样的措施。RocketMQ 解决这个问题的措施是增加补偿机制：定时回查本地事务状态，决定是提交还是回滚。 事务消息定时回查服务 TransactionalMessageCheckService 循环线程，默认每隔 60s 执行一次 TransactionalMessageCheckService.onWaitEnd，调用 TransactionalMessageService.check 执行回查。 获取所有 RMQ_SYS_TRANS_HALF_TOPIC 队列，即预提交消息队列 遍历预提交队列，每个队列处理 60s。 获取当前预提交队列对应的 RMQ_SYS_TRANS_OP_HALF_TOPIC，该主题队列用于记录已经提交或回滚的事务消息 获取 HALF、OP 队列当前进度 从 OP 队列拉取 32 条消息，因为 OP 消息记录事务已经被提交或回滚。 判断是否需要回查：主要根据消息有效时间、本地事务超时时间及消息是否在 OP 队列中 (OP队列中存在则已经提交或回滚，不需要回查)。如果无法判断是否回查，会从新拉取 32 条 OP 消息进行判断。 判断是否需要回查的逻辑及较为复杂，包含多个很多参数，但是最重要的就是是否在 OP 队列中，如果对其他细节感兴趣可以到源码中详细看看，三此君给大家添加了详细的备注。 调用 TransactionalMessageCheckListener.resolveHalfMsg 异步发送回查消息 更新 HALF、OP 处理进度 值得注意的是，rocketmq 并不会无休止的的信息事务状态回查，默认回查 15 次，如果 15 次回查还是无法得知事务状态，rocketmq 默认回滚该消息。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:6","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"远程事务 RocketMQ 的事务消息及时到这里就已经了解的差不多了，但是我看完官方文档，以及几本书上的内容后，总是觉得少了些什么？就这？怎么解决分布式事务问题的？回看前面的例子，例如生产者就是订单服务，现在下单成功了要发消息去库存服务减库存。 如何保证库存服务正常执行？只能基于 RocketMQ 的重试机制，默认重试 15 次后进入私信队列。通过重试尽可能保证库存服务执行成功。但是，万一就是库存本来就不够，库存扣减无法执行成功，但是订单服务又创建成功了怎么办？这就是基于 MQ 的分布式事务方法无能为力的地方，如果消费方执行出现问题，无法回滚生产者本第事务。 更有甚者 RocketMQ 出问题怎么办？我只能说凉拌炒鸡蛋。基于 MQ 的分布式事务消息，可以说是默认 MQ 本身是可靠的。 分布式事务各种解决方案有其自身的使用场景，没有一种方法能够完全解决分布式事务问题。 ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:3:7","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"参考文献 RocketMQ 官方文档 RocketMQ 源码 如何选择分布式事务解决方案？ 丁威, 周继锋. RocketMQ技术内幕：RocketMQ架构设计与实现原理. 机械工业出版社, 2019-01. 李伟. RocketMQ分布式消息中间件：核心原理与最佳实践. 电子工业出版社, 2020-08. 杨开元. RocketMQ实战与原理解析. 机械工业出版社, 2018-06. ","date":"2022-03-10","objectID":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:4:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","分布式事务","事务消息","2PC","XA","远程事务","提交","回滚"],"title":"RocketMQ 事务消息","uri":"/5.rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["RocketMQ"],"content":"前 言 大家好，我是三此君，一个在自我救赎之路上的非典型程序员。 “一张图”系列旨在通过“一张图”系统性的解析一个板块的知识点： 三此君向来不喜欢零零散散的知识点，通过一张图将零散的知识点连接起来，能够让我们对一个板块有更深入、更系统的理解。 同时本系列尽可能的精炼，希望能够让大家花 20% 的时间，快速理解这个板块下 80% 的内容。 本文是“一张图”系列的第一个板块：一张图解析 RocketMQ。 为了叙述的方便，绘图的时候将整个系列分为许多小的模块，讲解的时候也是按照模块循序渐进的。一张图解析 RocketMQ 原图 一张图解析 RocketMQ 是会深入到源码层面，但是文中不会粘贴源码。三此君在看源码的时候写了很多备注，可以降低大家看源码的难度，需要的同学自行到三此君的仓库中 Fork：rocketmq release-4.3.0 三此君经常会遇见这样的问题，理论学完觉得啥都会了，实践的时候又觉得啥都不会了。今天，我们通过一个真实的项目来看看 RocketMQ 在生产实践中如何使用，以及使用过程中会遇到什么问题，这些问题又如何解决？ 消息队列在生产实践中是很常见的中间件，甚至很多团队不管三七二十一，适不适用都往消息队列里面扔。我们也无法穷尽消息队列的所有场景及问题，所以本文只是通过一个简单的项目，演示 RocketMQ 的应用及问题。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:1:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"项目概述 今天分享的项目几乎是每个应用都会有的模块，每个人都用过，甚至会让有些人产生“恐惧”。这个项目就是消息中心，也就是给大家发消息的，如果还觉得不熟悉的话我提醒下你，你的应用是不是有个红点（有的还有数字），你是不是经常收到 Xxx 应用给你发送的短信/邮件？这些就是消息中心要做的事儿，给大家发消息。 消息中心的业务逻辑很简单，就是根据各个业务放的需求，按照模块，给用户发送消息。而消息可能是短信、邮件、站内信、推送通知（屏幕下滑出现的消息）、微信推送等各种渠道的消息，消息的类型也可以氛围营销、账号、验证码等。 首先是一些声明：本项目是三此君根据 Java3y 的 austin 项目修改而来，用于演示 RocketMQ 项目实践及问题，主要修改点如下： kafka 替换为 RocketMQ。 为了展示 RocketMQ 项目实践及问题，尽量减少依赖项，故去掉 Apollo/xxl-job/graylog 等依赖。 简化部署，更改 docker 模块，只需要一个命令即可部署好所有依赖的中间件。 简化部署，austin/austin-admin 合并。 去掉原有的业务上的去重逻辑，新增 通用幂等/重试 实现。 消费堆积处理 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:2:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"1、整体架构 我们先来看看消息通知的整体架构。这里只体现一些和消息中心自身强相关的组件或服务，要应用与实际生产环境中，肯定还有注册中心，监控告警，链路追踪等一系列微服务基础设施。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:2:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"2、整体流程 业务方 business service 调用 austin 消息发送接口（指定消息模板 ID 及接受者等参数），austin 调用 RocketMQ Producer API 将消息发送到 RocketMQ Broker。消费者消费消息并生成消息发送 Task 放入线程池中。线程被调度执行，不同渠道的消息使用不同的 Handler，Handler 调用三方服务发送消息。 项目的具体实现细节三此君就不在此赘述了，大家可以获取源码，根据上面的流程图看就行。如果对实现有任何问题可以留言或者加三此君微信私聊。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:2:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"项目部署 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:3:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"1、获取源码 GitHub：https://github.com/sancijun/austin.git Gitee： ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:3:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"2、安装 Docker 及 docker-compose Windows 安装 Docker MacOS 安装 Docker ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:3:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"3、安装中间件 进入项目 docker 目录，执行 docker-compose up -d，等待镜像下载，容器启动。你获取不了解 Docker 及 docker-compose，但是并不影响，我们只是方便大家部署，部署好之正常使用就行。启动之后可在 docker dashboard 查看相关容器： mysql: 127.0.0.1:13306 username: root password:（空） redis: 127.0.0.1：:6379 username: （空） password:（空） rocketmq-broker: 127.0.0.1:10909 rocketmq-namesrv: 127.0.0.1:9876 rocketmq-console: 127.0.0.1:8081 （访问 127.0.0.1:8081 即可查看 RocketMQ 控制台） ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:3:3","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"4、启动 austin-web 修改 austin-web/src/main/resources/application.properties 配置，打包启动即可。 需要特别说明的是，SMS、WeChat 渠道的接入会比较麻烦，只是为了加深对 RocketMQ 的理解的话，可以只接入 Email。接入 Email 的方式很简单，以 QQ 邮箱为例：进入 QQ 邮箱-\u003e点击设置-\u003e账号-\u003e开启 POP3/SMTP 服务-\u003e生成 Token； 替换 application.properties 中邮箱相关配置 account.emailAccount account.emailAccount = [{\"email_10\":{\"host\":\"smtp.qq.com\",\"port\":465,\"user\":\"your_email\",\"pass\":\"your_token\",\"from\":\"your_email\"}}] ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:3:4","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"5、启动 austin-admin 进入 austin-admin 目录，执行以下命令： # 安装依赖 npm i # 打开服务 npm start 访问 localhost:3000 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:3:5","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"6、验证 可以直接在 austin-admin 上点击测试，也可以使用 postman 调用接口，查看消息是否正常发送。 到这里，我们大致了解了 austin 项目，也能够正常的收到消息了。一切都是那么顺利，但是直觉告诉三此君，《没那么简单》。我发送的消息要是没送到怎么办？是因为生产者的问题还是 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:3:6","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"通用幂等 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:4:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"1、存在问题 网络二将军问题的存在使得消息的发送者往往要重复发送消息，直到收到接收者的确认才认为发送成功，但这往往又会导致消息的重复发送。由于网络二将军问题的存在，RocketMQ 需要通过重试保证消息的可靠性，也因此 RocketMQ 无法避免消息重复（Exactly-Once）。消息中心是重度依赖 RocketMQ 的能力，可能出现重复发送消息等问题，因此需要实现消费幂等。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:4:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"2、MySQL 排重表 业务唯一标识：可以借助关系数据库进行去重。首先需要确定消息的唯一键，根据消息中心目前实现没有合适的字段可以作为唯一标识。 1.部分接口有requestMsgId字段，是上游业务传过来的随机数，当前用于接口层面的防重。但是requestMsgId本身跟业务唯一性没有关系，并且RocketMQ消费者测试没有针对requestMsgId做处理。 2.每条消息会有 messageId，当前的实现方式是 UUID。简单的改造 messageId = SHA256(message content+telephone/uid/email/fcmToken+timestamp)，在同一时间，同一用户，相同的内容应该不会重复发送（业务唯一）。以messageId为唯一key实现排重。 3.message #1.开始事务begin;#2.插入消息表（处理好主键冲突的问题）insertintomsg_center_tab_xxxvalues(messageId,...)#3.提交事务commit; 实现问题： 1.消息的消费逻辑必须是依赖于关系型数据库事务。如果消费的消费过程中还涉及其他数据的修改，例如Redis这种不支持事务特性的数据源，则这些数据是不可回滚的。 2.不是通用方案：如果其他模块有需要处理幂等的地方，每个模块需要单独处理。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:4:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"3、Redis 记录消息状态 1）以业务唯一标识 messageId 为 Key 从 Redis 获取消息记录状态，如果在是消费中则延迟消费，消费成功则直接返回成功。 2）如果消息记录不存在，则先将消息记录到Redis, 业务唯一标识为key，消息状态为消费中，需要加入合理的过期时间； 3）插入消息记录成功后执行原有的业务逻辑，执行失败的话删除消息表记录； ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:4:3","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"4、幂等实现 幂等注解 @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Idempotent { /** 幂等 Redis Key 前缀，用于区分业务*/ String prefix() default \"\"; /** 组成幂等 Key 的参数，通过拼接前缀及参数生成幂等业务唯一key*/ String[] params() default {}; /** 如果接口有多个参数，需要指定subKeys包含在哪个目标参数中 */ String target() default \"\"; } 幂等切面 @Around(\"@annotation(com.shopee.banking.annotation.Idempotent)\") public Object around(ProceedingJoinPoint joinPoint) throws Throwable { try { Integer status = 0; // 1.获取参数生成业务唯一标识 key，从 Redis 获取消息记录状态 String key = getUniqueKey(joinPoint); // 2.插入消费状态记录 boolean first = redisTemplate.opsForValue().setIfAbsent(key,status,60*60, TimeUnit.SECONDS); // 3.插入不成功：消费成功则直接返回，消费不成功则抛出异常； // 4.执行业务代码 Object result = joinPoint.proceed(); // 5.设置为消费成功 redisTemplate.opsForValue().set(key, 1); return result; } catch (Throwable throwable) { // 6.消费失败删除消息状态记录，等待重试 String key = getUniqueKey(joinPoint); redisTemplate.delete(key); throw throwable; } } ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:4:4","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"消息堆积 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:5:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"1、背景 “2021-09-29 20:12，local反馈用户没有收到 Email OTP，通过监控面板发现，kafka消息堆积了约32w的消息”。原因是批量发送了大量消息，并且Email OTP 这样高优先级的消息和批量的不重要消息没有做区分。消息堆积后，重要的消息也无法正常发送。 这个问题 ID 市场已经临时处理。短期方案通过增加 kafka 分区数，增加消费者线程数处理堆积消息；长期方案将消息模板按优先级区分，高优先级和低优先级的消息通知通过topic隔离，互不影响。 目前 ID 市场就 2021-09-29 的消息堆积问题解决方案已经较为完善，但是 PH 市场 kafka 切换 RocketMQ，消息队列本身的特性不一致，如果再遇到消息堆积问题又如何处理呢？针对消息堆积还有没有其他的问题呢？同时本次事故除了消息堆积，还有个很重要的关注点是普通消息堆积，影响了重要的消息发送。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:5:1","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"2、消息堆积原因 消息处理流程中，如果客户端的消费速度跟不上服务端的发送速度，未处理的消息会越来越多，这部分消息就被称为堆积消息。RocketMQ DefaultPushConsumer 通过长轮询从 Broker 拉取消息，缓存到本地，再提交给业务线程。 Broker 消息堆积：主要关注下 Broker 端消息堆积的情况。Broker 端消息堆积是由于消息的生产和消费速度不匹配了，通常是由于客户端的消费能力不足。而客户端消费能力不足通常是由于受 消费耗时 和 消费并行度 影响。想要避免和解决消息堆积问题，必须合理的控制消费耗时和消息并发度，其中消费耗时的优先级高于消费并发度，必须先保证消费耗时的合理性，再考虑消费并发度问题。 客户端消息堆积：客户端堆积我们不经常遇到，RocketMQ 的消息堆积 这篇文档记录了客户端消息堆积的内容。简单来说就是，存在1 个消费者实例负责消费 n 个 ConsumeQueue，Push 消费模式消是 RocketMQ 将消息拉倒本地放在缓存里（每次消息量大于100M会执行流控）。那么，n 个 线程同时拉取 100M 的消息缓存到本地，本地的消息就会堆积了。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:5:2","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"3、消息堆积解决方案 避免消息堆积和延迟（事前） 为了避免在业务使用时出现非预期的消息堆积和延迟问题，您需要在前期设计阶段对整个业务逻辑进行完善的排查和梳理。整理出正常业务运行场景下的性能基线，才能在故障场景下迅速定位到阻塞点。其中最重要的就是梳理消息的消费耗时和消息消费的并发度。 梳理消息的消费耗时 通过压测获取消息的消费耗时，并对耗时较高的操作的代码逻辑进行分析。查询消费耗时，请参见获取消息消费耗时。梳理消息的消费耗时需要关注以下信息： 消息消费逻辑的计算复杂度是否过高，代码是否存在无限循环和递归等缺陷。 消息消费逻辑中的I/O操作（如：外部调用、读写存储等）是否是必须的，能否用本地缓存等方案规避。 消费逻辑中的复杂耗时的操作是否可以做异步化处理，如果可以是否会造成逻辑错乱（消费完成但异步操作未完成）。 设置消息的消费并发度 逐步调大线程的单个节点的线程数，并观测节点的系统指标，得到单个节点最优的消费线程数和消息吞吐量。 得到单个节点的最优线程数和消息吞吐量后，根据上下游链路的流量峰值计算出需要设置的节点数，节点数=流量峰值/单线程消息吞吐量。 队列及消费者实例扩容（事中） RocketMQ 可以扩容 ComsumeQueue 及增加消费者线程数。 但是只是扩容 ConsumeQueue 及线程数对于已经堆积的消息是没有用的，因为已经堆积的消息本身还是存储在原来的 ConsumeQueue 中。而根据 RocketMQ 消费者负载均衡策略（默认平均分配），同一个 ConsumeQueue 中的消息只会被同一个消费者组中的一个实例消费。例如：原本有4个 ConsumeQueue，扩容到 16 个ConsumeQueue，根据负载策略。原本的消息所在的 4 个ConsumeQueue 依然最多只能被 4 个消费者实例消费。短时间内堆积的消息还是无法。针对以上问题，可以考虑如下方案： 方案一：如果消息是可以被丢弃的，在 rocketmq-comsole 可以重置消费位移。 方案二：首先我们要评估在 Topic 创建的时候就设置足够的 ConsumeQueue。那么 Topic 中 MessageQueue 的数量大于 Consumer 的实例数量，可以将 Consumer 扩容，MessageQueue 会进行 Rebalance 重新分配给 Consumer 实例，此时多个 Consumer 实例可以迅速消费掉堆积的消息，但是要考虑到的后续如果业务是否能够支撑突增的并发量。 方案三：出现消息大量堆积，并且 Topic 中 MessageQueue 的数量小于 Consumer 的实例数量，也就是上面描述的问题，仅仅增加 Consumer 是无效的。可以执行步骤： 消费者入口增加 comsume.accumulation.exception.swtch，默认为 false。当开关开启时，不执行具体的消费逻辑，直接将消息发回到原有的 topic。 当遇到消息严重堆积时，先执行 ConsumeQueue 动态扩容，接着执行 Consume 扩容，增加消费线程数，然后打开 comsume.accumulation.exception.swtch 开关时消息平均分配到扩容后的 ConsumeQueue 中。 当存量的消息均匀分布在扩容后的 ConsumeQueue 时关闭开关，扩容后的 Consumer 根据负载策略可以较好的消费存量消息了。 线上排查消费耗时（事中） 有很多可以参考的资料，这里就不复制粘贴了。 如何处理消息堆积：https://help.aliyun.com/document_detail/193952.htm?spm=a2c4g.11186623.0.0.52cc466csEvAYq#trouble-2004065 Arthas 用户文档：https://arthas.aliyun.com/doc/ 综上，消息堆积通常由于消费者耗时和消费者并行度问题。为了避免消息堆积，在编码的时候应该详细评估消费者代码性能瓶颈，优化单此消费本身耗时。如果出现消息堆积大量堆积问题，根据情况不同有三种了应急策略：直接丢弃堆积消息，扩容消费者实例，ConsumeQueue 和 Consumer 同时扩容，并且将堆积的消息平均分布到扩容后的 ConsumeQueue。在应急之后还是应该分析耗时原因，具体是代码本身耗时，关联耗时？落到根本还是要解决消费者耗时问题上。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:5:3","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"消息堆积 1. 提高消费并行度 绝大部分消息消费行为都属于 IO 密集型，即可能是操作数据库，或者调用 RPC，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法： 同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。 提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax 实现。 2. 批量方式消费 某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量，例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可大幅度提高消费的吞吐量，通过设置 consumer 的 consumeMessageBatchMaxSize 返个参数，默认是 1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。 3. 跳过非重要消息 发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。例如，当某个队列的消息数堆积到 100000 条以上，则尝试丢弃部分或全部消息，这样就可以快速追上发送消息的速度。示例代码如下： public ConsumeConcurrentlyStatus consumeMessage( List\u003cMessageExt\u003e msgs, ConsumeConcurrentlyContext context) { long offset = msgs.get(0).getQueueOffset(); String maxOffset = msgs.get(0).getProperty(Message.PROPERTY_MAX_OFFSET); long diff = Long.parseLong(maxOffset) - offset; if (diff \u003e 100000) { // TODO 消息堆积情况的特殊处理 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } // TODO 正常消费过程 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } 4. 优化每条消息消费过程 举例如下，某条消息的消费过程如下： 根据消息从 DB 查询【数据 1】 根据消息从 DB 查询【数据 2】 复杂的业务计算 向 DB 插入【数据 3】 向 DB 插入【数据 4】 这条消息的消费过程中有 4 次与 DB 的 交互，如果按照每次 5ms 计算，那么总共耗时 20ms，假设业务计算耗时 5ms，那么总过耗时 25ms，所以如果能把 4 次 DB 交互优化为 2 次，那么总耗时就可以优化到 15ms，即总体性能提高了 40%。所以应用如果对时延敏感的话，可以把 DB 部署在 SSD 硬盘，相比于 SCSI 磁盘，前者的 RT 会小很多。 ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:6:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"categories":["RocketMQ"],"content":"参考文献 RocketMQ 官方文档 丁威, 周继锋. RocketMQ技术内幕：RocketMQ架构设计与实现原理. 机械工业出版社, 2019-01. 李伟. RocketMQ分布式消息中间件：核心原理与最佳实践. 电子工业出版社, 2020-08. 杨开元. RocketMQ实战与原理解析. 机械工业出版社, 2018-06. ","date":"2022-03-10","objectID":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/:7:0","tags":["RocketMQ","MQ","消息队列","消息中间件","kafka","项目实践","消息中心","重试","幂等","消息堆积"],"title":"RocketMQ 项目实践","uri":"/6.-rocketmq-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"}]