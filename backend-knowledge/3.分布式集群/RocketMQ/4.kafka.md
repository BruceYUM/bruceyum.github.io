# Kafka


[toc]


## 是什么

Kafkav是一个分布式的、可分区的、可复制的、基于发布/订阅的消息系统
1. Apache Kafka 是一个开源消息系统，由 Scala 写成。是由 Apache 软件基金会开发的一个开源消息系统项目。
2. Kafka 最初是由 LinkedIn 公司开发，并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。
3. Kafka 是一个分布式消息队列。Kafka 对消息保存时根据 Topic 进行归类，发送消息者称为 Producer，消息接受者称为 Consumer，此外 kafka 集群有多个 kafka 实例组成，每个实例(server)称为 broker。 
4. 无论是 kafka 集群，还是 consumer 都依赖于 zookeeper 集群保存一些 meta 信息，来保证系统可用性。


## 架构及工作流程

### 1、整体架构

![img](http://kityminder-img.gz.bcebos.com/123977958bd2b2b3c23fd1cc00ea27104a99db5c)

1. Producer ：消息生产者，就是向 kafka broker 发消息的客户端；
2. Consumer ：消息消费者，向 kafka broker 取消息的客户端；
3. Topic ：消息的主题、队列，每一个消息都有它的topic，Kafka通过topic对消息进行归类。Kafka中可以将Topic从物理上划分成一个或多个分区（Partition），每个分区在物理上对应一个文件夹，以”topicName_partitionIndex”的命名方式命名，该dir包含了这个分区的所有消息(.log)和索引文件(.index)，这使得Kafka的吞吐率可以水平扩展。
4. Consumer Group （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 CG。topic 的消息会复制（不是真的复制，是概念上的）到所有的 CG，但每个 partion 只会把消息发给该 CG 中的一个 consumer。如果需要实现广播，只要每个 consumer 有一个独立的 CG 就可以了。要实现单播只要所有的 consumer 在同一个 CG。用 CG 还可以将 consumer 进行自由的分组而不需要多次发送消息到不同的 topic；
5. Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个 topic；
6. Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的 id（offset）。kafka 只保证按一个 partition 中的顺序将消息发给consumer，不保证一个 topic 的整体（多个 partition 间）的顺序；
7. Offset：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是 00000000000.kafka。


### 2、消息存储

**1. 存储方式**

1. Kafka 数据存储 topic 中，一个 topic 标识一个队列：
2. topic 分成一个或多个 patition
3. 一个 partition 可以有多个副本
在物理上在数据存在 broker 上，一个 broker 就是集群中的一个节点；

**2. 分区**

每个分区都是一个 顺序的、不可变的消息队列， 并且可以持续的添加;分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。 producer 在发布消息的时候，可以为每条消息指定Key，这样消息被发送到 broker 时，会根据分区算法把消息存储到对应的分区中（一个分区存储多个消息），如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡。
物理上把 topic 分成一个或多个 patition（对应 server.properties 中的 num.partitions=3 配置），每个 patition 物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件）
每个 Partition 中的消息都是有序的，生产的消息被不断追加到 Partition log 上，其中的每一个消息都被赋予了一个唯一的 offset 值。

**3. 分区原因**

1. 方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic 又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；
2. 可以提高并发，因为可以以 Partition 为单位读写了。

**4. 分区原则**

1. 指定了 patition，则直接使用； 
2. 未指定 patition 但指定 key，通过对 key 的 value 进行 hash 出一个 patition； 
3. patition 和 key 都未指定，使用轮询选出一个 patition。

**5. 副本**

同 一 个 partition 可 能 会 有 多 个 replication （ 对 应 server.properties 配 置 中 的default.replication.factor=N）。没有 replication 的情况下，一旦 broker 宕机，其上所有 patition的数据都不可被消费，同时 producer 也不能再将数据存于其上的 patition。引入 replication之后，同一个 partition 可能会有多个 replication，而这时需要在这些 replication 之间选出一个 leader，producer 和 consumer 只与这个 leader 交互，其它 replication 作为 follower 从 leader 中复制数据。

**6. 存储策略**

无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：
1. 基于时间：log.retention.hours=168
2. 基于大小：log.retention.bytes=1073741824
需要注意的是，因为 Kafka 读取特定消息的时间复杂度为 O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。

**7. zookeeper节点结构**

![img](https://kityminder-img.gz.bcebos.com/a5ebf3493a612bc9cf825e7ec60869b0b9f7ae69)

### 3、消息生产

[消息写入流程](https://mp.weixin.qq.com/s/zxPz_aFEMrshApZQ727h4g)
producer 采用推（push）模式将消息发布到 broker，每条消息都被追加（append）到分区（patition）中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。

**写入流程**

![img](https://kityminder-img.gz.bcebos.com/5d1e4c21d5d2025124174122076dac1c9158f70d)

1. 序列化消息&&.计算partition
	将消息序列化，计算对应的partition
2. 发送到batch&&唤醒Sender 线程
	根据topic-partition获取对应的batchs（Dueue\<ProducerBatch>），然后将消息append到batch中.如果有batch满了则唤醒Sender 线程。队列的操作是加锁执行，所以batch内消息时有序的。后续的Sender操作当前方法异步操作。
3. 从zookeeper确定tp relica leader 所在的broker
4. 幂等发送到broker
	为实现Producer的幂等性，Kafka引入了Producer ID（即PID）和Sequence Number。对于每个PID，该Producer发送消息的每个<Topic, Partition>都对应一个单调递增的Sequence Number。同样，Broker端也会为每个<PID, Topic, Partition>维护一个序号，并且每Commit一条消息时将其对应序号递增。对于接收的每条消息，如果其序号比Broker维护的序号）大一，则Broker会接受它，否则将其丢弃：
- 如果消息序号比Broker维护的序号差值比一大，说明中间有数据尚未写入，即乱序，此时Broker拒绝该消息，Producer抛出InvalidSequenceNumber
- 如果消息序号小于等于Broker维护的序号，说明该消息已被保存，即为重复消息，Broker直接丢弃该消息，Producer抛出DuplicateSequenceNumber
- Sender发送失败后会重试，这样可以保证每个消息都被发送到broker
5. 消息同步replicas
	ack：producer收到多少broker的答复才算真的发送成功
	0： 表示producer无需等待leader的确认(吞吐最高、数据可靠性最差)
	1： 代表需要leader确认写入它的本地log并立即确认
	-1/all： 代表所有的ISR都完成后确认(吞吐最低、数据可靠性最高)
6. Sender处理broker发来的produce response
	一旦broker处理完Sender的produce请求，就会发送produce response给Sender，此时producer将执行我们为send（）设置的回调函数。至此producer的send执行完毕。


### 4、消息消费

![img](https://kityminder-img.gz.bcebos.com/9336b44d2683f4f27b878b8734cb17cadee8c2bd)

- 消费者通过fetch线程拉消息（单线程）
- 消费者通过心跳线程来与broker发送心跳。超时会认为挂掉
- 每个consumer group在broker上都有一个coordnator来管理，消费者加入和退出，以及消费消息的位移都由coordnator处理。

consumer 采用 pull（拉）模式从 broker 中读取数据。

push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。

对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。

pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）。


## 怎么用

### 1、集群部署

1. 解压安装包
$ tar -zxvf kafka_2.11-0.11.0.0.tgz -C /opt/module/
2. 修改解压后的文件名称
$ mv kafka_2.11-0.11.0.0/ kafka
3. 在/opt/module/kafka 目录下创建 logs 文件夹
$ mkdir logs
4. 修改配置文件
$ cd config/
$ vi server.properties
5. 在及群众的机器重复以上操作
6. 启动集群
$ bin/kafka-server-start.sh config/server.properties &

### 2、配置文件

```
#broker 的全局唯一编号，不能重复
broker.id=0
#删除 topic 功能使能
delete.topic.enable=true
#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘 IO 的现成数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600 #kafka 运行日志存放的路径
log.dirs=/opt/module/kafka/logs
#topic 在当前 broker 上的分区个数
num.partitions=1
#用来恢复和清理 data 下数据的线程数量
num.recovery.threads.per.data.dir=1
#zookeeper配置
zookeeper.connect=192.168.100.128:2181,192.168.100.129:2181,192.168.100.130:2181
```

### 3、命令行操作

1. 查看当前服务器中的所有 topic
$ bin/kafka-topics.sh --zookeeper 192.168.100.128:2181 --list
2. 创建 topic
$ bin/kafka-topics.sh --zookeeper 192.168.100.128:2181 \--create --replication-factor 3 --partitions 1 --topic first
选项说明：
* --topic 定义 topic 名
* --replication-factor 定义副本数
* --partitions 定义分区数
3. 删除 topic
$ bin/kafka-topics.sh --zookeeper 192.168.100.128:2181 \ --delete --topic first需要server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启。
4. 发送消息
$ bin/kafka-console-producer.sh \ --broker-list 192.168.100.128:2181 --topic first
\>hello world
5. 消费消息
$ bin/kafka-console-consumer.sh \ --zookeeper 192.168.100.128:2181 --from-beginning --topic first--from-beginning：会把 first 主题中以往所有的据都读取出来。根据业务场景选择是 否增加该配置。
6. 查看某个 Topic 的详情
$ bin/kafka-topics.sh --zookeeper 192.168.100.128:2181 \--describe --topic first
