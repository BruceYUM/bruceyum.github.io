# 快应用服务治理

[toc]

## 服务治理概述
度量、管控、管理三位一体

一、服务度量
开发度量：调用链
测试度量：单测
运维度量：监控，系统监控，应用监控（埋点/采集/缓存/实时分析/存储/离线分析），动态调用链跟踪

二、服务管控
服务的内部管控，包括服务负载策略调整、服务限流、服务降级、服务熔断和服务授权等；服务生命周期管理，包括服务的部署、服务扩缩容及服务下线等。

## 服务度量理论
服务度量的核心指标及相关的采集、聚合、分析方法，并从不同维度对微服务线上状态进行全面的分析和评估。
最基础的度量指标共三个：调用量、调用延时和异常。
单个服务某次请求，一分钟请求，一段时间的请求统计：调用链：调用者是谁，被调用者是谁，在什么时间，调用动作是什么，结果如何。
服务与服务，服务与资源之间的调用统计；

### 服务关系维度

服务的整体调用关系进行定期梳理和优化，并达到如下治理目标：避免循环调用；梳理集中调用；避免深度调用；梳理冗余服务；优化资源配置；根据服务的重要性，进行分级运维；

1.服务基础视图：服务列表及详情
服务ID、接口、负责人、服务提供者及消费者的统计量、服务所属应用等
2.服务调用关系视图：调用链
通过服务注册中心中的服务注册信息获取微服务的调用关系，虽然通过服务注册中心获取微服务调用关系是最经济的途径，但获取完整的接口级信息是有前提条件和限制的。
通过APM的动态调用链分析获取微服务的调用关系。
通过扫描源码仓库的全部工程源码，梳理出方法级的调用矩阵，在此基础上梳理出微服务和微服务接口之间的调用子集，即微服务的静态调用链。
单个服务调用关系视图：调用与被调用关系
整体服务调用拓扑视图：目前大部分公司都通过动态调用链汇总来勾画这个图，此外还可以基于静态调用链（调用矩阵）来获得。

通过调用关系图分析可以进行病患检测，最长调用链检测，集中调用检测，冗余服务检测

### 应用关系维度
基于“应用”来关联各种与业务无直接关系、相对独立的基础设施和组件，比如机器资源、域名、DB、缓存、消息队列等，勾画以应用为中心的运维统一视图。 梳理应用调用关系； 梳理应用重要性，运维分级保障； 清理冗余应用；勾画微服务架构下以应用为中心的运维统一视图。

单应用调用视图
整体应用调用拓扑图
以应用为中心的运维统一视图：应用除了必需的主机和IP等部署资源，在正常运行过程中还会和其他诸如数据库、消息队列、分布式缓存等基础资源创建各种连接关系。

### 服务性能维度
服务的调用延时、调用异常等基本指标数据，以及这些指标的分钟、小时、天、月等的汇总报表数据。在此基础上做进一步的服务线上性能和健康度度量及分析，并制定相应的管控策略，最终实现如下治理目标：
梳理资源占用，降低单点负载；
梳理集中调用，避免调用瓶颈；
优化调用性能；
提高线上服务的健康度及稳定性。

1. 调用耗时分区分布统计：将调用耗时根据时间长短划分成固定的若干区间，将一个时间维度（一分钟、一小时、一天）内针对某个服务的所有调用请求按这些区间进行汇总统计
2. 调用量/并发量分时分布统计
3. 调用耗时分时分布统计
4. 性能横比：多个服务在某些度量指标上的横向比较，用于发现需要重点关注的服务；
5. 性能纵比：单个服务在某些指标时间序列上的纵向比较，或者相同时间端同比，用于发现时间序列上的特性，趋势预估等
6. 综合性能分析：系统指标和服务指标综合度量
7. 容量规划：基于往年的访问量和经验，以及对业务前景及推广力度的评估给出访问量的合理预期指标；基于依赖关系逐层推进的性能压测，性能压测要秉持由点及线、再及面的策略
8. 动态阈值：
9. 趋势预测：

### 服务异常维度
故障种类繁多，更复杂的是，异常还存在向上传导和向外蔓延的特征，在微服务架构下，异常的检测、度量、定位、解决注定不是一件容易的事情。
故障定界定位，解决线上问题；
故障根因分析，消除系统隐患；
通过业务异常排查用户痛点，改进业务设计质量；
通过业务异常排查系统业务漏洞，防范灰产攻击；
1.实时异常报表：将日志中心（数据仓库）的最新时间刻度的异常指标按异常类型进行汇总，并按数据量进行降序排序；
2.异常分布报表：
3.异常列表及查询：
4.故障定界定位：基于调用关系的故障定界定位；基于运维变更事件（发版，修改配置等）的故障定界定位
5.智能根因分析：将服务和服务之间的调用关系、服务对资源的调用关系、服务及资源所依赖环境之间的关系都画在立体关系网络图中。以某个包含异常的节点为起点，顺着调用方向或者依赖方向进行逐级查找，一直找到无异常的正常节点为止，或者找到只有进入线没有出去线的节点为止。这样就可以找出连续包含异常指标的子网络，这个子网络的末梢节点，大概率就是故障传导链条的起点，该起点上的异常指标也就是所谓的故障“根因”。如果这个“根因”是一个应用异常，还要看它有没有记录异常堆栈，如果有，则查找最后一个异常（通常为真正的故障原因）。当然，这只是最基本的算法，在实际应用中，往往还要结合故障的种类、故障严重等级权重、故障发生的时间顺序来提高查找的精度或做最终根因判定。
6.业务异常分析：微服务框架上增加一个调用拦截器记录业务异常，用于业务质量监控、异常行为防控等。

### 调用链跟踪原理

性能管理（Application Performance Management，APM）技术体系，主要是指针对企业关键业务的IT应用性能和用户体验的监测、优化，提高企业IT应用的可靠性和质量，保证用户得到良好的服务，降低IT总拥有成本（TCO）。调用链跟踪是APM的核心能力。

**1.Google Dapper**：核心的三个定义是traceId、spanId、parentId。
在一个请求刚发起的时候，调用链会赋予它一个跟踪号（traceId），这个跟踪号会随着请求穿越不同的网络节点，并随日志落盘。每个Span包含一个spanId和parentId，spanId是当前服务调用过程的唯一标识，如果当前服务又调用了一个远程服务，则当前服务调用的spanId就成了远程服务调用的parentId。一个没有parentId的Span就是Root Span，是调用链的入口。根据traceId对收集的日志做聚合找到所有的关联日志，然后通过parentId和spanId排序，构建出这个请求跨网络的调用链（Trace），它能详细描述请求的整个生命周期的状况。spanId有两种常见的命名方式，一种采用类UUID编码，另一种采用诸如“0.1.2.3”这样的层级结构编码。

CS（Client Send）：客户端发起请求的时间，比如Dubbo调用端开始执行远程调用之前； CR（Client Receive）：客户端收到处理完请求的时间；
SR（Server Receive）：服务端收到调用端请求的时间；
SS（Server Send）：服务端处理完逻辑的时间
客户端调用时间=CR-CS。
服务端处理时间=SR-SS。

![image-20210601153645070](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210601153645070.png)

**2.调用链跟踪的整体架构**：日志埋点和采集，指标汇总，指标存储、查询、展现，告警、问题定位，调用链报表展示分析

**3.日志埋点**：基于SDK的手工埋点采集；基于字节码适配的自动插码埋点采集；基于中间件的自动埋点采集。

**4.日志上报**：主要问题是控制日志采集对资源的占用，并且快速、正确、方便地采集日志。一种是传统的ELK方式，但是磁盘I/O对性能影响大；另一种是无盘I/O，直接通过网络传输到日志收集端。
● 避免锁冲突：使用诸如RingBuffer这类高性能异步无锁队列做日志缓冲，提升日志写入性能；
● 避免频繁I/O：加大日志输出缓存，限制I/O操作频率，按秒级进行刷盘操作，降低频繁I/O操作对系统性能的影响；
● 压缩：使用LZO及Snappy这类能很好地平衡压缩率及性能的压缩算法对超过一定长度的字符串进行编码，以降低网络传输及存储成本。

![image-20210601155302904](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210601155302904.png)



调用链日志埋点采集到的服务请求的traceId、调用延时、调用状态、入参和出参等数据都会被封装到一个消息对象（Message）中，并被“压”入一个内存消息队列1中进行缓存。同时，由独立的预统计线程对这些消息进行预统计（如果需要的话），预统计结果也会被临时存储在一个内存的Map缓存对象中。定时线程会定期对Map缓存对象进行处理，一方面将时间分片的预统计结果封装成消息对象放入另一个内存消息队列2中，另一方面对已过期的时间分片数据进行清理。最后，由独立的发送线程（Sender Thread）将内存消息队列2中的原始日志或者预统计数据发送到远程的日志收集端。
● 采用全异步的方式，防止同步记录日志对业务操作产生的阻塞。
● 最好在消息队列满的时候实施一些快速抛弃的方法，防止内存堆积。
● 在消息队列的长度及Map缓存大小上要做适当的权衡及控制，防止对资源占用过多。
● 在最终的日志压缩和合并发送上，要保持一个度，因为压缩率越高，对计算资源的消耗越多。可以考虑采用LZO/Snappy这类在性能及压缩率上平衡较好的压缩算法。如果网络带宽能够保证，也可以不考虑压缩，毕竟压缩对采集端和收集端都有额外的计算损耗。
● 在内存消息队列的选择上，可以考虑采用效率更高的RingBuffer这类无锁的环形队列来替换Java中的BlockingQueue。

**5.日志采集**：日志收集包含日志的缓存和实时流处理，主要问题是“慢”，可以将接进来的日志统一被压入内存消息队列中缓存，再被分散到不同时间片对应的二级消息队列中，由独立的分析器实例集合进行分析和落盘存储。通过这种“纯内存+全异步”的处理方式，可以尽量避免资源锁的竞争，“榨取”服务器的性能，实现对日志的高效处理。

1）日志采集客户端基于负载均衡策略选中某台日志收集服务器，与之建立NIO长连接。
2）从日志采集客户端发送过来的日志会先被一个日志消息接收器（服务监听组件）接收并解码，反序列化为Message消息对象后直接“扔”进一个一级内存消息队列中。
3）一个独立运行的分拣线程从一级内存消息队列中不断获取日志消息，并根据创建时间把它分散到不同时间片对应的二级内存消息队列中。
4）每个二级内存消息队列都有一组独立的消息分析器实例为它服务，二级消息队列中的每个日志消息都会被这组分析器中的每个分析器逐一处理，每个分析器各司其职，有的负责告警分析，有的负责统计分析，有的负责链路分析，等等。
5）分析过的原始消息通过聚合被组装成调用链，并存储到NoSQL中，按时间片初步汇总后的统计信息会被存储到关系型数据库服务（RDB）中。
6）独立的统计线程会定时对RDB中的汇总数据做深度汇总，生成各个维度的统计及趋势分析报告。

![image-20210601160142362](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210601160142362.png)

**6.日志存储**：调用链的原始日志和统计数据需要分级存储：原始数据通过NoSQL存储，汇总统计数据通过RDB存储；



**7.告警**：一方面要保证准确性、减少误报，另一方面要保证及时性；并通过调度中心对线上服务或应用进行保护性调整，比如限流、降级、熔断、扩容等。

![image-20210601160734679](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210601160734679.png)

**8.调用链跟踪实战**：基于调用链进行实时监控及时告警，基于调用链跟踪的服务调用瓶颈分析，基于调用链跟踪的服务故障定界定位，通过调用链监控业务的健康状态

## 服务度量实践

### 常见解决方案

[Zipkin、pinpoint、jaeger、skywalking](https://www.cnblogs.com/Ming8006/p/13793598.html)、ESA Trace

|         | pinpoint | zipkin    | jaeger   | skywalking  | ESA Trace |
| --------| ---------| ----------| ---------| ----------- | ----------|
| OpenTracing兼容     | 否                 | 是                       | 是                       | 是                                |                                |
| 客户端支持语言      | java、php          | java,c#,go,php等         | java,c#,go,php等         | Java, .NET Core, NodeJS and PHP   | Java、C++、PHP、Pyhton、Go、JS |
| 存储                | hbase              | ES，mysql,Cassandra,内存 | ES，kafka,Cassandra,内存 | ES，H2,mysql,TIDB,sharding sphere | TSHouse、ES、Daks |
| 传输协议支持        | thrift             | http,MQ                  | udp/http                 | gRPC                              | Http |
| ui丰富程度          | 高                 | 低                       | 中                       | 中                                | 中 |
| 实现方式-代码侵入性 | 字节码注入，无侵入 | 拦截请求，侵入           | 拦截请求，侵入           | 字节码注入，无侵入                | 拦截请求，侵入 |
| 扩展性              | 低                 | 高                       | 高                       | 中                                | 高 |
| trace查询           | 不支持             | 支持                     | 支持                     | 支持                              | 支持 |
| 告警支持            | 支持               | 不支持                   | 不支持                   | 支持                              | 支持 |
| jvm监控             | 支持               | 不支持                   | 不支持                   | 支持                              | 不支持 |
| 性能损失            | 高                 | 中                       | 中                       | 低                                | 中 |

### OPPO ESA Trace

![image-20210601164434128](https://gitee.com/bruceyum/pictures/raw/master/pics/WEB536410243b72a7adf66f9121528269b4)

![image-20210601165414680](https://gitee.com/bruceyum/pictures/raw/master/pics/WEBc08faf275a0fa82fd17020da2cb6e40f)

日志埋点：网关埋点，其它的通过SDK埋点

日志上报：网关和SDK上报

日志采集：采集到的是调用链数据和统计数据

日志存储：调用链数据发送给拓扑分析集群做拓扑分析；统计数据发送到MQ统计聚合，调用链详情存入ES

告        警：

### OPPO云监控

窥探监控系统内部实现（涉及整体监控、异常告警、自定义监控、拨测、听风、promql等模块）

![image-20210525190232092](https://gitee.com/bruceyum/pictures/raw/master/pics/WEBd9fdf7cee85255cddd9fbee006a43c19)

听风1.0 基于Nagios



听风2.0 Prometheus

![image-20210525190519067](https://gitee.com/bruceyum/pictures/raw/master/pics/WEB352ef4ec72b44c5f3ab4266922b09612)

OPPO 云监控

![image-20210603161905466](https://gitee.com/bruceyum/pictures/raw/master/pics/WEBfa128be2c826bd52a6ba510849a33ade)

建议：产品文档不完善，很多链接点进去没有内容，排版混乱，有的页面就是Copy网页上的内容；

### 快应用接入调用链

采样策略：抽样采集，根据系统规模，稳定性及重要性调整采样率；
根据系统规模采用可变采样率
根据系统稳定性采用可变采样率
调用链分级采样

mysql：jdbc sdk 只能获取到有调用入口的数据；缓存刷新这样的定时任务需要通过 done
redis：jediscluster 自动注入，Spring监听器将jedisCluster替换成调用链代理类 done
ES：ES通过okhttp访问，可以通过okhttp监控。也可以采用javaagent 或 spring aop。done
rpc：dubo27 sdk，排除4.1.4依赖 done
http：okhttp sdk，done
restlight: restlight sdk done
jvm：云监控 exporter done
网关：网关自动上报 done
CompletableFuture/Thread pool/日志打印traceId
ZK/OCS/


## 服务管控理论

分布式服务整体鲁棒性保障有一些通用的架构设计原则，包括
1）冗余：A=1-(1-ax)^2 表示整体可用性，a 表示单个组件的可用性，x 表示组件数量
2）弹性伸缩：
3）单点无状态：
4）不可变基础设施：
5）故障传导阻断：切换流量（异地多活）、服务降级、 服务限流、服务熔断、超时控制、重试阻尼、幂等操作
6）基础设施即代码：

### 服务限流
服务限流是在高流量下保证服务集群整体稳定并提供一定可用性的有效办法。比起系统整体被“压趴”，所有用户都无法获得服务的状况，拒绝一部分用户，对另一部分用户提供正常服务总是要好一些。限流是根据某个应用或基础部件的某些核心指标，如总并发数、QPS或并发线程数，甚至IP地址白名单，来决定是否对后续的请求进行拦截。

单点限流：1、窗口：固定时间窗口、滑动窗口；2.漏桶算法、3.令牌桶算法：单桶单速、单桶双速、双桶单速、双桶双速度；

**1、固定窗口（计数器算法）**

在指定周期内累加访问次数，当达到设定的限流值时，触发限流策略；下一周期开始时，计数器清零并重新计数。
例：使用redis的incr原子自增与线程安全即可实现
用途：常用于QPS限流、统计总访问量
缺点：对于秒级周期计算会存在临界值归属的问题，达不到平滑限流。假设我们限流规则为每秒钟不超过 100 次接口请求，第一个 1s 时间窗口内，100 次接口请求都集中在最后的 10ms 内，在第二个 1s 的时间窗口内，100 次接口请求都集中在最开始的 10ms 内，虽然两个时间窗口内流量都符合限流要求 (<=100 个请求)，但在两个时间窗口临界的 20ms 内会集中有 200 次接口请求，如果不做限流，集中在这 20ms 内的 200 次请求就有可能压垮系统。

![](https://gitee.com/bruceyum/pictures/raw/master/pics/640)

**2、滑动窗口**

将时间周期分为N个小周期，分别记录每个小周期内的访问次数并且根据时间滑动删除过期的小周期。滑动窗口的格子划分得越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。
优点：可以很好的解决固定窗口算法的临界问题

![滑动窗口限流](https://gitee.com/bruceyum/pictures/raw/master/pics/WEB960238f271647370bf26f3798aca5570)

开始的时候，我们把t1~t5看做一个时间窗口，每个窗口1s，如果我们定的限流目标是每秒50个请求，那t1~t5这个窗口的请求总和不能超过250个。

这个窗口是滑动的，下一秒的窗口成了t2~t6，这时把t1时间片的统计抛弃，加入t6时间片进行统计。这段时间内的请求数量也不能超过250个。

滑动时间窗口的优点是解决了流量计数器算法的缺陷，但是也有2个问题：

- 流量超过就必须抛弃或者走降级逻辑
- 对流量控制不够精细，不能限制集中在短时间内的流量，也不能削峰填谷

**3、漏桶算法**

在客户端的请求发送到服务器之前，先用漏桶缓存起来，这个漏桶可以是一个长度固定的队列，这个队列中的请求均匀的发送到服务端。

如果客户端的请求速率太快，漏桶的队列满了，就会被拒绝掉，或者走降级处理逻辑。这样服务端就不会受到突发流量的冲击。

漏桶算法的优点是实现简单，可以使用消息队列来削峰填谷。

但是也有3个问题需要考虑:

- 漏桶的大小，如果太大，可能给服务端带来较大处理压力，太小可能会有大量请求被丢弃。
- 漏桶给服务端的请求发送速率。
- 使用缓存请求的方式，会使请求响应时间变长。

![image-20210706144542761](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210706144542761.png)

**4、令牌桶算法**

程序以R的速度向令牌桶中增加令牌，直到令牌桶满。请求到达时，先向令牌桶申请令牌如获取到令牌，则通过请求，否则触发限流策略。

当有突发大流量时，只要令牌桶里有足够多的令牌，请求就会被迅速执行。通常情况下，令牌桶容量的设置，可以接近服务器处理的极限，这样就可以有效利用服务器的资源。因此，这种策略适用于有突发特性的流量，且流量
需要即时处理的场景。

![image-20210706144641806](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210706144641806.png)

| **算法** | **参数**                  | **空间复杂度** | **时间复杂度** | **限制突发流量** | **平滑限流**            | **分布式实现难度** |
| -------- | ------------------------- | -------------- | -------------- | ---------------- | ----------------------- | ------------------ |
| 固定窗口 | 计数周期T 周期最大访问数N | 低             | 低             | 否               | 否                      | 低                 |
| 滑动窗口 | 计数周期T 周期最大访问数N | 高             | 中             | 是               | 相对实现 格子越多越平滑 | 中                 |
| 漏桶     | 漏桶流出速度R 漏桶容量N   | 低             | 高             | 是               |                         | 高                 |
| 令牌桶   | 令牌产生速度R 桶容量N     | 低             | 高             | 是               |                         | 高                 |

集群限流：集群环境下的限流也要以单点的限流为基础，先汇总集群各个服务节点的流量，并将这个总流量与预设的SLA阈值相比较，如果超过了总流量就要进行限流。



### 服务熔断

服务熔断是指调用方访问服务时通过断路器做代理进行访问，断路器会持续观察服务返回的成功、失败的状态，当失败超过设置的阈值时断路器打开，请求就不能真正地访问到服务了。

**1、熔断器有3种状态**

- CLOSED：默认状态。断路器观察到请求失败比例没有达到阈值，断路器认为被代理服务状态良好。
- OPEN：断路器观察到请求失败比例已经达到阈值，断路器认为被代理服务故障，打开开关，请求不再到达被代理的服务，而是快速失败。
- HALF OPEN：断路器打开后，为了能自动恢复对被代理服务的访问，会切换到半开放状态，去尝试请求被代理服务以查看服务是否已经故障恢复。如果成功，会转成`CLOSED`状态，否则转到`OPEN`状态。

断路器的状态切换图如下：

![img](https://pic3.zhimg.com/80/v2-e4623c3910059e648407b735990afb42_720w.jpg)

**2、需要考虑的问题**

使用断路器需要考虑一些问题：

- 针对不同的异常，定义不同的熔断后处理逻辑。
- 设置熔断的时长，超过这个时长后切换到`HALF OPEN`进行重试。
- 记录请求失败日志，供监控使用。
- 主动重试，比如对于`connection timeout`造成的熔断，可以用异步线程进行网络检测，比如`telenet`，检测到网络畅通时切换到`HALF OPEN`进行重试。
- 补偿接口，断路器可以提供补偿接口让运维人员手工关闭。
- 重试时，可以使用之前失败的请求进行重试，但一定要注意业务上是否允许这样做。

**3、使用场景**

- 服务故障或者升级时，让客户端快速失败
- 失败处理逻辑容易定义
- 响应耗时较长，客户端设置的`read timeout`会比较长，防止客户端大量重试请求导致的连接、线程资源不能释放

### 服务降级

服务降级，就是在线上流量暴涨的情况下，根据业务的重要度，对业务等级较低的一些服务或页面进行策略性的屏蔽或降低服务质量，以此释放服务器资源以保证线上高等级的服务正常运行。服务降级可以分为屏蔽降级、容错降级、Mock降级、熔断降级等。
1.屏蔽降级：当服务调用方频繁出错触发屏蔽后，调用方会将屏蔽服务实例移除可用服务集群列表。
2.容错降级：提供固定静态内容来替代调用结果的方式就是静态返回值降级，
3.Mock降级：远程调用失败后调用本地Mock类；
4.熔断降级：服务雪崩本质上就是一种因为“服务提供者的不可用”导致“服务调用者不可用”，并随着调用链的传导被放大的故障现象，服务雪崩的根本原因在于集群的故障传导，因此，通过“截断”故障的传导链条来避免故障蔓延是解决服务雪崩问题的最有效途径。当在一定时间内服务调用方调用服务提供方的服务的次数达到设定的阈值，并且出错的次数也达到设置的出错阈值时，Hystrix熔断器就会进行服务降级，让服务调用方执行本地设置的降级策略，不再发起远程调用。Hystrix熔断器具有自我反馈、自我恢复的功能，会根据调用接口的情况，让熔断器在closed（关闭）、open（全开）、half-open（半开）三种状态之间自动切换。
5.广义降级：入口降级、服务降级、资源与服务以来降级

### 负载均衡

它也是做服务灰度发布及在线压测的基础，可以利用权重动态调整将访问流量集中到一个或若干个节点上。常用的负载均衡策略有随机策略、轮询策略、最近最少访问策略、黏滞策略、一致性Hash策略及组合策略。

### 集群容错

快速失败（Failfast）：
失败安全（Failsafe）：
失败转移（Failover）：重试阻尼，防止级联重试，重试降级
失败重试（Failback）：
聚合调用（Forking）：
广播调用（Broadcast）：


### 服务授权
服务集群中服务和服务之间的调用本质上是一个应用去调用远程的另一个应用，这里就存在一个授权的问题，常见的授权方式有三种：自主授权、注册中心授权、第三方服务授权。
1.自主授权：基于微服务框架的过滤器
2.注册中心授权：注册中心下发Token
3.第三方服务授权：

### 生命周期管理

1.包部署模板：服务部署包分发，服务状态检测（“优化停机”），分批发布，服务发布执行
1）检查环境：检测系统环境是否正常，相关技术栈是否完备；
2）下载部署包：参考指定软件版本下载部署物料；
3）关闭服务监控：关闭服务监控，防止部署过程中产生大量报错信息，但部署监控必须开启；
4）服务下线：服务注册中心将该服务节点直接删除，或者调整该服务节点的路由权重为0来控制不再有新的请求进入该服务节点；
5）停止服务：发出进程关闭信息，通过“优雅停机”的方式在所有存量请求处理完毕之后，关闭服务进程；
6）部署服务：部署新服务的部署包；
7）启动服务：启动服务进程；
8）健康检测：检测服务是否正常启动，进程是否正常，并在服务注册中心中正常注册；
9）开启服务监控：服务启动成功并正常注册后，开启服务监控。
2.蓝绿发布：蓝绿发布的核心思想是新旧两套服务共存，
3.灰度发布：金丝雀测试，基于版本号的灰度发布

### 稳定性保障
通过实现预案并且将最佳方法记录在‘运维手册（palybook）’上通常可以使MTTR （故障平均恢复时间）降低3倍以上
1.应急预案选择及执行策略：故障发生概率，预案执行效率，预案负面影响，预案复杂度
2.建设行之有效的应急预案体系：覆盖度高，有效性高，自动化程度高
3.故障演练：
4.混沌工程：


## 服务管控实践

### 常见解决方案
|                   | Sentinel                                               | Hystrix                 | ServiceKeeper          | API Gateway | Dubbo  Admin |
| ----------------- | ------------------------------------------------------ | ----------------------- | ---------------------- | ----------- | ------------ |
| 隔离策略          | 信号量隔离（并发控制）                                 | 线程池隔离/信号量隔离   | 信号量隔离             |             |              |
| 熔断降级策略      | 基于慢调用比例、异常比例、异常数                       | 基于异常比例            | 基于异常比例、响应时间 |             |              |
| 实时统计实现      | 滑动窗口（LeapArray）                                  | 滑动窗口（基于 RxJava） |                        |             |              |
| 动态规则配置      | 支持多种数据源                                         | 支持多种数据源          |                        |             |              |
| 扩展性            | 多个扩展点                                             | 插件的形式              |                        |             |              |
| 基于注解的支持    | 支持                                                   | 支持                    | 支持                   |             |              |
| 限流              | 基于 QPS，支持基于调用关系的限流                       | 有限的支持              | 支持                   |             |              |
| 流量整形          | 支持预热模式与匀速排队控制效果                         | 不支持                  |                        |             |              |
| 系统自适应保护    | 支持                                                   | 不支持                  |                        |             |              |
| 多语言支持        | Java/Go/C++                                            | Java                    | Java                   |             |              |
| Service Mesh 支持 | 支持 Envoy/Istio                                       | 不支持                  | ESA Mesh               |             |              |
| 控制台            | 提供开箱即用的控制台，可配置规则、实时监控、机器发现等 | 简单的监控查看          | 简单的监控查看及配置   |             |              |

### Hystrix

**1、Hystrix整体流程**

1）构造一个 HystrixCommand或HystrixObservableCommand对象， 用于封装请求，并在构造方法配置请求被执行需要的参数；

2）执行命令， Hystrix 提供了4种执行命令的方法：execute()、queue()、observe()、toObservable()；

3）判断是否使用缓存响应请求，若启用了缓存，且缓存可用，直接使用缓存响应请求。 Hystrix 支持请求缓存，但需要用户自定义启动；

4）判断熔断器是否打开，如果打开，调到第8步；

5）判断线程池、队列、信号量是否已满，已满则调到第8步；

6）执行 HystrixObservableCommand.construct()或HystrixCommand.run()， 如果执行失败或者超时，跳到第8步；否者，跳到第9步；

7）统计熔断器监控指标；

8）走Fallback降级方法；

9）返回请求响应。

![Hystrix处理流程](https://mmbiz.qpic.cn/mmbiz_png/dkwuWwLoRKicDrqt9vkKKxxR0GocGHPPUBzv1RjxaMsMWgu25odx5DiajmWIf1ZEDNR8Rl88OZs3ZNWOHBg37xZQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



**2、资源隔离**

Hystrix提供了两种线程隔离的方式：线程池和信号量。

线程池和信号量都可以做线程隔离，但各有各的优缺点和支持的场景，对比如下：

|        | 线程切换 | 支持异步 | 支持超时 | 支持熔断 | 限流 | 开销 |
| ------ | -------- | -------- | -------- | -------- | ---- | ---- |
| 信号量 | 否       | 否       | 否       | 是       | 是   | 小   |
| 线程池 | 是       | 是       | 是       | 是       | 是   | 大   |

线程池和信号量都支持熔断和限流。相比线程池，信号量不需要线程切换，因此避免了不必要的开销。但是信号量不支持异步，也不支持超时，也就是说当所请求的服务不可用时，信号量会控制超过限制的请求立即返回，但是已经持有信号量的线程只能等待服务响应或从超时中返回，即可能出现长时间等待。线程池模式下，当超过指定时间未响应的服务， Hystrix会通过响应中断的方式通知线程立即结束并返回。

![image-20210706194359254](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210706194359254.png)

**3、熔断**

下图展示了HystrixCircuitBreaker的工作原理：

![图片](https://mmbiz.qpic.cn/mmbiz_png/dkwuWwLoRKicDrqt9vkKKxxR0GocGHPPUhg75Z8cOgqicnCABJiczia1E9yajWUiaQ812ia2wjW5iavHelp2zhMkLZtFA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

熔断器工作的详细过程如下：

第一步，调用 allowRequest() 判断是否允许将请求提交到线程池

1、允许熔断器强制打开， circuitBreaker.forceOpen为true，不允许放行，返回。

2、如果熔断器强制关闭， circuitBreaker.forceOpen为true，允许放行。 此外不必关注熔断器实际状态，也就是说熔断器仍然会维护统计数据和开关状态，只是不生效而已。

第二步，调用isOpen()判断熔断器开关是否打开

1、 如果熔断器开关打开，进入第三步，否则继续；

2、 如果一个周期内总的请求数小于circuitBreaker.requestVolumeThreshold的值，允许请求放行，否则继续；

3、 如果一个周期内错误率小于circuitBreaker.errorThresholdPercentage的值，允许请求放行。否则，打开熔断器开关，进入第三步。

第三步， 调用allowSingleTest()判断是否允许单个请求通行，检查依赖服务是否恢复

如果熔断器打开，且距离熔断器打开的时间或上一次试探请求放行的时间超过circuitBreaker.sleepWindowInMilliseconds的值时，熔断器器进入半开状态，允许放行一个试探请求；否则，不允许放行。

此外，为了提供决策依据，每个熔断默认维护了10个bucket，每秒一个bucket，当心的bucket被创建时，最旧的bucket会被抛弃。其中每个bucket维护了请求、失败、超时、拒绝的计数器，Hystrix负责收集并统计这些计数器。

**4、降级**



[Hystrix使用与分析](https://www.iteye.com/blog/hot66hot-2155036)

[Hystrix 限流熔断降级](https://mp.weixin.qq.com/s/paZmZJ5MmcsuiJ65RHqirg)

[Hystrix](https://mp.weixin.qq.com/s/u1BdeItIE85UorPkECPR8A)

### Sentinel 

Sentinel 的使用可以分为两个部分:

- 核心库（Java 客户端）：不依赖任何框架/库，能够运行于 Java 7 及以上的版本的运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持（见 主流框架适配）。
- 控制台（Dashboard）：Dashboard 主要负责管理推送规则、监控、管理机器信息等。

客户端和控制台通过Netty进行通信，上报客户端数据；
AHAS Sentinel 控制台提供了一个我们推荐的推送规则的做法，即 配置中心控制台/Sentinel 控制台 → 配置中心 → Sentinel 数据源 → Sentinel
但是基于这样的方式是在太重了；

[Sentinel 官网文档](https://sentinelguard.io/zh-cn/docs/introduction.html)

[阿里巴巴开源限流降级神器Sentinel大规模生产级应用实践](https://mp.weixin.qq.com/s/AjHCUmygTr78yo9yMxMEyg)

注：功能非常强大

### ServiceKeeper

[ServiceKeeper](http://cloud.oppoer.me/docsCenter/product0ec6948e58f6ed89844d08a23)

ESA ServiceKeeper 提供了方法以及方法参数级别的服务治理功能，无需修改业务代码，通过简单的配置即可获得QPS 限制、并发请求数限制、服务熔断等服务治理功能。

实例级别服务治理；

没有负载均衡/权重修改，没有条件路由/标签路由，没有被白名单；

基于信号量的资源隔离；

代码无侵入；




### API Gateway

应用集群级别服务治理

限流：如何实现分布式限流的？

降级

熔断

### Dubbo Admin

Dubbo 限流熔断降级？通过动态配置修改相关参数实现？Dubbo参数调优达到限流目的？

1、服务搜索(列表)

![image-20210705150755141](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210705150755141.png)

服务搜索是通过不同的过滤条件，在本地的注册数据缓存里，查找出合适的结果集。

1) 在RegistryServerSyn Bean初始化时，在afterPropertiesSet()方法中会订阅注册中心。直接调用注册中心模块的registryService#subscribe订阅，把this传入并作为监听者，因为RegistryServerSync也实现了监听接口。
2) 监听到变化时候，通过notify(List<URL> urls)方法更新本地的缓存数据。对于empty协议的变更，如果服务配置的group和version (Dubbo支持一个接口多个版本)的值是*,则清空所有本地的这个节点;如果指定了特定group和version,则只删除指定的节点。对于非empty协议的变更，则把数据按照类目、ServiceKey两种维度分别保存一份，更新本地缓存。ServiceKey的规则是：group + '/' + 接口名 +':' + version。
3) Bean被Spring容器销毁时，在destroy()方法中会取消订阅注册中心，直接调用registryService#unsubscribe 取消订阅。

获取注册中心的数据，并缓存到本地后，providerServicelmpl或ConsumepServicelmpl的查找就很好实现了，通过查询的参数遍历缓存，过滤出合适的结果即可。现有新版搜索支持根据Service名称、IP地址、服务名称进行搜索；旧版还支持创建、禁用、启用服务，这些特性是通过override特性实现的。

2、override特性的实现

![image-20210705152442662](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210705152442662.png)

override特性主要使用在动态参数的更新上，各个节点监听到注册中心的参数发生变化，从而更新本地的参数信息。override类型的URL是以override://开头的，允许整个URL中只有部分属性变化，监听者监听到变化后会做部分更新。下面我们来看一下override实现的具体操作逻辑：
1) 新增。把 override 对象转换成 URL,通过 registryservice.register(url)把 URL注册到注册中心。
2) 修改。根据Hash值找到老的URL,如果没找到则说明数据己经被修改，抛出异常；如果找到了，则先取消注册老的URL,再注册新的URLO
3) 删除。先根据id获取老的URL,再直接取消注册老的URL。
4) 启用/禁用。首先根据id获取老的URL,在新URL的params属性里把enabled设置为true或false,然后取消注册老的URL,最后注册新的URL。

通过override可以实现哪些治理？

3、route的实现

![image-20210705152507310](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210705152507310.png)

route规则可以为不同的服务指定特定的路由规则，route协议在注册中心的URL以route://开头。最后的conditions的意思就是，调用com.test.xxService服务中所有以find、list、get> is开头的方法，都路由到172.22.3.94、172.22.3.95、172.22.3.96这三个地址中的一个。它们之间使用=>表示路由。最终，整个route对象会转换为以route://开头的URL。增删改查的实现逻辑与override相同，都使用“注册”、"取消注册”方法来实现。

4、LoadBalance及Weight 

如果用户不做任何配置，则默认使用RandomLoadBalance，负载均衡对象会被转换成一个override对象，并使用override协议实现新增、更新、删除等操作。

当用户对服务设置了权重后，对权重高的节点会提高调用频率，对权重低的节点会降低调用频率。首先把前端传入的参数转换为Weight对象，然后把Weight对象转换为URL,最后使用overrideService把URL发布到注册中心。


### 快应用服务管控

负载均衡：随机或者轮询

集群容错：failover

限流：

[熔断降级](https://www.infoq.cn/article/JLb9z4up64MyQjN_ZbSd)

| 服务名称 | API类型 | 流量 | 成功率 | 平均响应耗时 | 治理措施 | 影响 |
| -------- | ------- | ---- | ------ | ------------ | -------- | ---- |
|          |         |      |        |              |          |      |