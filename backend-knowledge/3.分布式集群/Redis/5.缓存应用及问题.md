# 缓存应用及问题

[toc]

## 缓存特征

### 1、命中率

当某个请求能够通过访问缓存而得到响应时，称为缓存命中。  
缓存命中率越高，缓存的利用率也就越高。  

### 2、最大空间

缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。  
当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。  

### 3、缓存位置

**1. 浏览器**：当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。

**2. ISP**：网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。

**3. 反向代理**：反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。

**4. 本地缓存**：使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。

**5. 分布式缓存**：使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。

**6. 数据库缓存**：MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。

**7. Java 内部的缓存**：Java 为了优化空间，提高字符串、基本数据类型包装类的创建效率，设计了字符串常量池及 Byte、Short、Character、Integer、Long、Boolean 这六种包装类缓冲池。

**8. CPU 多级缓存**：CPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。

### 4、数据分布

**1. 数据分布设计原则**

在分布式数据存储系统中，需要将数据存储到不同的服务器上，那么数据如何索引及分布呢？通常会有如随机分布、范围分布、映射分布、哈希（一致性哈希）等数据分布方案。在分布式数据存储系统中，通常会考虑数据均匀、数据稳定和节点异构性这三个维度。  

- 数据均匀：不同存储节点中存储的数据要尽量均衡，避免让某一个或某几个节点存储压力过大，而其他节点却几乎没什么数据。用户访问也要做到均衡，避免出现某一个或某几个节点的访问量很大，但其他节点却无人问津的情况。
- 数据稳定：当存储节点出现故障需要移除或者扩增时，数据按照分布规则得到的结果应该尽量保持稳定，不要出现大范围的数据迁移。
- 节点异构性：不同存储节点的硬件配置可能差别很大，差别很大的节点，分到的数据量、用户访问量都差不多，本质就是一种不均衡。

除了上面这 3 个维度外，我们一般还会考虑隔离故障域、性能稳定性等因素。

**2. 哈希分布**

通过哈希函数得到数据应该存储的节点索引，例如：index = hash(key) % size

![哈希分布.png](https://gitee.com/bruceyum/pictures/raw/master/pics/WEBe30718eb2df7e5df0c155c3e3d7f3173)

哈希算法的一个优点是，只要哈希函数设置得当，可以很好地保证数据均匀性，
但有一个较为严重的缺点，就是稳定性较差,主要体现在服务器数量变动的时候，很多缓存的位置都要发生改变！
哈希方法适用于同类型节点且节点数量比较固定的场景。

**3. 一致性hash**

一致性哈希是指将存储节点和数据都映射到一个首尾相连的哈希环上，存储节点可以根据IP 地址进行哈希，数据通常通过顺时针方向寻找的方式，来确定自己所属的存储节点，即从数据映射在环上的位置开始，顺时针方向找到的第一个存储节点。一致性哈希同样是采用哈希函数，进行两步哈希：
1）哈希环：整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，直到2^ 32-1，我们把这个由2^32个点组成的圆环称为Hash环。
2）节点哈希：对存储节点进行哈希计算，也就是对存储节点做哈希映射，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。
3）数据哈希：当对数据进行存储或访问时，首先对数据进行映射得到一个结果，然后找到比该结果大的第一个存储节点，就是该数据应该存储的地方。


一致性Hash算法可以很好地解决哈希方法存在的稳定性问题，当节点加入或退出时，仅影响该节点在哈希环上顺时针相邻的后继节点，具有较好的容错性和可扩展性。一致性哈希方法比较适合同类型节点、节点规模会发生变化的场景


Hash环的数据倾斜问题：一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。

**4. 带虚拟节点的一致性哈希**

为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。带虚拟节点的一致性哈希方法，核心思想是根据每个节点的性能，为每个节点划分不同数量的虚拟节点，并将这些虚拟节点映射到哈希环中，然后再按照一致性哈希算法进行数据映射和存储。

可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点

同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。
带虚拟节点的一致性哈希方法比较适合异构节点、节点规模会发生变化的场景。

**5. 数据分布方法对比**

![数据分布对比.png](https://gitee.com/bruceyum/pictures/raw/master/pics/WEBe11a31f940978c493e788920d21bfa8b)

### 5、冷热数据

概念：比如网站的用户总数就是一个小而热的数据，但是比如每个用户的个人轨迹信息就是一个量大但是还冷热不均的数据，防止数据无限膨胀，所以用户缓存放到内存中都要设立过期时间。

比如，论坛的最新发表列表，最新报名列表，包括比如最新激活的用户可以存在 Redis 做最新列表的使用方式。

建议：Redis 一定要用在小而热的情况，防止数据的无限膨胀。基于 Redis 做冷热分离从技术上是可行的，从业务实用角度看却不一定。因为首先 Redis 不能很好区分冷热数据，然后很难避免读取落地冷数据时的性能问题，因此肯定不如纯内存的 Redis 性能好，而用户对 KV 数据库性能的期望是没有最好，只有更好。随着内存越来越大、越来越便宜，更多的数据可以直接放到 Redis 内存，会进一步导致冷热分离成为一个无人使用的鸡肋功能。


## Redis 缓存问题

![Redis 问题域](https://gitee.com/bruceyum/pictures/raw/master/pics/5fb0b61b07912964bbadcb8f)

### 1、缓存穿透

缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中。缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。

解决方案

- 缓存空对象：当第2步存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取。
缓存空对象会有两个问题：
1）空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间（如果是攻击，问题更严重），比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。
2）缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。

- 布隆过滤

布隆过滤器：把所有可能的请求的缓存值都放在
1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到⼏个哈
希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。在击穿缓存时，先查一下布隆过滤器，如果不存在，则不查db，一定程度保护了db层

这种方法适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少。

### 2、热Key重建（缓存击穿）

当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。在缓存失效的瞬间，有大量线程来重建缓存造成后端负载加大，甚至可能会让应用崩溃。

解决方案

- 加锁：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。

业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，类似于自旋锁，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。


- 缓存永远不过期

这里的“永远不过期”包含两层意思：

1) 从缓存上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。

2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期.

从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。


### 3、缓存雪崩

由于缓存层承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。 

做电商项目的时候，一般是采取不同分类商品，缓存不同周期。在同一分类中的商品，加上一个随机因子。这样能尽可能分散缓存过期时间，而且，热门类目的商品缓存时间长一些，冷门类目的商品缓存时间短一些，也能节省缓存服务的资源。

其实集中过期，倒不是非常致命，比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网。因为自然形成的缓存雪崩，一定是在某个时间段集中创建缓存，那么那个时候数据库能顶住压力，这个时候，数据库也是可以顶住压力的。无非就是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。

解决方案：

- 保证缓存层服务高可用性：Redis高可用保证部分服务器宕机整个缓存层依然可用。

- 依赖隔离组件为后端限流并降级。无论是缓存层还是存储层都会有出错的概率，可以将它们视同为资源。在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对 某个key只允许一个线程查询数据和写缓存，其他线程等待。

- 提前演练。在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定。

- 缓存预热

可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀
缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统，刷新过期时间。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

缓存预热方案：

1）直接写个缓存刷新页面，上线时手工操作下；

2）数据量不大，可以在项目启动的时候自动进行加载；

3）定时刷新缓存；

- 做二级缓存，或者双缓存策略

A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。


### 4、无底洞问题

无底洞问题及新增节点，但是性能并没有提升，反而可能会下降。造成这个问题的原因是节点更多，则数据更分散。对批量操作而言以为者更多的网络IO，所以性能会下降。常见的优化方案有四种：

1.串行命令：由于n个key是比较均匀地分布在 Redis Cluster 的各个节点上，因此无法使用mget命令一次性获取

2.串行IO：将属于同一个节点的key进行归档，得到每个节点的key子列表，之后对每个节点执行mget或者Pipeline操作，它的操作时间=node次网络时间+n次命令时间，网络次数是node的个数。

3.并行IO：此方案是将方案2中的最后一步改为多线程执行，网络次数虽然还是节点个数，但由于使用多线程网络时间变为O（1）

4.hash\_tag实现：Redis Cluster 的 hash_tag 功能，它可以将多个 key 强制分配到一个节点上，它的操作时间= 1次网络时间 +n 次命令时间。

![无底洞问题优化方案对比](https://gitee.com/bruceyum/pictures/raw/master/pics/WEB8ce0ef7c9c3f5fb4dadd1d325339bb17)


### 5、性能问题

![Redis性能问题总结](https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3PCDCjr6w7Q3WPa6Kj0LZWf9EAicrlpNWgia6WWdUpl0R8eHXBGEfCHadrH82dmhKs2NOibK81OBZgPQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


### 6、双写一致性

当业务需要更新数据时，缓存与数据库中的内容都需要被修改。但两者的执行必定存在一个先后顺序，这一定会导致缓存与数据库中的数据不一致。首先，我们的缓存都应该设置过期时间，缓存过期之后会自动重建，因此缓存和数据库是能够达成最终一致的。

但是如何保证缓存和数据库的最终一致同时，缩短缓存和数据库不一致时间，减少对业务影响？此时主要需要考虑两个问题：  

1）更新还是删除：当缓存中的内容变化时，是选择修改缓存(update)，还是直接删除缓存(delete)？  
2）执行顺序的问题：先更新缓存还是先更新数据库？  

**1.更新缓存vs删除缓存**

场景：A 线程更新数据库，B 线程更新数据库，B 线程更新缓存，A 线程更新缓存。此时缓存不一致直到过期。

1）更新缓存的成本通常大于淘汰缓存的成本（但是这个成本只是转到缓存过期重建上了呀，从用户体验上更新缓存还好一些呢）  
2）且很有可能造成数据长时间不一致（退化成过期重建），所以推荐直接淘汰缓存； 

更新操作采用分布式锁，串行化也可以吧？

**2.先删除缓存后更新数据库**

正常场景：  
1）线程 A 删除缓存，同时完成数据库更新；  
2）线程 B 请求数据，缓存未命中，则重建缓存；  

异常场景 1：同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:  
（1）线程 A 进行写操作，删除缓存
（2）线程 B 查询发现缓存不存在，B去数据库查询得到旧值，将旧值写入缓存。  
（3）线程 A 将新值写入数据库，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。（就算数据写入是再读取之前，也可能由于主从同步延迟读取到旧值）

解决方案：延时双删  
1）线程 A 删除缓存，同时完成数据库更新；  
2）休眠 n 秒，再次删除缓存；  

为什么要延迟 n 秒，确保其它线程读取到的旧值已经更新到缓存中，这样第二次删除能够把旧值删除。  
延时双删不是脱了裤子放屁吗？它先删除了缓存，导致其它线程有机会重建缓存，然后再通过删除缓存修复问题？那直接不引入问题，不要先删除缓存不就可以啦？

**3.先更新数据库后删除缓存**

正常场景：  
1）线程 A 更新数据库，同时完成缓存删除；  
2）线程 B 请求数据，缓存未命中，则重建缓存；

异常场景1：  
1）线程 A 更新数据库未完成（或者主从同步延迟）
2）线程 B 请求数据，由于缓存过期未命中，线程 B 重建缓存读取到旧值；
3）线程 A 更新完数据库之后删除缓存；
4）线程 B 将旧值写入缓存；

解决这个问题还是延迟双删。

**4.保证缓存成功删除**

无论是先更新数据库，还是延时双删？都需要保证

方案一：通过消息队列保证删除成功

1）更新数据库数据；  
2）缓存因为种种问题删除失败；  
3）将需要删除的key发送至消息队列；  
4）自己消费消息，获得需要删除的key；  
5）继续重试删除操作，直到成功。

![消息队列保证](https://gitee.com/bruceyum/pictures/raw/master/pics/1350514-20190625081803431-1674500057.png)

该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。

方案二：订阅 binloag

1）更新数据库数据；  
2）数据库会将操作信息写入binlog日志当中；  
3）订阅程序提取出所需要的数据以及key；  
4）另起一段非业务代码，获得该信息；  
5）尝试删除缓存操作，发现删除失败；  
6）将这些信息发送至消息队列；  
7）重新从消息队列中获得该数据，重试操作；  

![binglog](https://gitee.com/bruceyum/pictures/raw/master/pics/1350514-20190625081910951-1888679531.png)

**5.缓存更新建议**
一致性要求不高：其实直接更新数据库，等待缓存过期重建即可；
一致性要求较高：数据库和缓存同步双写即可，最差只是退化为过期重建；同步双写建议先更新数据库再删除缓存；
一致性要求很高：异步双写，更新数据库，异步删除，延时删除，通过消息队列[可选binlog]保证缓存正确删除；

延迟双删：先删除缓存，再更新数据库，再延迟删除缓存；
优化版本：更新数据库，删除缓存，再延迟删除缓存；
结论是绝对的先更新数据库！！！

### 7、丢失写入

主从切换丢失修改，或者集群脑裂丢失修改；
解决方案：大不多机制
master选举需要大多数投票；
写入 slaves 可以配置需要写入多少个 slaves 才算写入成功；


### 8、缓存降级/措施

核心就是弃车保帅，保证核心服务可用，降级可以丢弃的服务，可以让程序实施自动降级，也可以人工紧急降级。

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；

2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；

3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；

4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

## Redis 应用

### 1、分布式锁

[分布式锁](https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247485739&idx=1&sn=1401aba7c5816cf9c5230a28e2e7f2a3&scene=19#wechat_redirect)：多个进程同时访问共享资源会产生并发安全问题，可以通过分布式锁控制多个进程对资源的访问。

**1.基本实现**

1）加锁：SET lock_key value EX $expire_time NX  
2）操作共享资源  
3）释放锁：DEL lock_key 释放锁  

死锁问题：由持有锁的进程由于某种原因未能正常释放锁。通过设置过期时间自动释放锁解决。  
锁过期：客户端 1 操作共享资源耗时太久，导致锁被自动释放，之后被客户端 2 持有  
释放别人的锁：客户端 1 操作共享资源完成后，却又释放了客户端 2 的锁  

**2. 优化实现**

锁被别人释放：锁写入唯一标识，释放锁先检查标识，再释放。标识的查询和释放需要在同一个事务内，所以需要通过 Lua 脚本执行。  
锁提前过期：守护线程，自动续期。Redisson 是一个 Java 语言实现的 Redis SDK   客户端，在使用分布式锁时，它就采用了「自动续期」的方案来避免锁过期，这个守护线程我们一般也把它叫做「看门狗」线程。  

1）加锁：SET lock_key $unique_id EX $expire_time NX  
2）操作共享资源  
3）释放锁：Lua 脚本，先 GET 判断锁是否归属自己，再 DEL 释放锁  

```
if redis.call("GET",KEYS[1]) == ARGV[1]
then
    return redis.call("DEL",KEYS[1])
else
    return 0
end
```



![Redis 分布式锁优化版本](https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3N9hGL63cpMX4cTuPjx5Y0lOXukLVaibs66nBepjicM2ufro0mr5KzqG2H5cUXkPPPndLF9fYicfmoIA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**3.主从不一致问题**

Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。   
- 异步复制的情况：客户端向主节点写入后，还没来得及复制到从节点，主节点就宕机，写入丢失；   
- 主从脑裂的情况：客户端向主节点写入后，还没来得及复制到从节点，主从网络就分割，选取从节点升级为master后，原来的master即使断线重连也会成为slave，写入就丢失了。  

例如：客户端 1 在主库上执行 SET 命令，加锁成功此时，主库异常宕机，SET 命令还未同步到从库上（主从复制是异步的）从库被哨兵提升为新主库，这个锁在新的主库上，丢失了！

解决方案：RedLock  
1）客户端先获取「当前时间戳T1」  
2）客户端依次向这 5 个 Redis 实例发起加锁请求（用前面讲到的 SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁  
3）如果客户端从 >=3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败  
4）加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）  
5）加锁失败，向「全部节点」发起释放锁请求（前面讲到的 Lua 脚本释放锁）  

**4.RedLock正确性**

分布式系统异常场景主要包括三大块：NPC。

N：Network Delay，网络延迟      
P：Process Pause，进程暂停（GC）        
C：Clock Drift，时钟漂移   

场景1：客户端 1 向A、B、C、D、E多个节点申请锁，并且申请成功。此时客户端 1 进入 GC 暂停，锁过期失效。客户端 2 成功申请枷锁，则两个客户端同时持有锁。  
场景2：客户端 1 向A、B、C、D、E多个节点申请锁，并且获得A、B、C三个节点的锁，则申请成功。但是 C 节点时钟「向前跳跃」，锁提前释放。客户端 2 向A、B、C、D、E多个系欸但申请锁，并且获得C、D、E三个节点的锁，则申请成功。此时客户端 1 客户端 2 同时持有锁。

1）RedLock 对时钟精度要求不高，不要认为修改时钟；  
2）网络延迟或者进程暂停发生在客户端获取锁之前 RedLock 通过判断是可以解决的，发生再获取锁之后任何系统都是无能为力的；  

**5.分布式锁建议**

1）RedLock 由于需要获取多实例分布式锁，性能较低，不建议使用；
2）再优化版 Redis 分布式锁的基础上结合 fecing token 思想对资源访问进行控制；

### 2、Redis 高并发相关

Redis 分库

### 3、布隆过滤器



### 4、HyperLogLog





