# Redis高可用

[toc]

## RDB持久化

Redis 是内存数据库，它将自己的数据库状态储存在内存里面，一旦服务器进程退出，服务器中的数据库状态也会消失不见。

Redis 提供了 RDB 持久化功能，将 Redis 在内存中的数据库状态生成的 RDB 文件是一个经过压缩的二进制文件保存到磁盘里面，避免数据意外丢失。服务器启动可以通过 RDB 文件恢复数据库状态。

### 1、持久化命令

**SAVE** 该命令会阻塞当前 Redis 服务器，执行 SAVE 命令期间，Redis 不能处理其他命令，直到 RDB 过程完成为止。执行完成时候如果存在老的 RDB 文件，就把新的替代掉旧的。我们的客户端可能都是几万或者是几十万，这种方式显然不可取。

**BGSAVE** 执行该命令时，BGSAVE命令会 fork() 出一个子进程，RDB 持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短，服务器进程（父进程）继续处理命令请求。基本上 Redis 内部所有的RDB操作都是采用 BGSAVE 命令。

在BGSAVE命令执行期间，服务器处理SAVE、BGSAVE、BGREWRITEAOF三个命令的方式会和平时有所不同。
- 客户端发送的SAVE命令会被服务器拒绝
- 如果BGSAVE命令正在执行，那么客户端发送的BGREWRITEAOF命令会被延迟到BGSAVE命令执行完毕之后执行。
- 如果BGREWRITEAOF命令正在执行，那么客户端发送的BGSAVE命令会被服务器拒绝。

### 2、自动间隔保存

自动间隔保存是由我们的配置文件来完成的。在 redis.conf 配置文件中，save：这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如“save m n”。表示m秒内数据集存在n次修改时，不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能，自动触发bgsave 默认如下：
```
save 900 1
save 300 10
save 60 10000
```

save配置保存在 saveparams 属性数中，每个saveparam结构都保存了一个save选项设置的保存条件：

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-4c1e6c09a6bc61293ab66453d8f44c2fa384452c.png)

Redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，它的其中一项工作就是检查save选项所设置的保存条件是否已经满足，如果满足的话，就执行BGSAVE命令。

程序会遍历并检查saveparams数组中的所有保存条件，只要有任意一个条件被满足，那么服务器就会执行BGSAVE命令。

除了saveparams 数组之外，服务器状态还维持着一个 dirty 计数器，以及一个 lastsave 属性：

- dirty 计数器记录距离上一次成功执行 SAVE 命令或者 BGSAVE 命令之后，服务器对数据库状态（服务器中的所有数据库）进行了多少次修改（包括写入、删除、更新等操作）。当服务器成功执行一个数据库修改命令之后，程序就会对 dirty 计数器进行更新：命令修改了多少次数据库，dirty 计数器的值就增加多少。
- lastsave 属性是一个 UNIX 时间戳，记录了服务器上一次成功执行 SAVE 命令或者 BGSAVE 命令的时间。


### 3、RDB 文件结构

可以linux下使用 od 命令分析 RDB 文件

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/5eca3ba17d9c08156c5ee65b)

### 4、RDB 优缺点

**优点**
- RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。
- 生成 RDB 文件的时候，Redis 主进程会 fork() 一个子进程来处理所有保存工作，主进程不需要进行任何磁盘 IO 操作。
- RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

**缺点**
RDB 通常通过save条件自动触发 BGSAVE，如果在触发 BGSAVE 之前发生崩溃，那么将丢失这段时间内的修改。

### 5、RDB 常见问题

问题1：对内存进行快照，那么变化的数据怎么办呢？

CopyOnWrite，AOF 将副本副本写入文件。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/5fb0bfd1e401fd7d35ca7730)

BGSAVE 子进程是由主进程 fork() 生成的，可以共享主进程的所有内存数据。BGSAVE 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。如果主线程要修改一块数据（例如图中的键值对 C），这块数据就会被复制一份，生成该数据的副本。然后，BGSAVE 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。这种机制称为copy on write，简称cow

问题2：BGSAVE 有没有可能造成 Redis 卡顿

有可能：子进程在创建后不会再阻塞主线程，但是 fork()  这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。
因为子进程共享主进程的内存，所以需要复制主进程的页表。
子进程在被 fork() 处理时，与主进程共享同一份内存，但在生成快照时采取 COW 机制，确保不会阻塞主进程的数据读写


问题3：多久执行一次 BGSAVE 合适

推荐 BGSAVE 和 AOF 一起使用，一般一小时执行一次即可。



## AOF持久化

除了 RDB 持久化功能之外，Redis还提供了AOF（Append Only File）持久化功能。AOF持久化是通过保存 Redis 服务器所执行的写命令来记录数据库状态的，被写入 AOF 文件的所有命令都是以Redis的命令请求协议格式保存的，因为 Redis 的命令请求协议是纯文本格式，所以我们可以直接打开一个 AOF 文件，观察里面的内容。

### 1、AOF 文件的写入与同步

当 AOF 持久化功能处于打开状态时，服务器在处理文件事件时可能会执行写命令， 会以协议格式将被执行的写命令追加到服务器状态的 aof_buf 缓冲区的末尾。在服务器每次结束一个事件循环之前， 它都会调用 flushAppendOnlyFile 函数， 考虑是否需要将 aof_buf 缓冲区中的内容写入和保存到 AOF 文件里面，flushAppendOnlyFile 函数的行为由服务器配置的 appendfsync 选项的值来决定（默认值为 everysec）。

为了提高文件的写入效率， 当用户调用 write 函数， 将一些数据写入到文件的时候， 操作系统通常会将写入数据暂时保存在一个内存缓冲区里面， 等到缓冲区的空间被填满、或者超过了指定的时限之后， 才真正地将缓冲区中的数据写入到磁盘里面。

这种做法虽然提高了效率， 但也为写入数据带来了安全问题， 因为如果计算机发生停机， 那么保存在内存缓冲区里面的写入数据将会丢失。为此， 系统提供了 fsync 和 fdatasync 两个同步函数， 它们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面， 从而确保写入数据的安全性。

服务器配置 appendfsync 选项的值直接决定 AOF 持久化功能的效率和安全性。

always： 服务器在每个事件循环都要将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 并且同步 AOF 文件， 所以 always 的效率是 appendfsync 选项三个值当中最慢的一个， 但从安全性来说， always 也是最安全的， 因为即使出现故障停机， AOF 持久化也只会丢失一个事件循环中所产生的命令数据。

everysec：服务器在每个事件循环都要将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 并且每隔超过一秒就要在子线程中对 AOF 文件进行一次同步： 从效率上来讲， everysec 模式足够快， 并且就算出现故障停机， 数据库也只丢失一秒钟的命令数据。

当 appendfsync 的值为 no 时， 服务器在每个事件循环都要将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 至于何时对 AOF 文件进行同步， 则由操作系统控制。

因为处于 no 模式下的 flushAppendOnlyFile 调用无须执行同步操作， 所以该模式下的 AOF 文件写入速度总是最快的， 不过因为这种模式会在系统缓存中积累一段时间的写入数据， 所以该模式的单次同步时长通常是三种模式中时间最长的： 从平摊操作的角度来看， no模式和 everysec 模式的效率类似， 当出现故障停机时， 使用 no 模式的服务器将丢失上次同步 AOF 文件之后的所有写命令数据。

### 2、AOF 文件的载入

服务器只要读入并重新执行一遍AOF文件里面保存的写命令，就可以还原服务器关闭之前的数据库状态：
- 创建一个不带网络连接的伪客户端（fake client）：因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时所使用的命令直接来源于AOF文件而不是网络连接，所以服务器使用了一个没有网络连接的伪客户端来执行AOF文件保存的写命令，伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样
- 从AOF文件中分析并读取出一条写命令。
- 使用伪客户端执行被读出的写命令。
- 一直执行步骤2和步骤3，直到AOF文件中的所有写命令都被处理完毕为止。

### 3、AOF 重写

因为 AOF 持久化是通过保存被执行的写命令来记录数据库状态的，所以随着服务器运行时间的流逝，AOF 文件中的内容会越来越多，文件的体积也会越来越大，如果不加以控制的话，体积过大的AOF文件很可能对 Redis 服务器、甚至整个宿主计算机造成影响，并且AOF文件的体积越大，使用AOF文件来进行数据还原所需的时间就越多。为了解决 AOF 文件体积膨胀的问题，Redis 提供了AOF文件重写（rewrite）功能。

AOF文件重写是通过读取服务器当前的数据库状态来实现的，读取数据库内容，生成相应的命令；因为 aof_rewrite 函数生成的新 AOF 文件只包含还原当前数据库状态所必须的命令，所以新 AOF 文件不会浪费任何硬盘空间。

Redis 提供了 bgrewriteaof 命令 fork() 出一条新进程来将文件重写 。首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令保存到临时文件中。

子进程进行AOF重写期间，服务器进程（父进程）可以继续处理命令请求。

子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。

为了避免在执行命令时造成客户端输入缓冲区溢出，重写程序在处理列表、哈希表、集合、有序集合这四种可能会带有多个元素的键时，会先检查键所包含的元素数量，如果元素的数量超过了 redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD:64  常量的值，那么重写程序将使用多条命令来记录键的值，而不单单使用一条命令。例如，一个集合键包含了超过  64 个元素，那么重写程序会用多条 SADD 命令来记录这个集合，并且每条命令设置的元素数量也为 64 个。

**AOF 重写缓冲区**

子进程在进行AOF重写期间，服务器进程还需要继续处理命令请求，而新的命令可能会对现有的数据库状态进行修改，从而使得服务器当前的数据库状态和重写后的AOF文件所保存的数据库状态不一致

为了解决这种数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给 AOF 缓冲和 AOF 重写缓冲区

当子进程完成 AOF 重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：
- 将AOF重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。
- 对新的 AOF 文件进行改名，原子地（atomic）覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。

在整个 AOF 后台重写过程中，只有信号处理函数执行时会对服务器进程（父进程）造成阻塞，在其他时候，AOF 后台重写都不会阻塞父进程，这将 AOF 重写对服务器性能造成的影响降到了最低。

优点<br>
- AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 fsync 操作，最多丢失 1 秒钟的数据。
- AOF 日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。
- AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。
- AOF 日志文件的命令通过可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据 

劣点<br>
- 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大
- AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的
- 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。

### 4、AOF 常见问题

问题1：AOF 重写为什么不共享使用 AOF 本身的日志？

如果都用 AOF 日志的话，主进程要写，bgrewriteaof 子进程也要写，这两者会竞争文件系统的锁，这就会对 Redis 主线程的性能造成影响。

问题2：AOF 重写过程中有没有其他潜在的阻塞风险？

风险一：Redis 主线程 fork() 创建 bgrewriteaof 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（Process Control Block，简称为 PCB）。内核要把主线程的 PCB 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就会长，这就会给主线程带来阻塞风险。

风险二：bgrewriteaof 子进程会和主进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。

问题3：备份Redis数据

在服务器中创建一个cron作业，在一个目录中创建 RDB 文件的每小时快照，在另一个目录中创建每日快照。

每次运行cron脚本时，请确保调用find命令以确保删除太旧的快照：例如，您可以在最近的48小时内每小时拍摄一次快照，而在一个或两个月内每天拍摄一次。确保使用数据和时间信息命名快照。

每天至少有一次确保将 RDB 快照传输到数据中心外部或至少传输到运行 Redis 实例的物理计算机外部。
创建 RDB 文件和重写 AOF 文件都利用了 COW(copy on write) 机制。当是写入频繁的场景，当向磁盘保存 RDB 文件或者改写 AOF 日志时，Redis 可能会用正常使用内存 2 倍的内存。额外使用的内存和保存期间写修改的内存页数量成比例，因此经常和这期间改动的键的数量成比例

问题4：两种方式的优缺点及怎么选择合适？

RDB（保存的是数据集某个时间点的快照） 
- RDB 可以用 zlf 算法压缩，体积小；可自定义保存时间间隔，适合备份； 
- fork 一个子进程进行备份，主进程不用进行磁盘 I/O，最大化性能； 
- 对大数据集，对比 AOF，恢复数据速度较快 
- 如果宕机会丢失几分钟的写入数据 
- AOF（保存执行的写入操作） 
- 可选三种 fsync 策略，持久性比 RDB 好 
- 当 AOF 体积过大时，可在后台进行 rewrite 
- 积较大 * 根据场景选择，推荐混合使用


## 主从复制

### 1、旧版复制功能

2.8 版本以前复制功能有两个操作：同步(sync)和命令传播(command propagate)。

**1. 同步**

当客户端向从服务器发送 SLAVEOF 命令， 要求从服务器复制主服务器时， 从服务器首先需要执行同步操作， 也即是， 将从服务器的数据库状态更新至主服务器当前所处的数据库状态。

从服务器对主服务器的同步操作需要通过向主服务器发送 SYNC 命令来完成， 以下是 SYNC 命令的执行步骤：

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-97b9636a1ae5296d0dd59743f533ed887b80779a.png)

- 从服务器向主服务器发送 SYNC 命令。
- 收到 SYNC 命令的主服务器执行 BGSAVE 命令， 在后台生成一个 RDB 文件， 并使用一个缓冲区记录从现在开始执行的所有写命令。
- 当主服务器的 BGSAVE 命令执行完毕时， 主服务器会将 BGSAVE 命令生成的 RDB 文件发送给从服务器， 从服务器接收并载入这个 RDB 文件， 将自己的数据库状态更新至主服务器执行 BGSAVE 命令时的数据库状态。
- 主服务器将记录在缓冲区里面的所有写命令发送给从服务器， 从服务器执行这些写命令， 将自己的数据库状态更新至主服务器数据库当前所处的状态。

**2. 命令传播**

同步操作执行完毕之后，主从服务器两者的数据库将达到一致状态，主服务器的数据库就有可能会被修改， 并导致主从服务器状态不再一致。主服务器需要对从服务器执行命令传播操作： 主服务器会将自己执行数据修改命令发送给从服务器执行， 当从服务器执行了相同的命令之后， 主从服务器将再次回到一致状态。

**3. 旧版复制问题**

 效率低下：每次主从断线重连都需要完成的执行同步和命令传播过程来同步全部数据，断线可能只是少部分命令没有同步，但却要同步全部数据，非常低效。

 消耗资源：每次执行SYNC命令，主服务器需要执行BGSAVE命令来生成RDB文件，这个生成操作会耗费主服务器大量的CPU、内存和磁盘I/O资源。RDB文件发送给从服务器，消耗网络资源（带宽和流量），并对主服务器响应命令请求的时间产生影响。从服务器需要载入主服务器发来的RDB文件，并且在载入期间，从服务器会因为阻塞而没办法处理命令请求。 

解决：Redis 2.8 版本后使用 psync (即 partial resynchronization)

### 2、新版同步

PSYNC 命令具有完整重同步（full resynchronization）和部分重同步（partialresynchronization）两种模式：

- 完整重同步用于处理初次复制情况：完整重同步的执行步骤和 SYNC 命令的执行步骤基本一样，它们都是通过让主服务器创建并发送 RDB 文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步。

- 部分重同步则用于处理断线后重复制情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所处的状态。

**1. 部分重同步的实现**

**复制偏移量**

执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量：
- 主服务器每次向从服务器传播 N 个字节的数据时，就将自己的复制偏移量的值加上 N。
- 从服务器每次收到主服务器传播来的 N 个字节的数据时，就将自己的复制偏移量的值加上 N。

**复制积压缓冲区**

复制积压缓冲区是由主服务器维护的一个固定长度（fixed-size）先进先出（FIFO）队列，默认大小为1MB。主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令，并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量。

当从服务器重新连上主服务器时，从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作：
- 如果offset偏移量之后的数据（也即是偏移量offset+1开始的数据）仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作。
- 相反，如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整重同步操作。

**服务器运 ID**

除了复制偏移量和复制积压缓冲区之外，实现部分重同步还需要用到服务器运行 ID（run ID）：
- 每个 Redis 服务器，不论主服务器还是从服务，都会有自己的运行 ID。
- 运行 ID 在服务器启动时自动生成，由 40 个随机的十六进制字符组成
从服务器会保存主服务器的运行 ID，断连重新复制会根据从服务器保存的 ID 是否与主服务器 ID 相同决定全量复制还是部分复制，相同则部分同步，反之全量同步。

**2. PSYN 实现**

完整重同步：从服务器在开始一次新的复制时将向主服务器发送 PSYNC ? -1 命令

部分重同步：从服务器在开始一次新的复制时将向主服务器发送 PSYNC <runid> <offset> 命令，其中 runid 是上一次复制的主服务器的运行 ID，而 offset 则是从服务器当前的复制偏移量。

收到PSYNC命令的主服务器会向从服务器返回以下三种回复的其中一种：
- 如果主服务器返回 +FULLRESYNC <runid> <offset> 回复，那么表示主服务器将与从服务器执行完整重同步操作：其中 runid 是这个主服务器的运行 ID，从服务器会将这个ID保存起来，在下一次发送 PSYNC 命令时使用；而 offset 则是主服务器当前的复制偏移量，从服务器会将这个值作为自己的初始化偏移量。
- 如果主服务器返回 +CONTINUE 回复，那么表示主服务器将与从服务器执行部分重同步操作，从服务器只要等着主服务器将自己缺少的那部分数据发送过来就可以了。
- 如果主服务器返回-ERR回复，那么表示主服务器的版本低于 Redis 2.8，它识别不了PSYNC 命令，从服务器将向主服务器发送 SYNC 命令，并与主服务器执行完整同步操作。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-05c9723c0862aecf99485314d7de36c440686539.png)

### 3、主从复制实现

**1. 设置主服务器的地址和端口**

从服务器收到 SLAVEOF 127.0.0.1 6379 会将主服务器IP地址127.0.0.1以及端口6379保存到服务器状态的masterhost属性和masterport属性

**2. 建立套接字连接**

在SLAVEOF命令执行之后，从服务器将根据命令所设置的IP地址和端口，创建连向主服务器的套接字连接，并关联一个专门用于处理复制工作的文件事件处理器，这个处理器将负责执行后续的复制工作，比如接收RDB文件，以及接收主服务器传播来的写命令。

**3. 发送 PING 命令**

从服务器成为主服务器的客户端之后，做的第一件事就是向主服务器发送一个PING命令，这个 PING 命令有两个作用：
- 虽然主从服务器成功建立起了套接字连接，但双方并未使用该套接字进行过任何通信，通过发送 PING 命令可以检查套接字的读写状态是否正常。
- 因为复制工作接下来的几个步骤都必须在主服务器可以正常处理命令请求的状态下才能进行，通过发送 PING 命令可以检查主服务器能否正常处理命令请求。
如果主服务器超时或者返回错误，那从服务器尝试重新连接。如果从服务器读取到"PONG"回复，那么表示主从服务器之间的网络连接状态正常，并且主服务器可以正常处理从服务器（客户端）发送的命令请求

**4.身份验证**

从服务器在收到主服务器返回的"PONG"回复之后，下一步要做的就是决定是否进行身份验证：
- 如果主服务器没有设置requirepass选项，并且从服务器也没有设置masterauth选项，那么主服务器将继续执行从服务器发送的命令，复制工作可以继续进行。
- 如果从服务器通过AUTH命令发送的密码和主服务器requirepass选项所设置的密码相同，那么主服务器将继续执行从服务器发送的命令，复制工作可以继续进行。与此相反，如果主从服务器设置的密码不相同，那么主服务器将返回一个invalid password错误。
- 如果主服务器设置了requirepass选项，但从服务器却没有设置masterauth选项，那么主服务器将返回一个NOAUTH错误。另一方面，如果主服务器没有设置requirepass选项，但从服务器却设置了masterauth选项，那么主服务器将返回一个no password is set错误。

**5. 发送端口信息**

在身份验证步骤之后，从服务器将执行命令 REPLCONF listening-port <port-number>，向主服务器发送从服务器的监听端口号。主服务器在接收到这个命令之后，会将端口号记录在从服务器所对应的客户端状态的 slave_listening_port 属性中

**6. 同步**

从服务器将向主服务器发送PSYNC命令，执行同步操作，并将自己的数据库更新至主服务器数据库当前所处的状态

**7. 命令传播**

主服务器只要一直将自己执行的写命令发送给从服务器，而从服务器只要一直接收并执行主服务器发来的写命令，就可以保证主从服务器一直保持一致了。

**8. 心跳检测**

命令传播阶段，从服务器默认会以每秒一次的频率，向主服务器发送 REPLCONF ACK <replication_offset> 命令。

- 检测主从的网络状态：如果主服务器超过一秒钟没有收到从服务器发来的 REPLCONF ACK 命令，那么主服务器就知道主从服务器之间的连接出现问题了

- 辅助实现 min-slaves 选项：从服务器的数量少于 min-slaves-to-write 个，或者 min-slaves-to-write 个从服务器的延迟（lag）值都大于或等于 min-slaves-max-lag 秒时，主服务器将拒绝执行写命令，可以防止主服务器在不安全的情况下执行写命令。

- 检测命令丢失：从服务器向主服务器发送 REPLCONF ACK 命令时，主服务器将发觉从服务器当前的复制偏移量少于自己的复制偏移量，然后主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。

### 4、主从复制常见问题

**1. 注意事项**

- Redis使用异步复制，但从 Redis 2.8 开始，从服务器会周期性的应答从复制流中处理的数据量。
- 一个主服务器可以有多个从服务器。
- 从服务器也可以接受其他从服务器的连接，除了多个从服务器连接到一个主服务器之外，多个从服务器也可以连接到一个从服务器上，形成一个图状结构。
- Redis 主从复制不阻塞主服务器端，也就是说当若干个从服务器在进行初始同步时，主服务器仍然可以处理请求。
- 主从复制也不阻塞从服务器端，当从服务器进行初始同步时，它使用旧版本的数据来应对查询请求，假设你在 redis.conf 配置文件是这么配置的。否则的话，你可以配置当复制流关闭时让从服务器给客户端返回一个错误。但是，当初始同步完成后，需要删除旧的数据集和加载新的数据集，在这个短暂的时间内，从服务器会阻塞连接进来的请求。
- 主从复制可以用来增强扩展性，使用多个从服务器来处理只读的请求（比如，繁重的排序操作可以放到从服务器去做），也可以简单的用来做数据冗余。
- 使用主从复制可以为主服务器免除把数据写入磁盘的消耗：在主服务器的 redis.conf 文件中配置“避免保存”（注释掉所有“保存“命令），然后连接一个置为“进行保存”的从服务器即可。但是这个配置要确保主服务器不会自动重启（要获得更多信息请阅读下一段）
- 主从复制结构，一般 slave 服务器不能进行写操作，但是这不是死的，之所以这样是为了更容易的保证主和各个从之间数据的一致性，如果 slave 服务器上数据进行了修改，那么要保证所有主从服务器都能一致，可能在结构上和处理逻辑上更为复杂。不过你也可以通过配置文件让从服务器支持写操作。
- 主从服务器之间会定期进行通话，但是如果 master 上设置了密码，那么如果不给 slave 设置密码就会导致 slave 不能跟 master 进行任何操作，所以如果你的 master 服务器上有密码，那么也给 slave 相应的设置一下密码吧（通过设置配置文件中的masterauth）;
- 关于 slave 服务器上过期键的处理，由 master 服务器负责键的过期删除处理，然后将相关删除命令已数据同步的方式同步给 slave 服务器，slave 服务器根据删除命令删除本地的key。

**2. 主服务器磁盘有限**

在的全量同步过程中，master 会将数据保存在 RDB 文件中然后发送给 slave 服务器，但是如果 master 上的磁盘空间有有限怎么办呢？

那么此时全部同步对于 master 来说将是一份十分有压力的操作了。此时可以通过无盘复制来达到目的，由 master 直接开启一个 socket 将 RDB 文件发送给 slave 服务器。无盘复制一般应用在磁盘空间有限但是网络状态良好的情况下.

**3. 当主服务器不进行持久化时复制的安全性**

在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。

为什么不持久化的主服务器自动重启非常危险呢？

为了更好的理解这个问题，看下面这个失败的例子，其中主服务器和从服务器中数据库都被删除了。

设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。

这时出现了一个崩溃，但 Redis 具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。

节点 B 和 C 从节点 A 进行复制，现在节点 A 是空的，所以节点 B 和 C 上的复制数据也会被删除。

当在高可用系统中使用 Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。

比如主服务器可能在很短的时间就完成了重启，以至于 Sentinel 都无法检测到这次失败，那么上面说的这种失败的情况就发生了。

如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。

**4. 读写分离**

从 Redis 2.6 开始，从服务器支持只读模式，并且是默认模式。这个行为是由 Redis.conf 文件中的 slave-read-only 参数控制的，可以在运行中通过 CONFIG SET 来启用或者禁用。

只读的从服务器会拒绝所有写命令，所以对从服务器不会有误写操作。但这不表示可以把从服务器实例暴露在危险的网络环境下，因为像 DEBUG 或者 CONFIG 这样的管理命令还是可以运行的。不过你可以通过使用 rename-command 命令来为这些命令改名来增加安全性。你可能想知道为什么只读限制还可以被还原，使得从服务器还可以进行写操作。虽然当主从服务器进行重新同步或者从服务器重启后，这些写操作都会失效，还是有一些使用场景会想从服务器中写入临时数据的，但将来这个特性可能会被去掉。

**5. 一主多从**

和 Mysql 主从复制的原因一样，Redis 虽然读取写入的速度都特别快，但是也会产生读压力特别大的情况。为了分担读压力，Redis 支持主从复制，Redis 的主从结构可以采用一主多从或者级联结构

问题：一个master连接多个 slave 导致 master 复制数据工作量过大。解决：Master/slave chains 的架构

**writable slave**
有些场景副本可以设置 readonly 为 false，写一些短暂的数据，例如，计算 slow Set 或者 Sorted Set 的操作并将它们存储在本地 key 中，这样当与 master 同步时可以很容易删除，或重启时也会丢失。注意，4.0 版本之前的 writable slaves 不能用 TTL 淘汰 key。自从4.0开始，writable slaves 的写入只能存储在本地（不会同步到subslaves）。

**在主从切换过程中，客户端能否正常地进行请求操作呢？**

主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。

**如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？**

一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（Redis 应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。

**fork操作**
fork 不需要拷贝父进程物理内存空间，但是会复制父进程的空间内存页表，内存页表过大会影响Redis性能；
优化：
1）优先使用物理机或者高效支持fork操作的虚拟化技术，避免使用Xen；
2）控制Redis实例最大的可用内存，fork耗时跟内存成正比，线上建议每个Redis实例内存控制再10GB以内。
3）合理配置Linux内存分配策略，避免物理内存不足导致fork失败；
4）降低fork操作的频率，如适度放宽AOF自动触发时间，避免不必要的全量复制等；


## 哨兵模式

Sentinel 本质是运行在特殊模式下的 Redis 服务器，具有监控、通知、故障转移、配置提供等功能。
是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程（progress）， 这些进程使用流言协议（gossip protocols)来接收关于主服务器是否下线的信息， 并使用投票协议（agreement protocols）来决定由谁执行自动故障迁移。


### 1、启动并初始化Sentinel

1. 使用 redis-server /path/sentinel.conf --sentinel 启动 Sentinel 服务器。
2. 初始化服务器：初始化服务器数据结构，普通服务器会载入 AOF 或 RDB，Sentinel不会。
3. 将普 Redis 服务器使用的代码替换成Sentinel专用代码：普通Redis服务器使用redis.c/redisCommandTable作为服务器的命令表，而 Sentinel 则使用 sentinel.c/sentinelcmds 作为服务器的命令表。
4. 初始化 Sentinel 状态：初始化一个 sentinel.c/sentinelState 结构，保存服务器中所有和 Sentinel 功能有关的状态。
5. 根据给定的配置文件，初始化Sentinel的监视主服务器列表：Sentinel状态中的masters字典记录了所有被Sentinel监视的主服务器的相关信息，其中：字典的键是被监视主服务器的名字，字典的值则是被监视主服务器对应的sentinel.c/sentinelRedisInstance结构。每个sentinelRedisInstance结构）代表一个被Sentinel监视的Redis服务器实例（instance）
6. 创建连向主服务器的网络连接：对于每个被Sentinel监视的主服务器来说，Sentinel会创建两个连向主服务器的异步网络连接：一个是命令连接，这个连接专门用于向主服务器发送命令，并接收命令回复。另一个是订阅连接，这个连接专门用于订阅主服务器的__sentinel__:hello频道。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-b5c3067016489ac273ea53daa4d5fd47a5a27546.png)

### 2、获取与发送信息

- Sentinel 使用每**10秒一次**发送 info 命令，从  master 获取 master自身的信息，并存储在 sentinelRedisInstance 状态结构中。同时，获取 master 关联的 slaves，封装成 sentinelRedisInstance 实例结构加入到 slaves 字典中。

slaves字典

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-0aaa934bbba0242636272cfe7b7e4840dee7c2f7.png)

- Sentinel 从 master 获取到 slaves 信息后，还会创建到 slave 的命令连接和订阅连接，也发送 info 命令给 slave 获取信息。

- Sentinel 每**2秒一次**通过命令连接向被监视的所有服务器的 __sentinel__:hello 频道发送信息 `PUBLISH sentinel: hello <s ip>,<s port>, <s runid>, <s epoch>, <m name>, <m ip>, <m port>, <m epoch>`。

- 通过订阅连接向服务器发送 SUBCRIBE __sentinel__:hello 从服务器的订阅 __sentinel__:hello 频道信息。即 Sentinels 通过该频道发送和接收信息，监视同一个服务器的多个 Sentinel 然后更新各自 sentinelRedisInstance 状态结构中的 sentinels 字典属性。

sentinels字典

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/AFC2E4E6AADA4499AD976B5622CED6B6)

- Sentinel 通过频道发现其他 Sentinel 后，还会创建连向其他 Sentinel 的命令连接，这样 Sentinels 之间使用命令连接通信，如 SENTINEL is-master-down-by-addr 命令。Sentinels 之间不会创建订阅连接。

sentinel发送和接受信息

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-e6387dd1193deb5d0efcdce04c3e250b8cfd914a.png)



### 3、主观下线和客观下线

**1. 主观下线**

主观下线（subjectively down）指的是单个 Sentinel 实例对服务器做出的下线判断；
- 默认 Sentinel 每**1秒一次**向与它命令连接的 masters、slaves、sentinels 发送 PING，通过回复判读是否主观下线。
  -实例对PING命令的回复可以分为以下两种情况：
    - 有效回复：实例返回+PONG、-LOADING、-MASTERDOWN三种回复的其中一种。
    - 无效回复：实例返回除+PONG、-LOADING、-MASTERDOWN三种回复之外的其他回复，或者在指定时限内没有返回任何回复。
- 如果一个实例在down-after-milliseconds毫秒内，连续向Sentinel返回无效回复，那么Sentinel会修改这个实例所对应的实例结构，在结构的flags属性中打开SRI_S_DOWN标识，以此来表示这个实例已经进入主观下线状态.
- 多个Sentinel设置的主观下线时长可能不同

**2. 客观下线**

客观下线（objectively down）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断. 

- 当Sentinel将一个主服务器判断为主观下线之后，为了确认这个主服务器是否真的下线了，它会向同样监视这一主服务器的其他Sentinel进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下线）.
- 通过 `SENTINEL is-master-down-by-addr <ip> <port> <current epoch> <runid> ` 命令命令询问其他Sentinel是否同意主服务器已下线。
- 收到 `SENTINEL is-master-down-by-addr <ip> <port> <current epoch> <runid> ` 回复一条 Multi Bulk 信息：down_state 代表对主服务器的检查结果，leader_runid 表示目标 Sentinel 的运行 ID，leader_epoch 是领头 Sentinel 的配置纪元。
- 收到回复的 Sentinel 将统计其他 Sentinel 同意主服务器已下线的数量，若有 quorum个（不同 Sentinels 指定的 quorum 可能不同）Sentinels 判断 master 下线，则为客观下线。
- 当这一数量达到配置指客观下线条件只适用于主服务器： 对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以从服务器或者其他 Sentinel 永远不会达到客观下线条件。


### 4、选举领头 Sentinel

Sentinel 采用 raft 算法选举领头 Sentinel：

1. 每个发现主服务器进入客观下线的Sentinel都会再次发送 SENTINEL is-master-down-by-addr <ip> <port> <current epoch> <runid> 命令请求成为它的局部领头 sentinel；
2. Sentinel 设置局部领头Sentinel的规则是先到先得：最先向目标 Sentinel 发送设置要求的源 Sentinel 将成为目标 Sentinel 的局部领头 Sentinel，而之后接收到的所有设置要求都会被目标 Sentinel 拒绝。
3. 收到命令的服务器回复一条 Nulti Bulk，回复中的 leader_runid 参数和 leader_epoch 参数分别记录了目标 Sentinel 的局部领头 Sentinel 的运行 ID 和配置纪元
4. 源 Sentinel 在接收到目标Sentinel返回的命令回复之后，会检查回复中leader_epoch参数的值和自己的配置纪元是否相同，如果相同的话，那么源 Sentinel 继续取出回复中的 leader_runid 参数，如果 leader_runid 参数的值和源 Sentinel 的运行 ID 一致，那么表示目标 Sentinel 将 源Sentinel 设置成了局部领头 Sentinel。
5. 每个 sentinel只有一次投票机会，先到先得。如果有某个 Sentinel 被半数以上的 Sentinel 设置成了局部领头 Sentinel，那么这个 Sentinel 成为领头 Sentinel.
6. 成为领头 Sentinel 需要半数以上 Sentinels 投票同意，可保证每一纪元只有一个领头 Sentinel。
7. 若给定时间内没有选举出领头，一段时间后在新纪元再次开始选举。

### 5、执行故障转移操作

1. 选出新的主服务器：
- 剔除下线或断线或最近 5 秒没回复领头 Sentinel 的 PING 命令的 slaves；
- 剔除断开连接超过 down-after-milliseconds*10 毫秒时长的 slaves；
- 然后根据优先级最高、复制偏移量最大、runID 最小排序。
- 领头 Sentinel 向被选中的 slave 发送SLAVEOF no one命令。然后每 **1秒一次（平时是每十秒一次）** INFO 命令检查是否成为 master。
2. 修改从服务器的复制目标：发送 `SLAVEOF <m_ip> <m_port>` 命令，让 slaves 改为复制新的 master。
3. 将旧的主服务器变为从服务器：因为旧的主服务器已经下线，所以这种设置是保存在server1对应的实例结构里面的，当server1重新上线时，Sentinel就会向它发送SLAVEOF命令，让它成为server2的从服务器。

### 6、Sentinel 其他问题

**1.发布与订阅信息**
客户端可以将 Sentinel 看作是一个只提供了订阅功能的 Redis 服务器： 你不可以使用 PUBLISH 命令向这个服务器发送信息， 但你可以用 SUBSCRIBE 命令或者 PSUBSCRIBE 命令， 通过订阅给定的频道来获取相应的事件提醒。
一个频道能够接收和这个频道的名字相同的事件。 比如说， 名为 +sdown 的频道就可以接收所有实例进入主观下线（SDOWN）状态的事件。
通过执行 PSUBSCRIBE * 命令可以接收所有事件信息。

TILT 模式

处理 -BUSY 状态

Sentinel，Docker 或其他形式的网络地址转换或端口映射应格外小心：Docker 执行端口重新映射，破坏 Sentinel 对其他 Sentinel 进程的自动发现以及主副本的列表。


配置

如果大多数 Sentinel 进程无法进行对话，则 Sentinel 永远不会启动故障转移。（即只有少数sentinel的情况中也没有故障转移）

quorum 参数指定需要多少个 Sentinel 同意才判定 master 失效。quorum 仅用于判断 master 故障，真正进行故障转移需要大多数的 Sentinels 的投票选举出一个领头 Sentinel 来进行

down-after-milliseconds指定判断实例主观下线的时间阈值

parallel-syncs 指定可以同时被重新配置使用新master的副本数量，该值越小，故障转移花的时间越长。但是如果该值太大，会有很多副本同时进行复制过程，而复制过程中加载来自master的数据时副本进程会阻塞，导致客户端访问延迟。


部署（几种部署方式的可用性）

只有 1 个 master1 个 slave，分别持有 sentinel（只有 2 个 Sentinel 的情况）:

当同一机器上的 master 和 sentinel 都**失效或网络断开**，因为 2 个 Sentinel 无法交流就无法达成一致进行故障转移，所以该方案不可用

如果是网络断开且单边sentinel可以进行failover不需要其他sentinel同意的情况，clients就会不确定性地往这两个master写入，当网络修复，就无法确定哪个配置正确。

1 个 master2 个 slave，分别持有 sentinel

问题：当  master 失效或与 slave断开连接，选举slave作为新的master，但是由于网络分割（master与slave无法交流），客户端连接的依然是旧的master，导致写入丢失。

解决：配置min-replicas-to-write 1 min-replicas-max-lag 10，这样当master失效不再有副本或超过max-lag副本没有发送确认消息给master，client都不会再写入。但是当2个副本都关闭了时，即使master还在工作，也不会写入，这是一个权衡。

只有1个master和1个slave，3个clients分别持有sentinel

1个master1个slave2个clients，各持有1个sentinel


## Redis集群

### 1、节点

**1. 节点状态数据结构**

每个节点的状态结构：clusterNode、clusterLink、clusterState

每个节点都保存着一个 clusterState 结构，这个结构记录了在当前节点的视角下，集群目前所处的状态，例如集群是在线还是下线，集群包含多少个节点，集群当前的配置纪元
```c
typedef struct clusterState {

    // 指向当前节点的指针
    clusterNode *myself;

    // 集群当前的配置纪元，用于实现故障转移
    uint64_t currentEpoch;

    // 集群当前的状态：是在线还是下线
    int state;

    // 集群中至少处理着一个槽的节点的数量
    int size;

    // 集群节点名单（包括 myself 节点）
    // 字典的键为节点的名字，字典的值为节点对应的 clusterNode 结构
    dict *nodes;

    // ...

} clusterState;
```

clusterState 中的 nodes 字典记录了当前节点及集群中其他节点的 clusterNode 信息，clusterNode 结构保存了一个节点的当前状态，比如节点的创建时间、节点的名字、节点当前的配置纪元、节点的IP地址和端口号等等。
```c
struct clusterNode {

    // 创建节点的时间
    mstime_t ctime;

    // 节点的名字，由 40 个十六进制字符组成
    // 例如 68eef66df23420a5862208ef5b1a7005b806f2ff
    char name[REDIS_CLUSTER_NAMELEN];

    // 节点标识
    // 使用各种不同的标识值记录节点的角色（比如主节点或者从节点），
    // 以及节点目前所处的状态（比如在线或者下线）。
    int flags;

    // 节点当前的配置纪元，用于实现故障转移
    uint64_t configEpoch;

    // 节点的 IP 地址
    char ip[REDIS_IP_STR_LEN];

    // 节点的端口号
    int port;

    // 保存连接节点所需的有关信息
    clusterLink *link;

    // ...

} clusterNode;
```
clusterNode 结构的 link属性是一个 clusterLink 结构，该结构保存了连接节点所需的有关信息，比如套接字描述符，输入缓冲区和输出缓冲区
```c
typedef struct clusterLink {

    // 连接的创建时间
    mstime_t ctime;

    // TCP 套接字描述符
    int fd;

    // 输出缓冲区，保存着等待发送给其他节点的消息（message）。
    sds sndbuf;

    // 输入缓冲区，保存着从其他节点接收到的消息。
    sds rcvbuf;

    // 与这个连接相关联的节点，如果没有的话就为 NULL
    struct clusterNode *node;

} clusterLink;
```

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-9918e854bcc7de909d8ddac20b76618568e75723.png)

**2. CLUSTER MEET命令实现**

向节点 A 发送 CLUSTER MEET 命令， CLUSTER MEET <B_ip> <B_port>

- 节点 A 会为节点 B 创建一个 clusterNode 结构， 并将该结构添加到自己的 clusterState.nodes 字典里面。
- 节点 A 将根据 CLUSTER MEET 命令给定的 IP 地址和端口号， 向节点 B 发送一条 MEET 消息（message）。
- 节点 B 将接收到节点 A 发送的 MEET 消息， 节点 B 会为节点 A 创建一个 clusterNode 结构， 并将该结构添加到自己的 clusterState.nodes 字典里面。
- 节点 B 将向节点 A 返回一条 PONG 消息。
- 节点 A 将接收到节点 B 返回的 PONG 消息， 通过这条 PONG 消息节点 A 可以知道节点 B 已经成功地接收到了自己发送的 MEET 消息。
- 节点 A 将向节点 B 返回一条 PING 消息。节点 B 将接收到节点 A 返回的 PING 消息， 通过这条 PING 消息节点 B 可以知道节点 A 已经成功地接收到了自己返回的 PONG 消息， 握手完成。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-c3f19dd40ff14db891e429fb5d9e9a80182aa3ca.png)

之后， 节点 A 会将节点 B 的信息通过 Gossip 协议传播给集群中的其他节点， 让其他节点也与节点 B 进行握手， 最终， 经过一段时间之后， 节点 B 会被集群中的所有节点认识。

节点只能使用0号数据库。

### 2、槽指派

Redis集群通过分片的方式来保存数据库中的键值对：集群的整个数据库被分为16384个槽（slot），数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点可以处理0个或最多16384个槽。
当数据库中的16384个槽都有节点在处理时，集群处于上线状态（ok）；相反地，如果数据库中有任何一个槽没有得到处理，那么集群处于下线状态（fail）。

**1. 记录节点的槽指派信息**

clusterNode.slots 属性是一个 16384 bits 的二进制位数组，如果slots数组在索引i上的二进制位的值为1，那么表示节点负责处理槽i。clusterNode.numslot属性记录了节点负责处理的槽点个数;

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-f4e2ea85d79cfa546d741dfc6eb759c914b8238c.png)

**2. 传播节点的槽指派信息**

一个节点除了会将自己负责处理的槽记录在 clusterNode 结构的 slots 属性和 numslots 属性之外，它还会将自己的 slots 数组通过消息发送给集群中的其他节点，以此来告知其他节点自己目前负责处理哪些槽。当节点 A 通过消息从节点 B 那里接收到节点 B 的 slots 数组时，节点 A 会在自己的 clusterState.nodes 字典中查找节点 B 对应的 clusterNode 结构，并对结构中的 slots 数组进行保存或者更新

**3. 记录集群所有槽的指派信息**

clusterState.slots数组记录了集群中所有 16384 个槽的指派信息,slots数组包含16384个项，每个数组项都是一个指向 clusterNode 结构的指针, 如果 slots[i] 指针指向一个 clusterNode 结构，那么表示槽i已经指派给了clusterNode结构所代表的节点

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/9CC9F08910E34995857F88F78C020DF0)

**4. CLUSTER ADDSLOTS**

CLUSTER ADDSLOTS <slot> [slots...] 命令接受一个或多个槽作为参数，并将所有输入的槽指派给接收该命令的节点负责.

**5. 计算键属于哪个槽节点**

CRC16(key) & 16383 通过 CRC16（key）计算键key的CRC-16校验和，& 16383 计算出一个介于 0 至 16383 之间的整数作为键 key 的槽号

**6. 判断槽是否由当前节点负责处理**

当节点计算出键所属的槽i之后，节点就会检查自己在clusterState.slots数组中的项i，判断键所在的槽是否由自己负责：1）如果clusterState.slots[i] 等于 clusterState.myself，那么说明槽i由当前节点负责，节点可以执行客户端发送的命令。否则，节点会根据clusterState.slots[i] 指向的 clusterNode 结构所记录的节点IP和端口号，向客户端返回 MOVED 错误，指引客户端转向至正在处理槽i的节点。

**7. 节点数据库的实现**


节点和单机服务器在数据库方面的一个区别是，节点只能使用0号数据库，而单机Redis服务器则没有这一限制

另外，集群除了将键值对保存在数据库，节点还会用 clusterState.slots_to_keys 跳跃表来保存槽和键之间的关系。这样可以方便地对属于某些槽的所有键批量操作。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-7d8c052c7993e1861781c7f3191c28d8aca8318b.png)

slots_to_keys跳跃表每个节点的分值（score）都是一个槽号，而每个节点的成员（member）都是一个数据库键：
- 每当节点往数据库中添加一个新的键值对时，节点就会将这个键以及键的槽号关联到slots_to_keys跳跃表。
- 当节点删除数据库中的某个键值对时，节点就会 在slots_to_keys 跳跃表解除被删除键与槽号的关联。

### 3、重新分片

Redis集群的重新分片操作可以将任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点），并且相关槽所属的键值对也会从源节点被移动到目标节点。重新分片操作可以在线（online）进行，在重新分片的过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求

重新分片的实现原理Redis集群的重新分片操作是由Redis的集群管理软件redis-trib负责执行的，Redis提供了进行重新分片所需的所有命令，而redis-trib则通过向源节点和目标节点发送命令来进行重新分片操作。redis-trib对集群的单个槽slot进行重新分片的步骤如下：

**1. 重新分片原理**

- redis-trib对目标节点发送CLUSTER SETSLOT＜slot＞IMPORTING＜source_id＞命令，让目标节点准备好从源节点导入（import）属于槽slot的键值对。
- redis-trib对源节点发送CLUSTER SETSLOT＜slot＞MIGRATING＜target_id＞命令，让源节点准备好将属于槽slot的键值对迁移（migrate）至目标节点。
- redis-trib向源节点发送CLUSTER GETKEYSINSLOT＜slot＞＜count＞命令，获得最多count个属于槽slot的键值对的键名（key name）。
- 对于步骤3获得的每个键名，redis-trib都向源节点发送一个MIGRATE＜target_ip＞＜target_port＞＜key_name＞0＜timeout＞命令，将被选中的键原子地从源节点迁移至目标节点。
- 重复执行步骤3和步骤4，直到源节点保存的所有属于槽slot的键值对都被迁移至目标节点为止。每次迁移键的过程如图17-24所示。
- redis-trib向集群中的任意一个节点发送CLUSTER SETSLOT＜slot＞NODE＜target_id＞命令，将槽slot指派给目标节点，这一指派信息会通过消息发送至整个集群，最终集群中的所有节点都会知道槽slot已经指派给了目标节点。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-fba74127c3849e540cea49200ee809b01f8c8a27.png)

**2、ASK 错误**

如果节点收到一个关于键key的命令请求，并且键key所属的槽i正好就指派给了这个节点，那么节点会尝试在自己的数据库里查找键key，如果找到了的话，节点就直接执行客户端发送的命令。

与此相反，如果节点没有在自己的数据库里找到键key，那么节点会检查自己的clusterState.migrating_slots_to[i]，看键key所属的槽i是否正在进行迁移，如果槽i的确在进行迁移的话，那么节点会向客户端发送一个ASK错误，引导客户端到正在导入槽i的节点去查找键key。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/graphviz-e2c71f49318a6636a74534d4517ffa173c27dae0.png)


### 4、复制和故障转移


**1. 设置从节点**

- CLUSTER REPLICATE <node_id> 命令将节点设置为 <nodo_id> 的从节点，接收到该命令的节点首先会在自己的clusterState.nodes字典中找到node_id所对应节点的clusterNode结构，并将自己的clusterState.myself.slaveof指针指向这个结构，以此来记录这个节点正在复制的主节点
- 然后节点会修改自己在clusterState.myself.flags中的属性，关闭原本的REDIS_NODE_MASTER标识，打开REDIS_NODE_SLAVE标识，表示这个节点已经由原来的主节点变成了从节
- 节点调用复制代码，并根据 clusterState.myself.slaveof 指向的 clusterNode 结构所保存的IP地址和端口号，对主节点进行复制。
- 一个节点成为从节点，并开始复制某个主节点这一信息会通过消息发送给集群中的其他节点，最终集群中的所有节点都会知道某个从节点正在复制某个主节点。集群中的所有节点都会在代表主节点的clusterNode结构的slaves属性和numslaves属性中记录正在复制这个主节点的从节点名单

**2. 故障检测**

集群中的每个节点都会定期地向集群中的其他节点发送PING消息，以此来检测对方是否在线，如果接收PING消息的节点没有在规定的时间内，向发送PING消息的节点返回PONG消息，那么发送PING消息的节点就会将接收PING消息的节点标记为疑似下线（probable fail，PFAIL）。

集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息，例如某个节点是处于在线状态、疑似下线状态（PFAIL），还是已下线状态（FAIL）。当一个主节点A通过消息得知主节点B认为主节点C进入了疑似下线状态时，主节点A会在自己的clusterState.nodes字典中找到主节点C所对应的clusterNode结构，并将主节点B的下线报告（failure report）添加到clusterNode结构的fail_reports链表里面

如果在一个集群里面，半数以上负责处理槽的主节点都将某个主节点x报告为疑似下线，那么这个主节点x将被标记为已下线（FAIL），将主节点x标记为已下线的节点会向集群广播一条关于主节点x的FAIL消息，所有收到这条FAIL消息的节点都会立即将主节点x标记为已下线。

**3. 故障转移**

当一个从节点发现自己正在复制的主节点进入了已下线状态时，从节点将开始对下线主节点进行故障转移，以下是故障转移的执行步骤：
- 复制下线主节点的所有从节点里面，会有一个从节点被选中。2
- 被选中的从节点会执行SLAVEOF no one命令，成为新的主节点。
- 新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己。
- 新的主节点向集群广播一条PONG消息，这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点，并且这个主节点已经接管了原本由已下线节点负责处理的槽。
- 新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。17.6.4 

选举新的主节点新的主节点是通过选举产生的。以下是集群选举新的主节点的方法：
- 集群的配置纪元是一个自增计数器，它的初始值为0。
- 当集群里的某个节点开始一次故障转移操作时，集群配置纪元的值会被增一。
- 对于每个配置纪元，集群里每个负责处理槽的主节点都有一次投票的机会，而第一个向主节点要求投票的从节点将获得主节点的投票。
- 当从节点发现自己正在复制的主节点进入已下线状态时，从节点会向集群广播一条CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST消息，要求所有收到这条消息、并且并且具有投票权的主节点向这个从节点投票。
- 如果一个主节点具有投票权（它正在负责处理槽），并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，表示这个主节点支持从节点成为新的主节点。
- 每个参与选举的从节点都会接收CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持。7
- 如果集群里有N个具有投票权的主节点，那么当一个从节点收集到大于等于N/2+1张支持票时，这个从节点就会当选为新的主节点。
- 因为在每一个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有N个主节点进行投票，那么具有大于等于N/2+1张支持票的从节点只会有一个，这确保了新的主节点只会有一个。
- 如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/5ecd4d30e401fd268dd3c27a)


### 5、消息

各个节点间采用gossip协议通过发送和接收消息进行通信。
主要5种消息：MEET、PING、PONG、FAIL、PUBLISH。
一条消息由消息头和消息正文组成。

### 6、集群其他问题

**1. 哈希分区方式**

1. 节点取余分区。hash 算法一般使用 hash(key)%N 的方式将键映射到节点上，优点简单常见于分库分表，扩容采用节点翻倍的方式可以只迁移50%的数据，缺点当增删节点时会有大量缓存重建，所以可以预分区；

2. 一致性 hash 分区。一般把0-32^2范围的哈希值组成一个哈希环，将节点映射到哈希环上，然后key映射到哈希环上，数据存储在顺时针寻找到的第一个节点上。虚拟节点（自动负载均衡）

3. 虚拟槽分区。如redis cluster

数据分区规则一般有哈希分区和顺序分区

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/5ed0ac7f0791290fe092dcd9)

- 对于主进程是单线程工作的Redis，只运行一个实例就显得有些浪费。同时，管理一个巨大内存不如管理相对较小的内存高效。因此，实际使用中，通常一台机器上同时跑多个Redis实例。

- hashtag。通过合理命名key，可以将一组相关联的key放入同一个Redis节点，这在避免跨节点访问相关数据时很重要。

**2. Redis的集群方案**

**Redis官方集群方案 redis cluster。**

redis cluster 是查询路由方式和客户端分区方式的混合，查询随机一个实例，如果不是要访问的实例，就返回客户端正确实例的信息，客户端再重定向到正确节点。节点之间使用cluster bus通信，使用gossip协议。

**Redis sharding 集群**
客户端sharding方式，一般采用**一致性哈希**算法进行分区。但是水平扩容缩容麻烦，会导致一部分键不匹配，可以采用**Presharding**技术。

**中间件 proxy 实现大规模集群**
如，twemproxy、codis(支持多线程)。



