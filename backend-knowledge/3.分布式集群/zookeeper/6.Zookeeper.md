# Zookeeper

[toc]

## 是什么

Zookeeper 是一个开源的分布式的，为分布式应用提供协调服务的 Apache 项目。ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用

Zookeeper 从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架， 它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式
Zookeeper=文件系统+通知机制

## 能做什么

分布式消息同步和协调机制、服务器节点动态上下线、统一配置管理、负载均衡、集群管理等、分布式锁和分布式队

Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心(提供发布订阅服务)。

## 为什么存在

Zookeeper（业界简称zk）是一种提供配置管理、分布式协同以及命名的中心化服务，这些提供的功能都是分布式系统中非常底层且必不可少的基本功能，但是如果自己实现这些功能而且要达到高吞吐、低延迟同时还要保持一致性和可用性，实际上非常困难。因此zookeeper提供了这些功能，开发者在zookeeper之上构建自己的各种分布式系统。

## 原理及工作流程

### 1、数据如何存储

既然是“文件系统”，那么数据是怎么存取的呢？

![img](http://cdn.processon.com/60599a5c637689700772d168)

ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。
很显然 zookeeper 集群自身维护了一套数据结构。这个存储结构是一个树形结构，其上的每一个节点，我们称之为"znode"，每一个 znode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识

- 节点类型

1. 持久化目录节点（PERSISTENT）
	客户端与zookeeper 断开连接后，该节点依旧存在
2. 持久化顺序编号目录节点（PERSISTENT_SEQUENTIAL）
	客户端与 zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号
3. 临时目录节点（EPHEMERAL）
	客户端与zookeeper 断开连接后，该节点被删除
4. 临时顺序编号目录节点（EPHEMERAL_SEQUENTIAL）
	客户端与 zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号

* 创建 znode 时设置顺序标识，znode 名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护
* 在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序

- stat 结构

1. czxid- 引起这个znode 创建的 zxid，创建节点的事务的 zxid每次修改 ZooKeeper 状态都会收到一个 zxid 形式的时间戳，也就是 ZooKeeper 事务 ID。事务 ID 是 ZooKeeper 中所有修改总的次序。每个修改都有唯一的 zxid，如果 zxid1 小于 zxid2，那么zxid1 在 zxid2 之前发生。
2. ctime - znode 被创建的毫秒数(从 1970 年开始) 3）mzxid - znode 最后更新的 zxid
3. mzxid - znode 最后更新的 zxid
4. mtime - znode 最后修改的毫秒数(从 1970 年开始) 
5. pZxid-znode 最后更新的子节点zxid
6. cversion - znode 子节点变化号，znode 子节点修改次数
7. dataversion - znode 数据变化号
8. aclVersion - znode 访问控制列表的变化号
9. ephemeralOwner- 如果是临时节点，这个是 znode 拥有者的 session id。如果不是临时节点则是 0。
10. dataLength- znode 的数据长度
11. numChildren - znode 子节点数量



### 2、ZAB协议

ZAB协议包括两种基本的模式，分别是 崩溃恢复和消息广播。当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。

为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。

当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。 当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。正如上文介绍中所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。



### 3、集群及选举机制

![img](http://cdn.processon.com/60599a5c637689700772d16a)

1、 选举机制
当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。这个过程大致是这样的：

1. Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。
2. Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。
3. Synchronization（同步阶段）:同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。
4. Broadcast（广播阶段） 到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。

**注：**
* 半数机制（Paxos 协议）：集群中半数以上机器存活，集群可用。所以 zookeeper;适合装在奇数台机器上。
* Zookeeper 虽然在配置文件中并没有指定 master 和 slave。但是，zookeeper 工作时， 是有一个节点为 leader，其他则为 follower，Leader 是通过内部的选举机制临时产生的

**示例**
以一个简单的例子来说明整个选举的过程。假设有五台服务器组成的 zookeeper 集群，它们的 id 从 1-5，同时它们都是最新启动的， 也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。
![集群选举机制](./集群及选举机制.png)
1. 服务器 1 启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是 LOOKING 状态。
2. 服务器 2 启动，它与最开始启动的服务器 1 进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以 id 值较大的服务器 2 胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是 3)，所以服务器 1、2 还是继续保持 LOOKING 状态。
3. 服务器 3 启动，根据前面的理论分析，服务器 3 成为服务器 1、2、3 中的老大， 而与上面不同的是，此时有三台服务器选举了它，所以它成为了这次选举的 leader。
4. 服务器 4 启动，根据前面的分析，理论上服务器 4 应该是服务器 1、2、3、4 中最大的，但是由于前面已经有半数以上的服务器选举了服务器 3，所以它只能接收当小弟的命了。
5. 服务器 5 启动，同 4 作为fallower


### 4、监听原理

![img](http://cdn.processon.com/60599a5c637689700772d169)

1. 首先要有一个 main()线程
2. 在 main 线程中创建 Zookeeper 客户端，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）。
3. 通过 connect 线程将注册的监听事件发送给 Zookeeper。
4. 在 Zookeeper 的注册监听器列表中将注册的监听事件添加到列表中。
5. Zookeeper 监听到有数据或路径变化，就会将这个消息发送给 listener 线程。
6. listener 线程内部调用了 process（）方法。

######## 2、常见的监听

1. 监听节点数据的变化：
	get path [watch]

2. 监听子节点增减的变化
	ls path [watch]
<!--/Note-->

### 5、写数据流程

![img](http://cdn.processon.com/60599a5b637689700772d165)

1. 比如 Client 向 ZooKeeper 的 Server1 上写数据，发送一个写请求。
2. 如果 Server1 不是 Leader，那么 Server1 会把接受到的请求进一步转发给 Leader，因为每个 ZooKeeper 的 Server 里面有一个是 Leader。这个 Leader 会将写请求广播给各个Server，比如 Server1 和 Server2， 各个 Server 写成功后就会通知 Leader。
3. 当 Leader 收到大多数 Server 数据写成功了，那么就说明数据写成功了。如果这里三个节点的话，只要有两个节点数据写成功了，那么就认为数据写成功了。写成功之后， Leader 会告诉 Server1 数据写成功了。
4. Server1 会进一步通知 Client  数据写成功了，这时就认为整个写操作成功。ZooKeeper整个写数据流程就是这样的。

## 怎么做

### 1、安装及配置文件

1. tickTime：通信心跳数
	Zookeeper服务器心跳时间，单位毫秒Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔， 也就是每个tickTime时间就会发送一个心跳，时间单位为毫秒。它用于心跳机制，并且设置最小的session超时时间为两倍心跳时间。(session的最小超时时间是2*tickTime)
2. initLimit：LF初始通信时限
	集群中的follower跟随者服务器(F)与leader领导者服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连接到Leader的时限。投票选举新leader的初始化时间Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在initLimit时间内完成这个工作。
3. syncLimit：LF 同步通信时限
	集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit * tickTime， Leader认为Follwer死掉，从服务器列表中删除Follwer。在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那收到响应，那么就认为这个F已经不在线了。
4. dataDir：数据文件目录+数据持久化路径保存内存数据库快照信息的位置，如果没有其他说明，更新的事务日志也保存到数据库。
5. clientPort：客户端连接端口监听客户端连接的端口

#### 2、集群搭建

1. 增加如下配置
#############cluster#######	
server.2=192.168.100.128:2888:3888
server.3=192.168.100.129:2888:3888
server.4=192.168.100.130:2888:3888
2. 配置参数解读
	Server.A=B:C:D。
* A 是一个数字，表示这个是第几号服务器；
* B 是这个服务器的 ip 地址；
* C 是这个服务器与集群中的 Leader 服务器交换信息的端口；
* D 是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。

3. 创建myid文件
集群模式下配置一个文件myid，这个文件在dataDir 目录下，这个文件里面有一个数据就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个 server。
在/opt/module/zookeeper-3.4.10/zkData 目录下创建一个 myid 的文件
touch myid
myid的内容就是A值


### 3、基本操作

1. 启动zookeeper
$ ./bin/zkServer.sh start
2. 查看进程是否启动
$ jps 
$ Jps 4001 QuorumPeerMain
3. 查看状态：
$ bin/zkServer.sh status ZooKeeper JMX enabled by default
Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg Mode: standalone
4. 启动客户端：
$ bin/zkCli.sh
（5）退出客户端：
[zk: localhost:2181(CONNECTED) 0] quit
（6）停止zookeeper
$ bin/zkServer.sh stop



### 4、分布式锁实现

有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 

对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。 

对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。

curator这个开源项目提供的zookeeper分布式锁实现

### 5、Dubbo注册中心

## 特点/影响/建议

* ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。
* ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）
* ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。
* ZooKeeper 底层其实只提供了两个功能：①管理（存储、读取）用户程序提交的数据；②为用户程序提供数据节点监听服务。


