# 计算机操作系统 - 内存管理
[toc]

## 存储器

### 1、存储器概述

越靠近 CPU 核⼼的缓存其访问速度越快，CPU 访问 L1 Cache 只需要 2~4 个时钟周期，访问 L2 Cache⼤约 10~20 个时钟周期，访问 L3 Cache ⼤约 20~60 个时钟周期，⽽访问内存速度⼤概在 200~300个 时钟周期之间。

![image-20210808142054928](C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20210808142054928.png)

寄存器：常⻅的寄存器种类：

- 通⽤寄存器，⽤来存放需要进⾏运算的数据，⽐如需要进⾏加和运算的两个数据。
- 程序计数器，⽤来存储 CPU 要执⾏下⼀条指令「所在的内存地址」，注意不是存储了下⼀条要执⾏的指令，此时指令还在内存中，程序计数器只是存储了下⼀条指令的地址。
- 指令寄存器，⽤来存放程序计数器指向的指令，也就是指令本身，指令被执⾏完成之前，指令都存储在这⾥。

高速缓存：CPU Cache 通常会分为 **L1**、**L2**、**L3** 三层

- L1 ⾼速缓存的访问速度⼏乎和寄存器⼀样快，通常只需要 2~4 个时钟周期，⽽⼤⼩在⼏⼗ KB 到⼏百 KB 不等。每个 CPU 核⼼都有⼀块属于⾃⼰的 L1 ⾼速缓存，指令和数据在 L1 是分开存放的，所以 L1 ⾼速缓存通常分成指令缓存和数据缓存。
- L2 ⾼速缓存同样每个 CPU 核⼼都有，但是 L2 ⾼速缓存位置⽐ L1 ⾼速缓存距离 CPU 核⼼ 更远，它⼤⼩⽐ L1 ⾼速缓存更⼤，CPU 型号不同⼤⼩也就不同，通常⼤⼩在⼏百 KB 到⼏ MB 不等，访问速度则更慢，速度在 10~20 个时钟周期。
- L3 ⾼速缓存通常是多个 CPU 核⼼共⽤的，位置⽐ L2 ⾼速缓存距离 CPU 核⼼ 更远，⼤⼩也会更⼤些，通常⼤⼩在⼏ MB 到⼏⼗ MB 不等，具体值根据 CPU 型号⽽定。访问速度相对也⽐较慢⼀些，访问速度在 20~60 个时钟周期。

内存：内存⽤的芯⽚和 CPU Cache 有所不同，它使⽤的是⼀种叫作 **DRAM** （**Dynamic Random Access**

**Memory**，动态随机存取存储器） 的芯⽚。

**SSD/HDD** 硬盘：SSD（*Solid-state disk*） 就是我们常说的固体硬盘，结构和内存类似，但是它相⽐内存的优点是断电后数据还是存在的，⽽内存、寄存器、⾼速缓存断电后数据都会丢失。内存的读写速度⽐ SSD ⼤概 10~1000 倍。还有⼀款传统的硬盘，也就是机械硬盘（*Hard Disk Drive, HDD*），它是通过物理读写的⽅式来访问

数据的，因此它访问速度是⾮常慢的，它的速度⽐内存慢 10W 倍左右。

**SSD** 比机械硬盘快 **70** 倍左右；内存比机械硬盘快 **100000** 倍左右；**CPU L1 Cache** 比机械硬盘快 **10000000** 倍左右；

每个存储器只和相邻的⼀层存储器设备打交道，当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 ⾼速缓存，如果 L1 没有，则查询 L2 ⾼速缓存，L2 还是没有的话就查询 L3 ⾼速缓存，L3 依然没有的话，才去内存中取数据。

### 2、CPU Cache

CPU 读取数据的时候，⽆论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache中找不到数据时，才会去访问内存，并把内存中的数据读⼊到 Cache 中，CPU 再从 CPU Cache 读取数据。CPU Cache 是由很多个 Cache Line 组成的，CPU Line 是 CPU从内存读取数据的基本单位，⽽ CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成，你可以在

下图清晰的看到：

Cache Line 由 组标记，有效位以及数据组成：

![image-20210808151810092](C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20210808151810092.png)

1. 根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Line 的地址；

2. 找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是⽆效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执⾏；

3. 对⽐内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执⾏；

4. 根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字。

### 3、缓存一致性

**1.CPU Cache 与内存一致性**

那么如果数据写⼊ Cache 之后，内存与 Cache 相对应的数据将会不同，这种情况下 Cache 和内存数据都不⼀致了。通过两种方式保持CPU Cache 和 内存的一致性：写直达（*Write Through*），写回（*Write Back*）。

**写直达**：保持内存与 Cache ⼀致性最简单的⽅式是，把数据同时写⼊内存和 **Cache** 中，这种⽅法称为写直达（Write Through）。

写⼊前会先判断数据是否已经在 CPU Cache ⾥⾯了：如果数据已经在 Cache ⾥⾯，先将数据更新到 Cache ⾥⾯，再写⼊到内存⾥⾯；如果数据没有在 Cache ⾥⾯，就直接把数据更新到内存⾥⾯。

⽆论数据在不在 Cache ⾥⾯，每次写操作都会写回到内存，这样写操作将会花费⼤量的时间，⽆疑性能会受到很⼤的影响。

**写回**：写回机制中，当发⽣写操作时，新的数据仅仅被写⼊ Cache Block ⾥，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率，这样便可以提⾼系统的性能。在 CPU 都是多核的，由于 L1/L2 Cache 是多个核⼼各⾃独有的，那么会带来多核⼼的缓存⼀致性（Cache Coherence） 的问题，如果不能保证缓存⼀致性的问题，就可能造成结果错误。

- 写数据时，如果数据已经在 CPU Cache ⾥的话，则把数据更新到 CPU Cache ⾥，同时标记CPU Cache ⾥的这个 Cache Block 为脏（Dirty）的，不需要将数据写到内存；
- 写数据时，如果数据所对应的 Cache Block ⾥存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block ⾥的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block⾥的数据写回到内存，然后再把当前要写⼊的数据，写⼊到这个 Cache Block ⾥，同时也把它标记为脏的；如果 Cache Block ⾥⾯的数据没有被标记为脏，则就直接将数据写⼊到这个 Cache Block⾥，然后再把这个 Cache Block 标记为脏的就好了。

**2.多核CPU Cache 一致性**

![img](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210808154007451.png)

A/B 两个CPU同时对变量 i 执行自加操作，从内存读取到 i = 1并保存到 CPU Cache 中
根据写回策略，A 执行完自加写入 CPU Cache 并标记相应的 Cache Line 为 dirty，但是并没有写入内存中这时旁边的 B 号核⼼尝试从内存读取 i 变量的值，则读到的将会是错误的值，因为刚才 A 号核⼼更新i 值还没写⼊到内存中，内存中的值还依然是 0。

这个就是所谓的缓存⼀致性问题，**A** 号核⼼和 **B** 号核⼼的缓存，在这个时候是不⼀致，从⽽会导致执⾏结果的错误。要想实现缓存⼀致性，关键是要满⾜ 2 点：

- 第⼀点是写传播，也就是当某个 CPU 核⼼发⽣写⼊操作时，需要把该事件⼴播通知给其他核⼼；
- 第⼆点是事物的串⾏化，这个很重要，只有保证了这个，才能保障我们的数据是真正⼀致的，我们的程序在各个不同的核⼼上运⾏的结果也是⼀致的；

基于总线嗅探机制的 MESI 协议，就满⾜上⾯了这两点，因此它是保障缓存⼀致性的协议。

总线嗅探：例如，当 A 号 CPU 核⼼修改了 L1 Cache 中 i 变量的值，通过总线把这个事件⼴播通知给其他所有的核⼼，然后每个 CPU 核⼼都会监听总线上的⼴播事件，并检查是否有相同的数据在⾃⼰的 L1 Cache ⾥⾯，如果 B 号 CPU 核⼼的 L1 Cache 中有该数据，那么也需要把该数据更新到⾃⼰的 L1 Cache。总线嗅探只保证了写传播，没有保证事务的串行化。

MESI 协议：MESI 协议，是已修改、独占、共享、已实现这四个状态的英⽂缩写的组合。

已修改：代表该 Cache Line上的数据已经被更新过，但是还没有写到内存⾥。

独占：独占状态的时候，数据只存储在⼀个 CPU 核⼼的 Cache ⾥，并且数据没有被修改；

共享：状态代表着相同的数据在多个 CPU 核⼼的 Cache ⾥都有，并且数据没有被修改；所以当我们要更新 Cache ⾥⾯的数据的时候，不能直接修改，⽽是要先向所有的其他 CPU 核⼼⼴播⼀个请求，要求先把其他核⼼的Cache 中对应的 Cache Line 标记为「⽆效」状态，然后再更新当前 Cache ⾥⾯的数据。

已失效：表示的是这个 Cache Block ⾥的数据已经失效了，不可以读取该状态的数据。

整个 MSI 状态的变更，则是根据来⾃本地 CPU 核⼼的请求，或者来⾃其他 CPU 核⼼通过总线传输过来的请求，从⽽构成⼀个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送⼴播给其他 CPU 核⼼。

### 4、伪共享问题

现在假设有⼀个双核⼼的 CPU，这两个 CPU 核⼼并⾏运⾏着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是类型为 long 的变量 A 和 B，这个两个数据的地址在物理内存上是连续的，如果Cahce Line 的⼤⼩是 64 字节，并且变量 A 在 Cahce Line 的开头位置，那么这两个数据是位于同⼀个**Cache Line** 中，⼜因为 CPU Line 是 CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读⼊到了两个 CPU 核⼼中各⾃ Cache 中。

![image-20210808160623075](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210808160623075.png)

如果这两个不同核⼼的线程分别不停的修改不同的数据，⽐如 1 号 CPU 核⼼的线程只修改了 变量 A，或 2 号 CPU 核⼼的线程的线程只修改了变量 B。

根据基于总线嗅探的MESI协议，核心 1 修改 A 变量，则核心 2 中相应 Cache Line 失效，核心 2 读取变量B就只能从内存读取，然后修改导致核心 1 中的Cache  Line 失效，核心 1再次修改 A变量也只能从 内存读取并修改……如此往复，不会命中 CPU Cache，导致性能低下。

**这种因为多个线程同时读写同⼀个 Cache Line 的不同变量时，⽽导致 CPU Cache 失效的现象称为伪共享（False Sharing）。**

伪共享问题解决方式：

 Linux 内核中存在 __cacheline_aligned_in_smp 宏定义，是⽤于解决伪共享的问题，这个宏定义使得变量在 Cache Line ⾥是对⻬的。

有⼀个 Java 并发框架 Disruptor 使⽤「字节填充 + 继承」的⽅式，来避免伪共享的问题。RingBuffer 类会经常被多个线程使⽤：

RingBufferPad 中的 7个 long 类型数据作为 Cache Line 前置填充，⽽ RingBuffer 中的 7 个 long 类型数据则作为 Cache Line 后置填充，这 14 个 long 变量没有任何实际⽤途，更不会对它们进⾏读写操作。

![image-20210808162301069](C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20210808162301069.png)



## 虚拟内存

### 1、页

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0\~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

其实虚拟内存技术从某种角度来看的话，很像是糅合了基址寄存器和界限寄存器之后的新技术。它使得整个进程的地址空间可以通过较小的虚拟单元映射到物理内存，而不需要为程序的代码和数据地址进行重定位。

### 2、页表

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

页表由多个页表项（Page Table Entry, 简称 PTE）组成，页表项的结构取决于机器架构，不过基本上都大同小异。一般来说页表项中都会存储物理页框号、修改位、访问位、保护位和 "在/不在" 位（有效位）等信息。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

![page_tables](C:/Users/Administrator/Pictures/Camera%20Roll/page_tables.jpg)

CPU 则是把这些虚拟地址通过地址总线送到内存管理单元（Memory Management Unit，简称 MMU），MMU 将虚拟地址翻译成物理地址之后再通过内存总线去访问物理内存

### 3、多级页表

单页表的缺陷：在 32 位的环境下，虚拟地址空间共有 4GB，假设⼀个⻚的⼤⼩是 4KB（2^12），那么就需要⼤约 100 万 （2^20） 个⻚，每个「⻚表项」需要 4 个字节⼤⼩来存储，那么整个 4GB 空间的映射就需要有 4MB的内存来存储⻚表。每个进程都是有⾃⼰的虚拟地址空间的，也就说都有⾃⼰的⻚表，100个进程就需要400M。

要解决上⾯的问题，就需要采⽤⼀种叫作多级⻚表（*Multi-Level Page Table*）的解决⽅案。对于 64 位的系统，两级分⻚肯定不够了，就变成了四级⽬录，分别是：全局⻚⽬录项 PGD（*Page Global Directory*）；上层⻚⽬录项 PUD（*Page Upper Directory*）；中间⻚⽬录项 PMD（*Page Middle Directory*）；⻚表项 PTE（*Page Table Entry*）；通过全局页表目录项找到上层目录项，上级目录项找到中间页目录项，中间页目录项找到页表项。

![image-20210808171107173](C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20210808171107173.png)

⼀级⻚表覆盖到了全部虚拟地址空间，二级页表按需创建：如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。假设只有 20% 的⼀级⻚表项被⽤到了，那么⻚表占⽤的内存空间就只有 4KB（⼀级⻚表） + 20% *4MB（⼆级⻚表）= 0.804MB ，这对⽐单级⻚表的 4MB 是⼀个巨⼤的节约。

### 4、TLB 快表

多级⻚表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了⼏道转换的⼯序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。在 CPU 芯⽚中，加⼊了⼀个专⻔存放程序最常访问的⻚表项的 Cache，这个 Cache 就是 TLB（*Translation Lookaside Buffer*） ，通常称为⻚表缓存、转址旁路缓存、快表等。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的⻚表。

![image-20210808171847993](https://gitee.com/bruceyum/pictures/raw/master/pics/image-20210808171847993.png)



### 5、寻址流程

在 MMU 进行地址转换时，如果页表项的有效位是 0，则表示该页面并没有映射到真实的物理页框号 PPN，则会引发一个**缺页中断**，CPU 陷入操作系统内核，接着操作系统就会通过页面置换算法选择一个页面将其换出 (swap)，以便为即将调入的新页面腾出位置，如果要换出的页面的页表项里的修改位已经被设置过，也就是被更新过，则这是一个脏页 (Dirty Page)，需要写回磁盘更新该页面在磁盘上的副本，如果该页面是"干净"的，也就是没有被修改过，则直接用调入的新页面覆盖掉被换出的旧页面即可。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvauNO6QadFJvbG1OjFtc6yM1e0YEykjuYMA3CzJJfbfSb3h54rI21wf8rnPRiaia6nic7CB44wyNh2eibw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

缺页中断的具体流程如下：虚拟地址，物理地址，多级页表，主存，高速缓存，TLB，缺页中断

- **第 1 步**：处理器生成一个虚拟地址 VA，通过总线发送到 MMU；
- **第 2 步**：MMU 从 TLB 中取出对应的 PTE；如果查询 TLB 失败，走正常的多级页表查询流程拿到 PTE，然后把它放入 TLB 缓存，以备下次查询，如果 TLB 此时的存储空间不足，则这个操作会汰换掉 TLB 中另一个已存在的 PTE；MMU 通过虚拟页号得到页表项的地址 PTEA，通过内存总线从 CPU 高速缓存/主存读取这个页表项 PTE；
- **第 3 步**：CPU 高速缓存或者主存通过内存总线向 MMU 返回页表项 PTE；
- **第 4 步**：检查返回的页表项 PTE 发现其有效位是 0，则 MMU 触发一次缺页中断异常，然后 CPU 转入到操作系统内核中的缺页中断处理器；
- **第 5 步**：缺页中断处理程序检查所需的虚拟地址是否合法，确认合法后系统则检查是否有空闲物理页框号 PPN 可以映射给该缺失的虚拟页面，如果没有空闲页框，则执行页面置换算法寻找一个现有的虚拟页面淘汰，如果该页面已经被修改过，则写回磁盘，更新该页面在磁盘上的副本；
- **第 6 步**：缺页中断处理程序从磁盘调入新的页面到内存，更新页表项 PTE；
- **第 7 步**：缺页中断程序返回到原先的进程，重新执行引起缺页中断的指令，CPU 将引起缺页中断的虚拟地址重新发送给 MMU，此时该虚拟地址已经有了映射的物理页框号 PPN，因此会按照『Page Hit』的流程走一遍，最后主存把请求的数据返回给处理器。

### 6、分段管理

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/22de0538-7c6e-4365-bd3b-8ce3c5900216.png"/> </div><br>

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png"/> </div><br>

### 7、段页式管理

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

### 8、分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。

- 地址空间的维度：分页是一维地址空间，分段是二维的。

- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。

- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

## linux 内存管理

### 1、MMU 地址转换

**Linux** 系统主要采⽤了分⻚管理，但是由于 **Intel** 处理器的发展史，**Linux** 系统⽆法避免分段管理。**Linux** 系统中的每个段都是从 **0** 地址开始的整个 **4GB** 虚拟空间（**32** 位环境下），也就是所有的段的起始地址都是⼀样的。这意味着，**Linux** 系统中的代码，包括操作系统本身的代码和应⽤程序代码，所⾯对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被⽤于访问控制和内存保护。

- MMU 是一种硬件电路，它包含两个部件，一个是分段部件，一个是分页部件
- 分段机制把一个逻辑地址转换为线性地址
- 分页机制把一个线性地址转换为物理地址

![图片](https://mmbiz.qpic.cn/mmbiz_png/SeWfibBcBT0FvSKIicrJGVrKcjEuO2VvqKjXiaQLd1ggy84BMabjwDTXgztZ4yBjnr81tRv5GNCePqcAglDSwQlZg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 2、分段机制

**段选择符**

- 为了方便快速检索段选择符，处理器提供了 6 个分段寄存器来缓存段选择符，它们是：cs,ss,ds,es,fs 和 gs
- 段的基地址(Base Address)：在线性地址空间中段的起始地址
- 段的界限(Limit)：在虚拟地址空间中，段内可以使用的最大偏移量

**分段实现**

- 逻辑地址的段寄存器中的值提供段描述符，然后从段描述符中得到段基址和段界限，然后加上逻辑地址的偏移量，就得到了线性地址

  ![图片](https://mmbiz.qpic.cn/mmbiz_png/SeWfibBcBT0FvSKIicrJGVrKcjEuO2VvqK9wrHsGVffYsAW826bMwAdleEiaCDW6ZVKySCWbeJMtJcjiaMdJd7dsjQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



### 3、分页机制（32 位）

- 分页机制是在分段机制之后进行的，它进一步将线性地址转换为物理地址
- 10 位页目录，10 位页表项， 12 位页偏移地址
- 单页的大小为 4KB

![图片](https://mmbiz.qpic.cn/mmbiz_png/SeWfibBcBT0FvSKIicrJGVrKcjEuO2VvqKDTen8ibytC4TRcK3V5EWfP7XtAsOXR0T7IeK56TdZXTpzcuPhJ9lwFQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 3、用户态地址空间

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/SeWfibBcBT0FvSKIicrJGVrKcjEuO2VvqKTEEGDico32dszGXIelfWdJwJnNMIOXLia6YaOQtfxiaU9dGKN5811zUFQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- TEXT：代码段可执行代码、字符串字面值、只读变量
- DATA：数据段，映射程序中已经初始化的全局变量
- BSS 段：存放程序中未初始化的全局变量
- HEAP：运行时的堆，在程序运行中使用 malloc 申请的内存区域
- MMAP：共享库及匿名文件的映射区域
- STACK：用户进程栈

### 4、内核态地址空间

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/SeWfibBcBT0FvSKIicrJGVrKcjEuO2VvqKGcnLGSiaRMYsiavCVliaOCHMdU3pXPlq5RoiacwzJGCMI5LebIAHHP7QNA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 5、进程内存空间

- 用户进程通常情况只能访问用户空间的虚拟地址，不能访问内核空间虚拟地址
- 内核空间是由内核负责映射，不会跟着进程变化；内核空间地址有自己对应的页表，用户进程各自有不同额页表

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/SeWfibBcBT0FvSKIicrJGVrKcjEuO2VvqKmNbCGOOBanCIe34Kuib6ibUp0cKFibIOatD3ZXpJ54A7s5oT8oALB0qWQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 直接映射区：线性空间中从 3G 开始最大 896M 的区间，为直接内存映射区
- 动态内存映射区：该区域由内核函数 vmalloc 来分配
- 永久内存映射区：该区域可访问高端内存
- 固定映射区：该区域和 4G 的顶端只有 4k 的隔离带，其每个地址项都服务于特定的用途，如：ACPI_BASE 等

### **6、DMA 内存**

**什么是 DMA**

- 直接内存访问是一种硬件机制，它允许外围设备和主内存之间直接传输它们的 I/O 数据，而不需要系统处理器的参与2)  DMA 控制器的功能
- 能向 CPU 发出系统保持（HOLD）信号，提出总线接管请求
- 当 CPU 发出允许接管信号后，负责对总线的控制，进入 DMA 方式
- 能对存储器寻址及能修改地址指针，实现对内存的读写操作
- 能决定本次 DMA 传送的字节数，判断 DMA 传送是否结束
- 发出 DMA 结束信号，使 CPU 恢复正常工作状态

**DMA 信号**

- DREQ：DMA 请求信号。是外设向 DMA 控制器提出要求，DMA 操作的申请信号
- DACK：DMA 响应信号。是 DMA 控制器向提出 DMA 请求的外设表示已收到请求和正进行处理的信号
- HRQ：DMA 控制器向 CPU 发出的信号，要求接管总线的请求信号。
- HLDA：CPU 向 DMA 控制器发出的信号，允许接管总线的应答信号：

![图片](https://mmbiz.qpic.cn/mmbiz_png/SeWfibBcBT0FvSKIicrJGVrKcjEuO2VvqKSGsHdYK5HDMibaTo96W1aXaoN8C9UFiaxYpFeGtU2gGb1rVRHicBUNTmg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 1、最佳

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```html
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 2、最近最久未使用

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

```html
4，7，0，7，1，0，1，2，1，2，6
```

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/eb859228-c0f2-4bce-910d-d9f76929352b.png"/> </div><br>
### 3、最近未使用

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4、先进先出

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高。

### 5. 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/ecf8ad5d-5403-48b9-b6e7-f2e20ffe8fca.png"/> </div><br>

### 6、时钟

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/5f5ef0b6-98ea-497c-a007-f6c55288eab1.png"/> </div><br>
